[["index.html", "Introduction to GAM using R 本稿の目的", " Introduction to GAM using R Tsubasa Yamaguchi 2023-08-09 本稿の目的 本稿は、一般化加法モデル(GAM)の概要を解説し、それをRで実行する方法を学ぶことを目的とする。本稿の内容はこちらから読むことができる。 GAMは一般化線形モデル(GLMに代表される線形なモデルを拡張し、変数間の関係をより柔軟な形で表現できるようにしたものである。そのため、GLMで仮定されるような単調増加または単調減少の関係だけでなく、非線形な関係を調べることができる。 霊長類の行動のような複雑なデータでは変数間の関係が非線形になることがしばしばあるため、GAMは多くの研究で用いられている(e.g., Matsumoto 2017; Taniguchi and Matsumoto-Oda 2018; Hongo et al. 2022)。GLMのように線形性を仮定するモデルがデータに当てはまらない場合には、GAMなどの非線形性を許容するモデルを使用する必要性が生じてくるだろう。 本稿は、Alain Zuurが執筆した”A beginner’s guide to generalized additive models with R”(Zuur 2012)の内容を基に執筆している。本書はなるべく数学的な説明を省きつつ、実際の生態学のデータを用いてGAMについてわかりやすく解説したもので、GAMの入門として非常によい書籍である。より詳細な情報を知りたい場合は原著にアクセスしていただきたい。 その他に参考にしたのは以下の本である。 Zuur (2009) Mixed effects models and extensions in ecology with R. James et al. (2013) An Introduction to Statistical Learning with Applications in R. 竹澤 (2009) Rによるノンパラメトリック回帰の入門講義 References "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham and Grolemund 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al. 2021) 出版社サイト 使用するパッケージは以下のとおりである。GAMの実行は主にgamパッケージ(Hastie and Hastie 2018)を用い、結果の作図についてはggplotパッケージでGAMの結果を可視化することに特化したgratiaパッケージを用いる。 ## GAM library(mgcv) library(gamlss) library(gratia) library(gstat) library(MASS) library(brms) library(rstan) library(cmdstanr) library(DHARMa) library(DHARMa.helpers) ## データハンドリング library(tidyverse) library(easystats) library(data.table) ## グラフや表関連 library(sp) library(plotly) library(htmlwidgets) library(ggnewscale) library(GGally) library(patchwork) library(DT) library(knitr) library(kableExtra) library(dagitty) library(ggdag) library(ggforce) library(concaveman) library(ggsci) library(lemon) library(gganimate) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) References "],["Chapter1.html", "1 Review of multiple linear regressions 1.1 Light levels and size of the human visual system 1.2 The variables 1.3 Protocol for the analysis 1.4 Data exploration 1.5 Multiple linear regression 1.6 Finding the optimal model 1.7 Degree of freedom 1.8 Model validation 1.9 Model interpretation 1.10 What to do if things go wrong", " 1 Review of multiple linear regressions 本章では、一般化加法モデル(GAM)の説明に入る前に、多くの人に馴染みのある重回帰分析(multiple linear regression)について説明する、なぜなら、GAMは重回帰分析を拡張したものだからである。 1.1 Light levels and size of the human visual system Pearce and Dunbar (2012) は、ヒトの集団が住んでいる標高と眼窩の容量に正の関連があることから、住んでいる環境の光量がヒトの視覚システムの進化の原動力になっていると結論付けた。本章ではこの論文のデータを用いて重回帰分析について説明を行う。重回帰分析でデータを探索し、モデルを構築し、モデルを当てはめ、モデル選択を行い、モデルの妥当性を確認する方法はGAMでもほとんど同じように適用できる。 1.2 The variables Pearce and Dunbar (2012) は、オックスフォード大学博物館にある55人の成人の頭蓋骨から、頭蓋の容量(cranial capacity: CC)と眼窩容量(orbital volume)、大後頭孔(foramen magnum: FM)などの測定を行った。 データは以下のとおりである。平均眼窩容量(mean orbital volume)が目的変数であり、それ以外の変数は説明変数である1。AbsoluteLatitudeとMinimum_Tempreture_celsiusはそれぞれ 頭蓋が発見された場所の標高と最低気温、FMarea_intercondyleは体格の大きさを示す指標、Minimum_Illuminanceはlogスケールで表した光の強度、Genderは頭蓋の性別である。 hvs &lt;- read_delim(&quot;data/HVS.txt&quot;) datatable(hvs, filter = &quot;top&quot;, options = list(scrollX = 20)) 変数名が長いので、以下のように短く変更する。 hvs %&gt;% rename(OrbitalV = MeanOrbitalVolume, LatAbs = AbsoluteLatitude, CC = CranialCapacity, Illuminance = Minimum_Illuminance, Temperature = Minimum_Temperature_celsius, FM = FMarea_intercondyle) %&gt;% mutate(fPopulation = factor(Population), fGender = factor(Gender)) -&gt; hvs 新しい列名は以下の通り。 colnames(hvs) ## [1] &quot;Museum&quot; &quot;Findsite&quot; &quot;Gender&quot; &quot;Population&quot; &quot;Latitude&quot; ## [6] &quot;LatAbs&quot; &quot;CC&quot; &quot;FM&quot; &quot;OrbitalV&quot; &quot;Illuminance&quot; ## [11] &quot;Temperature&quot; &quot;fPopulation&quot; &quot;fGender&quot; 1.3 Protocol for the analysis いかなるデータ分析も、以下の手順に沿って行わなければならない。 Data exploration 外れ値がないか、多重共線性(説明変数同士の強い相関)がないか、目的変数と説明変数の関係がどうか、ゼロ過剰はないか、サンプリングの収集が時間や場所によってばらついていないか、などをチェックする必要がある。 Model application 1の作業で分かったことや研究仮説をもとに、適切なモデルを適用する。今回は重回帰分析を行うが、様々なモデルを適用可能である。 Check the result モデルを当てはめたら、どの変数が有意な影響を持つかを調べ、そうでなかった変数についてはどうするかを考える。 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。満たしていれば結果の解釈や結果の作図を行い、満たしていなければモデルを改善する必要がある(GAM、GLM、GLMを使うなど)。 1.4 Data exploration まずは手順1のデータ探索を行う。データ探索については Zuur et al. (2010) に詳しい。 1.4.1 欠損値の確認 まず、欠損値がないかを調べる。 colSums(is.na(hvs)) ## Museum Findsite Gender Population Latitude LatAbs ## 0 0 0 0 0 0 ## CC FM OrbitalV Illuminance Temperature fPopulation ## 0 1 0 0 0 0 ## fGender ## 0 FMの列に1つ欠損値があるので取り除く。 hvs_b &lt;- na.omit(hvs) 1.4.2 外れ値の確認 続いて、外れ値がないかを確認する。ここでは、連続値の説明変数(Latitude、CC、FM、Illuminance、Temperature)についてCleveland Dotplotを作成する。Dotplotは縦軸にサンプル番号、横軸に実際の値をとる。 図は以下のとおりである(図1.1)。図を見る限り、外れ値はなさそうだ。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature) %&gt;% mutate(sample_number = 1:n()) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = sample_number))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Values of the variable&quot;, y = &quot;Sample number&quot;)+ theme(aspect.ratio = 1) 図1.1: Cleveland dotplot for covariates. 1.4.3 多重共線性の確認 次に、多重共線性(説明変数同士の強い相関)がないかを調べる。もしあると、推定結果にバイアスが生じてしまう。 説明変数同士の関連を調べたところ(図1.2)、LatAbsとIlluminance、IlluminanceとTemperature、TemperatureとLatAbsに強い相関があることが分かる。また、CCは男性で高い傾向があることが分かったので、CCとfGenderを同じモデルに説明変数として入れない方がよさそうである(今回はfGenderを用いない)。 ggpairs(hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, fGender)) 図1.2: correlation between covariates 1.4.4 目的変数と説明変数の関係の確認 最後に、目的変数と説明変数の関連を調べる(図1.3)。図には局所回帰(LOESS)による回帰曲線を追加している。 図から、LatAbsとOrbitalVの間に線形の関係がありそうだということが分かる(’CC’も?)。IlluminanceやTemperatureにも同様のことがいえるが、これは変数間に強い相関があることを考えれば当然だろう。多重共線性を考慮し、Pearce and Dunbar (2012) にもとづいて解析ではLatAbsを用いてIlluminanceとTemperatureは用いないこととする。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, OrbitalV) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = OrbitalV))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Explanatory Variables&quot;, y = &quot;OrbitalV&quot;)+ theme(aspect.ratio = 1)+ geom_smooth(method = &quot;loess&quot;, se= F, color = &quot;grey32&quot;, span = 0.9) 図1.3: Relationship between explanatory variables and orbital volume (OrbitalV). A LOESS smoother was added to the plot. 1.5 Multiple linear regression 1.5.1 Underlying statistical theory それでは、重回帰分析を行う。まずは説明のために説明変数が1つだけのモデル(= 単回帰)を考えよう。 標高のみを説明変数とする単回帰モデルは以下のように実行できる。 M1 &lt;- lm(OrbitalV ~ LatAbs, data = hvs_b) summary(M1) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9893 -1.4166 -0.1616 1.5037 3.8887 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.91064 0.51412 44.563 &lt; 2e-16 *** ## LatAbs 0.06598 0.01411 4.677 2.11e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.253 on 52 degrees of freedom ## Multiple R-squared: 0.2961, Adjusted R-squared: 0.2825 ## F-statistic: 21.87 on 1 and 52 DF, p-value: 2.111e-05 これは、実際には何をやっているのだろうか? lm関数で短回帰を実行するとき、私たちは下記のモデルを実行している。なお、\\(i\\)はサンプル番号(今回は55個の頭蓋がある)を、2行目は\\(\\epsilon_i\\)が平均0、分散\\(\\sigma^2\\)の正規分布に従うことを表す。 \\[ \\begin{aligned} OrvitalV_i &amp;= \\alpha + \\beta\\times LatAbs_i + \\epsilon_i \\;\\; (i = 1,2,\\dots, 55)\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルで推定するパラメータは\\(\\alpha\\)、\\(\\beta\\)、\\(\\sigma\\)である。\\(\\beta\\)は標高(LatAbs)が眼窩容量(OrbitalV)に与える影響の大きさを表し、式からわかるように標高が1増えると眼窩容量が\\(\\beta\\)増えることを表す。先ほどlm関数で実行した結果でEstimateの下に書かれていた数字(\\(22.91...と0.065...\\))は\\(\\alphaと\\beta\\)の推定値を示しているのである。 もし以下のように行列を定義すると、 \\[ \\begin{aligned} \\mathbf{y} = \\begin{pmatrix} OrbitalV_1\\\\ OrbitalV_2\\\\ \\vdots\\\\ OrvitalV_{55} \\end{pmatrix} , \\mathbf{X} = \\begin{pmatrix} 1 &amp; LatAbs_1\\\\ 1 &amp; LatAbs_2\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; LatAbs_{55} \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_{55} \\end{pmatrix} \\end{aligned} \\] モデル式は以下のように書ける。 \\[ \\mathbf{y = X\\times\\beta + \\epsilon} \\] \\(\\mathbf{X}\\)はRで以下のように求められる。 head(model.matrix(M1)) ## (Intercept) LatAbs ## 1 1 1.33 ## 2 1 5.42 ## 3 1 5.42 ## 4 1 28.51 ## 5 1 28.51 ## 6 1 28.51 パラメータは最小二乗法(ordinary least square)で求められる。最小二乗法は、残差の二乗和(実際の測定値と推定されたモデルによる予測値の差、ここでは\\(\\sum_i^{55}( y_i - \\alpha + \\beta \\times OrbitalV_i)\\))が最小になるようにパラメータを推定する方法である。 \\(\\mathbf{\\beta}\\)の推定値は数学的に以下のように求められる。なお、\\(\\mathbf{X^t}\\)は\\(\\mathbf{X}\\)の転置行列を、\\(\\mathbf{X^{-1}}\\)はは\\(\\mathbf{X}\\)の逆行列を表す。 \\[ \\mathbf{\\hat{\\beta}} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\tag{1.1} \\] なお、\\(\\mathbf{\\hat{\\beta}}\\)は\\(\\mathbf{\\beta}\\)の推定値であることを表し、便宜的にここでは\\(\\mathbf{\\hat{\\beta}} = \\begin{pmatrix}a\\\\b \\end{pmatrix}\\)とする。 Rでは\\(\\mathbf{\\hat{\\beta}}\\)を以下のように求められ、lm関数で推定した場合と同じ推定値が得られることが分かる。 X &lt;- model.matrix(M1) solve(t(X) %*% X) %*% t(X) %*% hvs_b$OrbitalV ## [,1] ## (Intercept) 22.9106427 ## LatAbs 0.0659754 よって、モデルによって推定された眼窩容量(\\(\\hat{y_i}\\))は以下のように表せる。 \\[ Fitted OrbitalV_i = 22.930 + 0.066 \\times LatAbs_i \\] すなわち、モデルの推定値から得られた残差\\(e_i\\)は以下のように表せる。 \\[ e_i = OrbitalV_i - a + b\\times LatAbs_i \\] \\(\\mathbf{\\hat{y}} = \\mathbf{X}\\times \\mathbf{\\beta}\\)と書けるので、残差の行列\\(\\mathbf{e}\\)は\\(\\mathbf{H} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t}\\)とするとき以下のように書ける。 \\[ \\mathbf{e} = \\mathbf{y} - \\mathbf{\\hat{y}} = \\mathbf{y} - \\mathbf{H\\times y} = \\mathbf{(1-H)\\times y} \\tag{1.2} \\] モデル式より、\\(\\mathbf{y}\\)の分散共分散行列は\\(\\sigma^2 \\times \\mathbf{I}\\)と表せるので(\\(\\mathbf{I}\\)は単位行列)、\\(\\mathbf{e}\\)の分散共分散行列は以下のように表せる。 \\[ cov(\\mathbf{e}) = \\sigma^2 \\times (\\mathbf{1 - H}) \\] また、以下の値を標準化残差(standardized residuals)という。なお、\\(H_{ii}\\)は\\(\\mathbf{H}\\)の\\(i\\)番目の対角成分を表す。 \\[ e_i ^* = \\frac{e_i}{\\hat{\\sigma} \\sqrt{(1-H_{ii})}} \\] もしモデルが正しいとき、標準化残差は標準正規分布に従うので、その値のほとんどは-2から2の間に収まるはずである。 Rでは、残差と標準化残差を以下のように求められる。 e &lt;- resid(M1) estd &lt;- rstandard(M1) 実際、1つのデータを除いて-2から2の範囲に収まっている(図1.4)。 data.frame(estd = estd) %&gt;% ggplot(aes(x = estd))+ geom_histogram(binwidth = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_y_continuous(breaks = seq(0,10,1)) 図1.4: 標準化残差の分布 1.5.1.1 外れ値のチェック モデルに極端な外れ値がないかを調べるときには、LeverageとCook’s distanceが用いられることが多い。 leverageは\\(\\mathbf{H}\\)の対角成分で0から1の値をとり、大きいほどそのデータポイントが結果に大きな影響を与える外れ値であることを示す。特に極端な値はないよう(図1.5)。 data.frame(h = diag(H), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = h))+ geom_col(width = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Leverage&quot;) 図1.5: Leveragevalue for each observation 式(1.2)より、以下のように書ける。すなわち、\\(i\\)番目の観察に対してモデルから予測される値(fitted value)は元データの観測値の加重平均であり、重みは行列\\(\\mathbf{H}\\)により与えられる。 \\[ \\hat{y_i} = H_{i1} \\times y_1 + H_{i2} \\times y_2 + \\dots + H_{i55} \\times y_55 \\tag{1.3} \\] 特に\\(H_{ii}\\)は観測値\\(y_i\\)がモデルからの予測値\\(\\hat{y_i}\\)に与える影響の大きさを表している。そのため、\\(H_{ii}\\)が高いことは、その観測値がモデルの推定に大きな影響を及ぼしていることを示しているのである。 ある観測値がモデルの推定に影響を与えている度合いを表すのがCook’s distanceで、以下の式で表せる。\\(\\hat{y_{(i)}}\\)は式(1.3)から\\(H_{ii}\\times y_i\\)を除いたものである。また、\\(p\\)はモデルの回帰式の中のパラメータ数である。 \\[ D_i = \\frac{||\\hat{y_i} - \\hat{y_{(i)}}||}{p \\times \\hat{\\sigma^2}} \\] Cook’s distanceはRで以下のように取得できる。 D &lt;- cooks.distance(M1) data.frame(cookD = D, n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cookD))+ geom_col(width = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.6: Cook’s distance for each observation 1.5.1.2 95%信頼区間と予測区間の算出 \\(\\mathbf{\\beta}\\)の推定値の分散共分散行列は\\(\\mathbf{y}\\)の分散共分散行列が\\(\\mathbf{\\sigma^2 \\times I}\\)であることを考えると、式(1.1)より以下のようになる。 \\[ \\begin{aligned} cov(\\mathbf{\\hat{\\beta}}) &amp;= \\mathbf(X^t \\times X)^{-1} \\times \\mathbf{X^t} \\times cov(\\mathbf{y}) \\times \\mathbf{X} \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\\\ &amp;= \\sigma^2 \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\end{aligned} \\] \\(\\hat{\\beta}\\)の標準偏差は上式から得られる行列の対角成分の1/2乗である。この値は、lm関数を利用した結果(Std. Errorの下の数値)と一致する。 SE &lt;-summary(M1)$sigma * sqrt(diag(solve(t(X) %*% X))) SE ## (Intercept) LatAbs ## 0.51411731 0.01410749 95%信頼区間は、モデル式より\\(\\beta\\)が正規分布に従うので以下のように求められる。 Z &lt;- rbind(coef(M1) + 1.96*SE, coef(M1) - 1.96*SE) %&gt;% data.frame() rownames(Z) &lt;- c(&quot;Upper bound&quot;, &quot;Lower bound&quot;) Z ただし、これはサンプルサイズが十分に大きいときのみ成り立つ。実際は、\\(\\hat{\\beta}\\)は自由度\\(55-2\\)(サンプル数 - パラメータ数)のt分布に従うので、より正確に95%信頼区間を求めるには、1.96ではなく2.005746…を用いる必要がある。 qt(1- 0.05/2, df = 55-2) ## [1] 2.005746 95％信頼区間は、もし100回同様の方法で実験/観察を行ってそれぞれについて95%信頼区間を算出するとき、そのうち95個には真の値が含まれていることを表す。95%信頼区間に0が含まれていないとき、\\(\\hat{\\beta}\\)が有意に0とは違うということができる。 同様に、モデルに基づいた予測値の分散共分散行列は以下のように求められ、その対角成分の1/2乗が予測値の標準誤差(SE)になる。 \\[ cov(\\mathbf{\\hat{y}}) = \\mathbf{X} \\times cov(\\mathbf{\\hat{\\beta}}) \\times \\mathbf{X^t} \\tag{1.4} \\] 予測値の95%信頼区間はある標高(LatAbs)に対して100回データをサンプリングすれば95個のデータが含まれる範囲を表し、予測値が自由度55-2のt分布に従うので、\\(予測値 ± 2.0057 \\times SE\\)で求められる。 一方で95%予測区間は新たにデータをサンプリングしたときにデータの95%が収まる範囲を指す。予測区間を求める際の標準誤差には式(1.4)に\\(\\hat{\\sigma^2}\\)を足したものを用いればよい。 Rでは予測値と95%信頼区間、95%予測区間は以下のように求められる。 ## 係数の分散共分散行列 covbeta &lt;- vcov(M1) data &lt;- data.frame(LatAbs = seq(0,65,length.out = 100)) X &lt;- model.matrix(~LatAbs, data = data) t &lt;- qt(1-0.05/2, df = 55-2) data %&gt;% ## 予測値 mutate(p = X %*% coef(M1)) %&gt;% ## se(信頼区間) mutate(se.ci = sqrt(diag(X %*% covbeta %*% t(X)))) %&gt;% ## se(予測区間) mutate(se.pi = sqrt(diag(X %*% covbeta %*% t(X)) + summary(M1)$sigma^2)) %&gt;% mutate(ci_upper = p + t*se.ci, ci_lower = p - t*se.ci, pi_upper = p + t*se.pi, pi_lower = p - t*se.pi) -&gt; pred 図示すると以下のようになる(図1.7)。 pred %&gt;% ggplot(aes(x = LatAbs, y = p))+ geom_line()+ geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(aes(ymin = pi_lower, ymax = pi_upper), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point(data = hvs_b, aes(y = OrbitalV))+ theme(aspect.ratio = 1)+ theme_bw()+ labs(y = &quot;OrbitalV&quot;) 図1.7: 95%信頼区間と予測区間 predict関数を用いて簡単に求めることができる。 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; conf_M1 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; pred_M1 hvs_b %&gt;% ggplot(aes(x = LatAbs, y = OrbitalV))+ geom_line(data = conf_M1, aes(y = fit))+ geom_ribbon(data = conf_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(data = pred_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point()+ theme(aspect.ratio = 1)+ theme_bw() 図1.8: 95%信頼区間と予測区間(predict関数を使用) 1.5.2 Multiple linear regression それでは、2つ以上の変数を含めたモデリングを行う。データ探索や先行研究の知見から、モデルにはLatAbs、CC、FMを説明変数として入れ、2変数の交互作用を全ての組み合わせについて含めた。 \\[ \\begin{aligned} OrbitalV_i &amp;= \\alpha + \\beta_1 \\times LatAbs_i + \\beta_2 \\times CC_i + \\beta_3 \\times FM_i \\\\ &amp; + \\beta_4 \\times LatAbs_i \\times CC_i\\\\ &amp; + \\beta_5 \\times LatAbs_i \\times FM_i \\\\ &amp; + \\beta_6 \\times CC_i \\times FM_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 1.5.3 Fitting the model in R and estimate parameters モデルのパラメータは、先ほどと同様にlm関数で推定できる。推定は前節で行ったのと全く同じ方法(最小二乗法)で行う。 M2 &lt;- lm(OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM, data = hvs_b) 結果は以下の通り。Estimateはパラメータの推定値を、t valueは5%水準でパラメータが有意に0と異なっているかを判断する際に用いられる。P値(Pr(&gt;|t|))を見ると、有意な変数は一つもなかった。 print(summary(M2), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + ## CC:FM, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.79 -1.50 -0.23 1.40 4.63 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.19e+01 2.24e+01 0.97 0.335 ## LatAbs -2.51e-01 1.60e-01 -1.56 0.124 ## CC 9.37e-04 1.65e-02 0.06 0.955 ## FM 2.16e-03 3.50e-02 0.06 0.951 ## LatAbs:CC 2.37e-04 1.30e-04 1.83 0.074 ## LatAbs:FM -4.49e-05 1.57e-04 -0.29 0.776 ## CC:FM -1.56e-06 2.50e-05 -0.06 0.951 ## ## Residual standard error: 2.14 on 47 degrees of freedom ## Multiple R-squared: 0.427, Adjusted R-squared: 0.354 ## F-statistic: 5.84 on 6 and 47 DF, p-value: 0.000131 1.6 Finding the optimal model さて、先ほどのモデルでは1つも有意に0と異なるパラメータ(\\(\\alpha, \\beta_1 \\sim \\beta_6\\))はなかった(= 目的変数に有意な影響を持つ説明変数変数がなかった)。このようなとき、選択肢がいくつかある。 そのままのモデルを採用し、全ての交互作用が5%水準では有意ではなかったと報告する。 AICを利用して古典的なモデル選択を行う。 仮説検定の結果に基づいて変数選択を行う(効果のなさそうな変数を外す)。 交互作用についてのみモデル選択を行う。 情報理論的アプローチを用い、モデル平均化などを行う(c.f., Burnham et al. (2011) )。 ここでは、 Pearce and Dunbar (2012) に従い、AICを用いたモデル選択を行うことにする。 Rでは、step関数を用いることでステップワイズ法(AICが最も低くなるまで説明変数を1つずつ増減させる方法)を用いた変数選択を行うことができる。分析の結果、LatAbs、CC、これらの交互作用のみを含むモデルが最もAICが低い(= 予測精度が高い)と判断された。 step(M2) ## Start: AIC=88.54 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM ## ## Df Sum of Sq RSS AIC ## - CC:FM 1 0.0177 214.75 86.547 ## - LatAbs:FM 1 0.3756 215.11 86.637 ## &lt;none&gt; 214.74 88.543 ## - LatAbs:CC 1 15.2596 230.00 90.250 ## ## Step: AIC=86.55 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM ## ## Df Sum of Sq RSS AIC ## - LatAbs:FM 1 0.4172 215.17 84.652 ## &lt;none&gt; 214.75 86.547 ## - LatAbs:CC 1 15.2501 230.00 88.252 ## ## Step: AIC=84.65 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## - FM 1 0.5409 215.71 82.788 ## &lt;none&gt; 215.17 84.652 ## - LatAbs:CC 1 16.8268 232.00 86.718 ## ## Step: AIC=82.79 ## OrbitalV ~ LatAbs + CC + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 215.71 82.788 ## - LatAbs:CC 1 17.24 232.95 84.940 ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + LatAbs:CC, data = hvs_b) ## ## Coefficients: ## (Intercept) LatAbs CC LatAbs:CC ## 2.323e+01 -2.552e-01 -5.829e-05 2.201e-04 そこで、選ばれた変数のみを用いたモデルを作成し、分析を行う。 M3 &lt;- lm(OrbitalV ~ LatAbs*CC, data = hvs_b) 分析の結果は以下のとおりである。交互作用項の係数の推定値のP値が0.051であり、わずかに交互作用項の影響があることが示唆された? print(summary(M3), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs * CC, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.759 -1.504 -0.098 1.513 4.588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.32e+01 5.23e+00 4.44 4.9e-05 ## LatAbs -2.55e-01 1.53e-01 -1.67 0.101 ## CC -5.83e-05 3.94e-03 -0.01 0.988 ## LatAbs:CC 2.20e-04 1.10e-04 2.00 0.051 ## ## Residual standard error: 2.08 on 50 degrees of freedom ## Multiple R-squared: 0.425, Adjusted R-squared: 0.39 ## F-statistic: 12.3 on 3 and 50 DF, p-value: 3.81e-06 1.7 Degree of freedom 重回帰分析では、 モデルの自由度は回帰式のパラメータ数なので4である。しかし、このような自由度の求め方はGAMではできない。一般に、パラメータ数は\\(\\mathbf{H}\\)の対角成分の和(= trace)で求めることができる。 \\[ p = \\sum_{i =1} ^{55} \\mathbf{H_{ii}} \\] 確かに4になっている。 X &lt;- model.matrix(M3) H &lt;- X %*% solve(t(X) %*% X) %*% t(X) sum(diag(H)) ## [1] 4 1.8 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。残差には普通の残差のほかに、標準化残差、スチューデント化残差などがあるが、ここでは標準化残差を用いる。 等分散性が成り立つか (→ モデルに基づく予測値と残差をプロットする) モデルがデータに当てはまっているか(線形性が成り立つか)、残差の独立性があるか (→ 残差とモデルに含まれる説明変数、モデルに含まれない説明変数の関係をプロットする) データの独立性があるか(→ 自己相関があるかを確認する) 残差が仮定した分布(今回は正規分布)に従うかを確認する(→ QQプロットを書く) モデルへの影響が大きいデータがないか確認する(→ Cook’s distanceやLeverage) まず、モデルによる予測値と標準化残差の関係をプロットする(図1.9)。このときプロットにパターンがあってはいけない(e.g., 広がっていく、ばらつきが不均等など)。もし前提を満たしていれば、0を中心に均等にばらつくはずである。図からは、明確なパターンは見られない(横軸が26~27で負の残差がほとんどないなどを除けば)。 data.frame(fitted = fitted(M3), resstd = rstandard(M3)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;) 図1.9: Standardized residuals versus fitted values to assess homogeneity 続いて、Cook`s distanceを用いて影響の大きいデータがないか確認する。Cook’s distanceは通常1を超えると影響が大きいと判断される2。ほんもでるではそのような値をとる観測値はない(図1.10)。 data.frame(cook = cooks.distance(M3), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cook))+ geom_col(width = 0.2)+ geom_hline(yintercept = 1, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Observations&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.10: Cook’s disance for each observation 残差の正規性は、ヒストグラムとQQプロットを基に判断される。QQプロットとは、「得られたデータ(今回の場合は標準化残差)と理論分布(今回の場合は標準正規分布)を比較し、その類似度を調べるためのグラフ」である。詳細についてはこちら。もし類似度が高ければ、点が直線上に乗る。そこまで大きくは外れていなさそう。 qqnorm(rstandard(M3)) qqline(rstandard(M3)) 図1.11: QQplot for M3 続いて、(モデルに入れていない説明変数を含めた)各連続変数と標準化残差の関連を図示する(図1.12)。いずれも関連はないようで、これはモデルによって説明できない部分(= 残差)はこうした変数とも関連がないことを示している。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(CC, LatAbs, FM, Illuminance, Temperature, resstd) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_point()+ geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;)+ facet_rep_wrap(~var, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.12: Multiple scatterplots of the standardized residuals versus each continuous variables これは、離散的な変数についても同様のようである(図1.13)。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(fPopulation, fGender, resstd) %&gt;% pivot_longer(1:2, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_boxplot()+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.13: Boxplot of standardized residuals versus discrete variable 自己相関も大きくなさそうである。 acf(hvs_b$OrbitalV) 1.9 Model interpretation モデルの推定値に基づくと、眼窩容量の予測値は以下のように書ける。 \\[ OrbitalV_i = 23.23 -0.25 \\times LatAbs_i -0.000058 \\times CC_i + 0.00022 \\times LatAbs_i \\times CC_i \\] モデルに基づく回帰平面を描くと以下のようになる(図1.14)。 data_M3 &lt;- crossing(LatAbs = seq(0.02,65, length.out = 100), CC = seq(1100,1700, length.out = 100)) pred &lt;- predict(M3, newdata = data_M3) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(data_M3) %&gt;% pivot_wider(names_from = CC, values_from = pred) %&gt;% select(-1) plot_ly(hvs_b, x = ~LatAbs, y = ~CC, z = ~OrbitalV, type = &quot;scatter3d&quot;, size = 2) %&gt;% add_trace(z = as.matrix(pred), x = seq(0.02,65, length.out = 100), y = seq(1100,1700, length.out =100), type = &quot;surface&quot;) -&gt; p p 図1.14: 3d plot of the fitted surface 1.10 What to do if things go wrong もしモデルが前提を満たさなかったらどうすればよいだろうか?本節では特にどのようなときにGAMを適用すべきかを解説する。 等分散性の仮定が満たされないとき、以下の選択肢を検討する必要がある。 目的変数に変数変換を施す 一般化最小二乗法(GLS)を用いる さらに説明変数や交互作用を加える 目的変数の分布として他の分布を用いる(ガンマ分布など) 3つ目の選択肢において、非線形のパターンも許容するように拡張すると、GAMが使えるようになる。これは、残差と説明変数が何らかのパターンを示した時にも有効である(= 関係が線形でない可能性があるため)。 References "],["Chapter2.html", "2 Introduction to additive models using deep-sea fisheries data 2.1 Impact of deep-sea fisheries 2.2 First encounter with smoothers 2.3 Allpying GAM in R using the mgcv package 2.4 Cross validation 2.5 Model validation 2.6 Extending the GAM with more covariates 2.7 Transforming the density data 2.8 Allowing for heterogeneity 2.9 Transforming and allowing for heterogeinity 2.10 What to present in paper", " 2 Introduction to additive models using deep-sea fisheries data 本章では、正規分布に従う一般化加法モデル(GAM)の導入を行う。 2.1 Impact of deep-sea fisheries 本章では、商業的な漁業が深海(水深800–4865m)の魚の密度に及ぼす影響を調べた Bailey et al. (2009) のデータを用いる。データは2つの期間に分かれており、1979年から1989年は商業的な漁業がおこなわれる前(深い水深での漁業が発展している段階)で、1997年から2002年は商業的漁業がおこなわれている時期である。商業的漁業は技術的または商業的な理由により水深約1600mまでに限られている。 fish &lt;- read_delim(&quot;data/BaileyDensity.txt&quot;) datatable(fish, options = list(scrollX = 20), filter = &quot;top&quot;) 期間ごとにデータをサンプリングした場所を示したのが図2.1である。Periodは1が1979–1989年を、2が1997–2002年を表す。 fish %&gt;% mutate(Period = as.factor(Period)) %&gt;% ggplot(aes(x = Xkm, y = Ykm))+ geom_point(aes(fill = Period), shape = 21, alpha = 0.6)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;)) 図2.1: Position of the Sites Bailey et al. (2009) では、魚の密度を以下のように定義している。 \\[ 場所iにおける魚の密度 = \\frac{場所iの魚の総量}{場所iで探索を行った面積} \\] 密度のような割り算データを目的変数にして正規分布に当てはめると、等分散性の問題が生じることが多い。通常、このような分子が整数値の割り算データに対してはポワソン分布や負の二項分布でオフセット項を用いる(第4章を参照)。もし分母が試行数、分子が成功数などのカウントデータの場合は二項分布を当てはめた方がよい。密度が0より大きい値しかとらないのであれば、ガンマ分布を当てはめることもできる。 2.2 First encounter with smoothers 2.2.1 Applying linear regression 2.2.1.1 当てはめるモデル 全種を含めた魚の密度は以下のように表せる。なお\\(i\\)は場所を、\\(j\\)は魚の種類を表す。また、\\(SA_i\\)は場所\\(i\\)における探索面積を、\\(Y_{ij}\\)は場所\\(i\\)における種\\(j\\)の捕獲個体数を表す。 \\[ Dens_i = \\frac{\\sum_j Y_{ij}}{SA_i} \\] まずは、各探索場所の深さのみが魚の密度に影響するとする線形なモデルを考える。モデル式は以下のようになる。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta \\times Depth_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.2.1.2 data exploration いかなるモデルを作ろうとも、まずはデータ探索を行う。まずは、水深と魚の密度の関連をプロットする(図2.2)。図から明らかに水深と魚の密度の関係は線形ではない。しかし、ここではこうしたデータが線形モデルの前提を満たさないことを示すため、まずは通常の線形モデルを適用する。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% mutate(year01 = ifelse(Year &gt; 1990, &quot;commercial&quot;,&quot;non-commercial&quot;)) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(shape = year01))+ scale_shape_manual(values = c(19,1)) + theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.2: Relationship between fish density and mean sampling depth. Filled circles are observations from the second period and open circles from the first period. モデルは以下のように実行できる。モデルは、目的変数のばらつきの33.7%が水深で説明できると推定している(Adjusted R-squaredより)。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% na.omit() -&gt; fish M2_1 &lt;- lm(Dens ~ MeanDepth, data = fish) print(summary(M2_1), digits = 3) ## ## Call: ## lm(formula = Dens ~ MeanDepth, data = fish) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.007835 -0.002519 -0.000558 0.001420 0.023109 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.09e-02 8.06e-04 13.51 &lt;2e-16 *** ## MeanDepth -2.56e-06 2.96e-07 -8.63 1e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.00449 on 145 degrees of freedom ## Multiple R-squared: 0.339, Adjusted R-squared: 0.335 ## F-statistic: 74.4 on 1 and 145 DF, p-value: 1.02e-14 2.2.1.3 model diagnosis それでは、モデル診断を行おう。 まずは標準化残差とモデルの予測値の関係を見る(図2.3のA)。明らかにパターンが見て取れ、モデルが等分散性の仮定を満たしていないことが分かる。また、水深と標準化残差にもパターンがあるように見え(図2.3のB)、このモデルでは水深でうまく目的変数を説明できていないことが分かる。 data.frame(resstd = rstandard(M2_1), fitted = fitted(M2_1)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_1_a data.frame(resstd = rstandard(M2_1), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_1_b p_diag_M2_1_a + p_diag_M2_1_b 図2.3: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットでも標準化残差が標準正規分布に従っていないことが示唆される。 qqnorm(rstandard(M2_1)) qqline(rstandard(M2_1)) 図2.4: QQplot for M2_1 残差に見られたパターンは、明らかに非線形なデータに直線的なモデルを当てはめているために生じている。図2.5からわかるように、水深2000m以上ではモデルに基づく回帰直線がほとんどデータの上に来てしまっている。また、水深約4000m以上では予測値がマイナスになってしまっている。 dataM2_1 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_1 &lt;- predict(M2_1, newdata = dataM2_1) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_1) pred_M2_1 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.5: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.2 Applying cubic polynomials モデルを改善するため、説明変数に水深の二乗、三乗、四乗項を入れるモデルを考える(= 多項式回帰)。このようにすることで非線形な関係をとらえられるかもしれない。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth^2_i + \\beta_3 \\times Depth^3_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] そのようなモデルは以下で実行できる。 M2_2 &lt;- lm(Dens ~ poly(MeanDepth, 3), data = fish) モデルの診断を行ったのが図2.6である。明確なパターンがあるように見え(A. 予測値が大きいほどばらつきが大きくなる、B. 水深が浅くなるほどばらつきが大きくなる)、モデルが十分に改善できていないことが分かる。 data.frame(resstd = rstandard(M2_2), fitted = fitted(M2_2)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_2_a data.frame(resstd = rstandard(M2_2), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_2_b p_diag_M2_2_a + p_diag_M2_2_b 図2.6: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットからも標準化残差が標準正規分布に従っていないことが分かる(図2.7)。 qqnorm(rstandard(M2_2)) qqline(rstandard(M2_2)) 図2.7: QQplot for M2_2 実測値にモデルに基づく予測値を描いたのが図2.8である。水深4000mあたりで予測値がほとんどの実測値よりも低くなってしまっている。 dataM2_2 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_2 &lt;- predict(M2_2, newdata = dataM2_2) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_2) pred_M2_2 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.8: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.3 A simple GAM モデルを改善するほかの選択肢は、一般化加法モデル(GAM)を用いることである。シンプルなGAMは以下のように書ける。\\(f(Depth_i)\\)は平滑化関数であり、予測値がデータに合うような曲線を描くように推定される。以下では、GAMではどのようにしてこの関数を推定するのかを説明していく。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + f(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{2.1} \\] 2.2.4 Moving average and LOESS smoother データに合うように平滑化を行う方法は複数存在するが、比較的単純なものが移動平均とLOESS(局所回帰)である。より複雑な手法については第3方で解説する。 2.2.4.1 移動平均 移動平均は、推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータの平均値を推定値とするような方法である。例えば、水深2500mのときの推定値として、その前後500m(2000m ~ 3000m)にあるデータの平均値を用いると、0.00286になる(図2.9)。 fish %&gt;% filter(MeanDepth &gt;= 2000 &amp; MeanDepth &lt;= 3000) %&gt;% summarise(mean = mean(Dens)) -&gt; mean fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_vline(xintercept = 2000, linetype = &quot;dashed&quot;)+ geom_vline(xintercept = 3000, linetype = &quot;dashed&quot;)+ geom_point(aes(x = 2500, y = mean$mean), size = 5, shape = 18, color = &quot;black&quot;)+ annotate(geom = &quot;text&quot;, x = 3000, y = mean$mean + 0.002, label = sprintf(&quot;%.5f&quot;,mean$mean))+ geom_segment(aes(x = 2550, xend = 2900, y = mean$mean, yend = mean$mean + 0.0015))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.9: Visualization of the process of the moving average. A target value of depth = 2500 was chosen. これを一定間隔のデータで行ってつなげると、移動平均に基づいて平滑化曲線を描くことができる(図2.10)。 Depth_n &lt;- seq(810, 4800, length.out = 150) Mean_n &lt;- data.frame(MeanDepth = Depth_n, Est = NA) for(i in seq_along(Depth_n)){ fish %&gt;% filter(MeanDepth &gt;= Depth_n[i] - 500 &amp; MeanDepth &lt;= Depth_n[i] + 500) %&gt;% summarise(mean = mean(Dens)) -&gt; mean_i Mean_n[i,2] &lt;- mean_i$mean } fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_line(data = Mean_n, aes(y = Est), linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.10: Estimated moving average smoother 2.2.4.2 局所回帰(LOESS) 移動平均ではギザギラのラインが推定されるが、LOESSではよりスムーズなラインを引くことができる。局所回帰は推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータだけを用いて多項式回帰を行い(多くのソフトでデフォルトでは2次の項までを含む)、その予測値を推定値とする方法である。移動平均と同様に一定間隔のポイントに対してこれを行うことで、平滑化した曲線を描く。 Rでは、loess関数で推定を行うことができる。span =で各ポイントでの推定に用いるデータの割合を指定できる(デフォルトは0.75)。図2.11はspanを0.1, 0.5, 1にした場合に描けるモデルから推定された平滑化曲線である。1のときは、全データを使用した多項式回帰と同じ結果である。移動平均でもLOESSでも、推定を行う際に使用するデータの範囲を変えると結果も大きく変わるので注意が必要である。 M2_3_a &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.1) M2_3_b &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.5) M2_3_c &lt;- loess(Dens ~ MeanDepth, data = fish, span = 1) pred_M2_3_a &lt;- predict(M2_3_a, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.1) pred_M2_3_b &lt;- predict(M2_3_b, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.5) pred_M2_3_c &lt;- predict(M2_3_c, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 1) bind_rows(pred_M2_3_a, pred_M2_3_b, pred_M2_3_c) %&gt;% mutate(span = str_c(&quot;span = &quot;, span)) %&gt;% ggplot(aes(x = MeanDepth, y = fit))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3)+ geom_point(data = fish, aes(y = Dens), shape = 1)+ facet_rep_wrap(~ span)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.11: LOESS smoother using a span of 0.1, 0.5, and 1. 2.2.5 Packages for smoothing Rには、平滑化を行うことができるパッケージが複数存在する。例えば、gamパッケージ(Hastie and Hastie 2018)、mgcvパッケージ(Wood and EPSRC 2007)、gamlssパッケージ(Rigby et al. 2019)などがある。それぞれのパッケージに長所と短所があり、gamはLOESSを用いる際に使いやすく、mgvcはより発展的な手法に対して使いやすい。gamlssはより広い分布に対して用いることができる。本稿では主にmgcvパッケージを用いる。 mgvcパッケージでは様々な手法を用いた平滑化を行うことができるが、自身のデータに対してどの方法を用いるかを決めるためにはこうした手法について知っていなければならない。こうした手法については、第(3)章で詳しく学ぶ。 2.3 Allpying GAM in R using the mgcv package 本節では、mgvcパッケージを用いてGAMを適用する方法を学ぶ。まず、gam関数を用いて式(2.1)を以下のように適用する。なお、fx = TRUE、k = 5というのは有効自由度4の平滑化関数が用いられていることを示しているが、詳しくは次章で説明する。 M2_4 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 5), data = fish) gam関数はthin plate regression splineといわれる方法を用いている。有効自由度は曲線の形を決める値であり(calibration value)、1だと直線になり大きくなるほどより非線形な形になる。自由度4は古典的なパッケージでデフォルトとしてよく使われている値であり、推定された曲線は3次の項までを含む多項式回帰によるものと似ている。次節(2.4)ではcross validationを用いてどの自由度が最も適切か決める方法を学ぶ。 summary関数でモデルの結果の概要を得ることができる。 summary(M2_4) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, fx = TRUE, k = 5) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0047137 0.0003616 13.04 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 4 4 22.12 3.27e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.367 Deviance explained = 38.4% ## GCV = 1.9894e-05 Scale est. = 1.9218e-05 n = 147 切片の推定値は0.0047なので、モデル式は以下のように書ける。 \\[ Dens_i = 0.0047 + f(Depth_i) \\] また、結果からはモデルが分散の36.9%を説明すること、推定された残差が従う正規分布の分散が\\(1.908 \\times 10^{-5}\\)であることも分かる。 smoother(\\(f(Dens_i)\\))の有意性(Approximate significance of smooth term)は、以下のF値によって計算されている。なお、\\(RSS_1、RSS_2\\)はそれぞれsmootherがないモデルとあるモデルの残差平方和、\\(pとq\\)はそれぞれsmootherがあるモデルとないモデルの自由度、\\(N\\)はサンプル数である。もしモデルが前提を満たすならば、Fは自由度\\(N-p\\)と\\(p-q\\)のF分布に従う。 \\[ F = \\frac{(RSS_1 - RSS_2)/(p-q)}{RSS_2/(N-p)} \\] モデルによって推定された曲線は以下のようになる(図2.12)。mgvcパッケージで推定した結果は、gratiaパッケージを用いると簡単に描画することができる。 dataM2_4 &lt;- data.frame(MeanDepth = seq(800, 4865, length.out = 100)) ## 予測値を算出 pred_M2_4_4 &lt;- fitted_values(M2_4, data = dataM2_4) %&gt;% mutate(df = 4) ## 描画 pred_M2_4_4 %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.12: Fitted values obtained by the GAM. 2.4 Cross validation 前節では自由度4で分析を行ったが、自由度はほかの値に設定することも可能である。図2.13は様々な自由度を用いたモデルの推定結果を図示したものである。どのようにして最適な自由度を選べばよいだろうか? ## df = 2 M2_4_2 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 3), data = fish) pred_M2_4_2 &lt;- fitted_values(M2_4_2, data = dataM2_4) %&gt;% mutate(df = 2) ## df = 3 M2_4_3 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 4), data = fish) pred_M2_4_3 &lt;- fitted_values(M2_4_3, data = dataM2_4) %&gt;% mutate(df = 3) ## df = 5 M2_4_5 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 6), data = fish) pred_M2_4_5 &lt;- fitted_values(M2_4_5, data = dataM2_4) %&gt;% mutate(df = 5) ## df = 7 M2_4_7 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 8), data = fish) pred_M2_4_7 &lt;- fitted_values(M2_4_7, data = dataM2_4) %&gt;% mutate(df = 7) ## df = 9 M2_4_9 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 10), data = fish) pred_M2_4_9 &lt;- fitted_values(M2_4_9, data = dataM2_4) %&gt;% mutate(df = 9) ## 描画 bind_rows(pred_M2_4_2, pred_M2_4_3, pred_M2_4_4, pred_M2_4_5, pred_M2_4_7,pred_M2_4_9) %&gt;% mutate(df = str_c(&quot;df = &quot;,df)) %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) + facet_rep_wrap(~df, repeat.tick.labels = TRUE) 図2.13: Fitted values obtained by the GAM using 2, 3, 4, 5, 7, 9 degrees of freedom. gam関数では、fx =とk =を書かなければ自動的に交差検証(cross validation)を実行し、最適な自由度を探してくれる。下記のように、最適な自由度は5.62ということになる。 M2_5 &lt;- gam(Dens ~ s(MeanDepth), data = fish) summary(M2_5) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0047137 0.0003561 13.24 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.621 6.723 14.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.386 Deviance explained = 40.9% ## GCV = 1.9514e-05 Scale est. = 1.8635e-05 n = 147 推定結果をもとに描いた平滑化曲線は以下のようになる(図2.14)。 pred_M2_5 &lt;- smooth_estimates(M2_5, data = dataM2_4) %&gt;% ## 95%信頼区間を算出 add_confint() %&gt;% mutate(est = est + coef(M2_5)[[1]], lower_ci = lower_ci + coef(M2_5)[[1]], upper_ci = upper_ci + coef(M2_5)[[1]]) %&gt;% mutate(df = 4) ## 描画 pred_M2_5 %&gt;% ggplot(aes(x = MeanDepth, y = est))+ geom_line()+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(-0.001,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.14: Fitted values obtained by the GAM. それでは、交差検証とは何だろうか?smoother\\(f(Depth_i)\\)の推定値を\\(\\hat{f}(Depth_i)\\)とするとき、推定値が真のsmootherとどれほど近いかは以下の式で表せる。 \\[ M = \\frac{1}{n}\\sum_{i = 1} ^n (f(Depth_i) - \\hat{f}(Depth_i))^2 \\] もし私たちが真の\\(f(Depth_i)\\)を知っているならば、Mが最小になるように\\(\\hat{f}(Depth_i)\\)を推定することができるが、真のsmootherを知ることはできない。そのため、私たちは\\(M\\)を何か計算可能なもので代用する必要がある。 方法としては、交差検証、一般化交差検証(generalized cross validation)、頑強なリスク推定(unbiased risk estimator)、Marrow’s Cpなどがある。gam関数では、通常の加法モデルを適用するか、一般化加法モデルを適用するかによってこれらのいずれかが用いられる。本節では、通常の交差検証(ordinary cross validation: OCV)について簡単な解説を行う。 交差検証のスコア\\(V_0\\)は以下の式で与えられる。\\(f^{-i}(Depth_i)\\)は\\(i\\)番目のデータ以外のデータから推定されたsmootherの推定値を表す。\\(V_0\\)を最小にするようにsmootherの推定値を求める。 \\[ V_0 = \\frac{1}{n}\\sum_{i = 1} ^n (Depth_i -f^{-i}(Depth_i))^2 \\] 理論的に、\\(V_0\\)の期待値は\\(M\\)の期待値に分散\\(\\sigma^2\\)を足した値に近似できる。 \\[ E[V_0] \\approx E[M] + \\sigma^2 \\] これを計算するのは負荷が大きいため、通常はgeneralized cross validation scoreというものを用いることでshortcutを行う。詳細については第3章で解説を行う。データ数が50未満の場合は多重共線性やデータの非独立性によって交差検証の結果に問題が生じることがある。そのため、交差検証の結果をきちんと確認することが必要である。 2.5 Model validation 2.5.1 Normality and homogeneity GAMでは重回帰分析のときと同様に残差を抽出し、その正規性や等分散性、独立性、影響のある観察の有無を確認しなければならない。 gratiaパッケージでは、appraise関数でQQプロット、残差 vs 予測値、残差のヒストグラム、実測値 vs 予測値のプロットを作成してくれる(図2.15)。なお、それぞれのグラフはqq_plot()、residuals_linpred_plot()、residuals_hist_plot()、observed_fitted_plotで個別に作成できる。 この結果から、等分散性や残差の正規性が成立していないことが分かる。 appraise(M2_5, type = &quot;response&quot;) 図2.15: Model diagnosis using gratia package. 手動で残差 vs 予測値、残差のヒストグラムは以下のように作成できる(図2.16)。 data.frame(res &lt;- resid(M2_5), fitted = fitted(M2_5)) -&gt; diag_M2_5 diag_M2_5 %&gt;% ggplot(aes(x = fitted,y = res))+ geom_point()+ geom_hline(yintercept = 0, color = &quot;red&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted value&quot;, y = &quot;Residuals&quot;) -&gt; p_diag_M2_5_a diag_M2_5 %&gt;% ggplot(aes(x = res))+ geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Residuals&quot;, y = &quot;Frequancy&quot;) -&gt; p_diag_M2_5_b p_diag_M2_5_a + p_diag_M2_5_b 図2.16: Model diagnosis of GAM. 2.5.2 Independence 残差の独立性を確認するため、残差と説明変数などの変数の関連をプロットする(図2.17)。水深との関連については(A)、等分散性の仮定が満たされていないことを除けば、特にパターンは見られない。もし水深との関連にもパターンがみられていたら、GAMの自由度を上げることでこの問題を解決できる。 一方で、期間との関連についてはパターンがみられ、期間2の残差がほとんど0を下回っている。このことは、Periodをモデルに加えた方がいいことを示唆している。 data.frame(res = resid(M2_5), MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;, title = &quot;A&quot;) -&gt; p_ind_M2_5_a data.frame(res = resid(M2_5), Period = as.factor(fish$Period)) %&gt;% ggplot(aes(x = Period, y = res))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Period&quot;, y = &quot;Residuals&quot;, title = &quot;B&quot;) -&gt; p_ind_M2_5_b p_ind_M2_5_a + p_ind_M2_5_b 図2.17: A: residuals versus depth. B: residuals versus period 残差に空間的な相関があるかを調べるため、各データポイントで調査が行われた場所と残差の大きさの関連を示したものが図2.18である。残差の大きさが点の色と大きさで表されている。このデータだけではいまいち解釈がしにくい。 data.frame(res = resid(M2_5), x = fish$Xkm, y = fish$Ykm) %&gt;% ggplot(aes(x = x, y = y))+ geom_point(aes(color = res, size = res), alpha = 0.5)+ scale_size(range = c(1,7))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X-coordinates&quot;, y = &quot;Y-coordinates&quot;) 図2.18: Bubble plot of the residuals. このようなときに使えるのがバリオグラム(variogram)である。バリオグラムは以下の手順で作成する。なお、通常dは離散的に選択する。 全てのサイト間の距離を計算する。 距離がある特定の値dであるサイトの全組み合わせについて残差の差の二乗を計算し、それの平均値を算出する。 これを全ての距離について行い、距離と平均値の関係をプロットする。 もし残差が空間的に独立なのであれば、算出された平均値は水平に分布する。 Rではgstatパッケージで以下のように算出できる。図で表したものが図2.19である。図からは150m以上離れるとsemi-variogram値(縦軸)が大きくなる傾向があることが分かる。このパターンは、他の変数や交互作用をモデルに含めることで解消できるかもしれない。 fish_cor &lt;- fish ## coordinateを作成 sp::coordinates(fish_cor) &lt;- ~ Xkm + Ykm ## 算出 vario_M2_5 &lt;- gstat::variogram(resid(M2_5) ~ 1, fish_cor) ## 作図 vario_M2_5 %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(size = 3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Distance (km)&quot;, y = &quot;semivariogram&quot;) 図2.19: Semi-variogram of the residuals of the GAM. この分析の問題点は深さが考慮されていない点である。2地点間のxy平面上の距離が近くても、深さが違えば実際の距離は最大で5km近く離れている可能性がある。 2.5.3 Influential observations GAMではcook’s distanceは算出できないが、各観測値の影響力の強さは全データを用いたモデルから推定されたsmoother(\\(\\hat{f}(Depth_i)\\))からその観測値以外のデータを用いたモデルから推定されたsmoother(\\(f^{-i}(Depth_i)\\))を引いた値の二乗の合計値を算出することで求めることができる。各観測値について影響力の大きさは以下のように定式化できる。 \\[ I_i = \\sum_{i = 1}^n (\\hat{f}(Depth_i) - f^{-i}(Depth_i))^2 \\] Rでは以下のように計算できる。 nd &lt;- data.frame(MeanDepth = seq(min(fish$MeanDepth), max(fish$MeanDepth), length.out = 150)) pred_M2_5 &lt;- predict(M2_5, newdata = nd, type = &quot;terms&quot;) I &lt;- vector() for(i in 1:nrow(fish)){ M2_5.i &lt;- gam(Dens ~ s(MeanDepth), data = fish %&gt;% filter(Site != fish[i,1][[1]])) pred_M2_5.i &lt;- predict(M2_5.i, newdata = nd, type = &quot;terms&quot;) I[i] &lt;- sum((pred_M2_5[1:150] - pred_M2_5.i[1:150])^2) } 各ポイントの影響力の大きさをサイズにしてプロットしたのが図2.20である。いくつか影響力の高そうな点があるが、それが有意に大きいのか否かを言うことはできない。 fish %&gt;% mutate(I = I) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(size = I))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.20: Scatterplot of fish density versus depth. The size of an observation point is proportional to its influence on the shape of the smoother. 2.6 Extending the GAM with more covariates 2.6.1 GAM with smoother and a normal covariate GAMでも通常の線形モデルと同様に2つ以上の説明変数や交互作用を含めることができる。ここでは、これまでのモデルでは考慮できなかった調査期間(Period)と調査期間と水深(MeanDepth)の交互作用を入れることで、調査期間ごとに水深と魚の密度の関係が変わっているのかを調べるモデルを作成する。本節では交互作用なしとありのモデルを作成し、どちらがより良いモデルかを検討する。 交互作用なしモデルのモデル式は以下のようになる。このモデルでは、水深と魚の密度の関連はいずれの期間でも同じだが、その平均が期間によって異なることを仮定している。 \\[ \\begin{aligned} Dnes_i &amp;= \\alpha + f(Depth_i) + \\beta \\times Period_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] モデルはRで以下のように実行できる。 fish &lt;- fish %&gt;% mutate(Period = as.factor(Period)) M2_6 &lt;- gam(Dens ~ s(MeanDepth) + Period, data = fish) 結果は以下の通り。 summary(M2_6) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054572 0.0004291 12.716 &lt; 2e-16 *** ## Period2 -0.0021859 0.0007433 -2.941 0.00383 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.566 6.664 14.85 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.417 Deviance explained = 44.4% ## GCV = 1.8637e-05 Scale est. = 1.7677e-05 n = 147 モデルの推定結果からそれぞれの期間について以下のような式が書ける。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0032 + f(Depth_i) \\end{aligned} \\] モデルの結果を図示したのが図2.21である。 nd &lt;- crossing(MeanDepth = seq(800, 4650, length.out = 100), Period = as.factor(c(1,2))) fitted_values(M2_6, data = nd, scale = &quot;response&quot;) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish, aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.21: Visualisation of the GAM that contains a smoother of depth and period as a factor. 2.6.2 GAM with interaction terms; first implement GAMで交互作用を含める場合、モデルは以下のようになる。\\(f_1(Depth_i)\\)と\\(f_2(Depth_i)\\)はそれぞれの期間ごとのsmootherを表す。 \\[ \\begin{aligned} Dnes_i &amp;= \\alpha + f_1(Depth_i) +f_2(Depth_i) + \\beta \\times Period_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sin N(0,\\sigma^2) \\end{aligned} \\] このモデルはRでは以下のように実行できる。 M2_7 &lt;- gam(Dens ~ s(MeanDepth, by = Period) + Period, data = fish) 推定結果は以下の通り。期間ごとにsmootherを推定しているので、それぞれのsmootherの自由度が異なる。期間2は自由度が1.078なのでほとんど直線に近いことになる。 summary(M2_7) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, by = Period) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054405 0.0004286 12.693 &lt; 2e-16 *** ## Period2 -0.0022054 0.0007324 -3.011 0.00309 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth):Period1 4.169 5.094 17.18 &lt; 2e-16 *** ## s(MeanDepth):Period2 1.078 1.151 10.33 0.000913 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.419 Deviance explained = 44.4% ## GCV = 1.8547e-05 Scale est. = 1.7632e-05 n = 147 推定結果から、各期間の魚の密度と水深の関係は以下のようになる。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f_1(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0032 + f_2(Depth_i) \\end{aligned} \\] 推定結果を図示したのが図2.22である。 fitted_values(M2_7, data = nd, scale = &quot;response&quot;) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)), aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2))))+ facet_wrap(~Period) 図2.22: Visualisation of the GAM that contains a smoother of depth and period as a factor. 2.6.3 GAM with interaction; third implementation 期間ごとに異なるsmootherを推定するもう一つの方法として、以下のモデルを使うこともできる。ここで、\\(f(Depth)\\)は両期間に共通するsmoother、、\\(f_2(Depth)\\)は期間2のみに適用されるsmootherである。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + f(Depth_i) +f_2(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルはRで以下のように実行できる。モデル式の中にモデルM2_7のように\\(Period\\)が単独で説明変数として入っていない点には注意が必要である。これは、gamでs(MeanDepth, by = as.numeric(Period == \"2\"))のように指定を行う場合はsmootherが0で中心化されていないからである(それ以外の場合は0で中心化されている)。 M2_8 &lt;- gam(Dens ~ s(MeanDepth) + s(MeanDepth, by = as.numeric(Period == &quot;2&quot;)), data = fish) モデルの結果は以下のとおりである。期間2だけのsmootherも有意であるので、期間1と2でsmootherが有意に異なることが分かる。モデルM2_7と異なるのは、このように水深と魚の密度の関連が期間ごとに有意に異なるのかを検定できる点である。 summary(M2_8) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) + s(MeanDepth, by = as.numeric(Period == ## &quot;2&quot;)) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054462 0.0004248 12.82 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 4.714 5.729 15.697 &lt; 2e-16 *** ## s(MeanDepth):as.numeric(Period == &quot;2&quot;) 2.000 2.000 6.737 0.00161 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.428 Deviance explained = 45.4% ## GCV = 1.8319e-05 Scale est. = 1.7358e-05 n = 147 推定結果から、各期間の魚の密度と水深の関係は以下のようになる。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0054 + f(Depth_i) + f_2(Depth_i) \\end{aligned} \\] 推定結果を図示したのが図2.23である。 fitted_values(M2_8, data = nd, scale = &quot;response&quot;) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)), aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2))))+ facet_wrap(~Period) 図2.23: Visualisation of the GAM that contains a smoother of depth and period as a factor. これまでに適用した交互作用を含むモデル(M2_7とM2_8)のモデル診断を行うと、いずれも等分散性や正規性の仮定を満たしていないことが分かる(図2.24と図(fig:fig-gam-diagnosis-M2-8))。 このようなとき、取りうる手段は(1) 変数を変換する、(2)等分散性を許容できる推定方法(GLSなど)を用いる、(3) (1)と(2)を組み合わせた方法を用いる、などがある。以下では、こうした方法について議論する。 appraise(M2_7) 図2.24: Model diagnosis of M2_7 appraise(M2_8) 図2.25: Model diagnosis of M2_8 2.7 Transforming the density data まず、魚の密度の平方根を目的変数とするように変数変換を行ったモデルを考える。 fish &lt;- fish %&gt;% mutate(Dens_sqrt = sqrt(Dens)) M2_9_a &lt;- gam(Dens_sqrt ~ s(MeanDepth, by = Period) + Period, data = fish) しかし、変数変換を施しても等分散性の仮定は両期間で満たされない。 data.frame(res = resid(M2_9_a), Period = fish$Period, MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(aes(yintercept = 0))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;) 図2.26: Residuals versus Mean Depth for M2_9_a 魚の密度を対数変換することもできる。 fish &lt;- mutate(fish, Dens_log = log(Dens)) M2_9_b &lt;- gam(Dens_log ~ s(MeanDepth, by = Period) + Period, data = fish) そうすると、等分散性の問題が解決されたように見える。 data.frame(res = resid(M2_9_b), Period = fish$Period, MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(aes(yintercept = 0))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;) 図2.27: Residuals versus Mean Depth for M2_9_b ただし、QQプロットを見ると正規性の仮定は満たされていなさそう? qq_plot(M2_9_b)+ theme_bw()+ theme(aspect.ratio = 1) 図2.28: QQplot for M2_9 2.8 Allowing for heterogeneity 変数変換の問題点は、大きい目的変数の方が小さいものよりもより圧縮されることで、期間ごとの違いが小さくなってしまう傾向があることである。 Pinheiro and Bates (2000) は、モデルの中に分散の不均等性を入れ込むことができることを示した。残差が従う正規分布の分散として\\(\\sigma^2\\)ではなく、以下の3つのうちのいずれかを考える。 1つ目は、例えば期間ごと(\\(s = 1, 2\\))に異なる分散を考えるというものである。より細かくエリアごとに分散を求めたり、水深をカテゴライズしてそれぞれのカテゴリに異なる分散を割り当てることもできる。 2つ目と3つ目は、深さによって分散の値を変化させるというもので、その変化の仕方は最尤推定法によって推定されるパラメータ\\(\\delta\\)によって決定される。 \\[ \\begin{aligned} \\epsilon_i &amp;\\sim N(0, \\sigma_s^2)\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2 \\times |Depth_i|^{2 \\times \\delta}) \\\\ \\epsilon_i &amp;\\sim N(0, e^{2 \\times \\delta \\times Depth_i}) \\end{aligned} \\tag{2.2} \\] Zuur (2009) は、正しい分散構造や共変量を選ぶための10ステップのプロトコルを書いている。1つの選択肢は、たくさんの分散構造のモデルを当てはめてみて、AICなどでモデル選択を行うというものである。もう一つは、通常の分散を持つモデルの残差からどのような分散構造を当てはめるべきかを検討するというものである。 2つ目のアプローチをとるとすると、図2.26は2通りに解釈できる。 水深が2000m以下のデータはそれ以外のデータより大きな分散をとる 水深が深くなるほど、分散は小さくなっていく 1つ目の解釈に従うとすると、残差の従う正規分布の分散は以下のように書ける。 \\[ \\begin{aligned} var(\\epsilon_i) = \\begin{cases} \\sigma_2^2 &amp; (Depth_i &lt; 2000m)\\\\ \\sigma_1^2 &amp; (Depth_i &gt; 2000m)\\\\ \\end{cases} \\end{aligned} \\tag{2.3} \\] 2つ目の解釈に従うとすると、式(2.2)の2つ目か3つ目のアプローチをとることになる。2つで推定される結果の違いはほとんどなく、問題になるのは\\(Depth\\)が0になるときだけであるが、今回は問題ない(\\(Depth &gt; 800\\))。 式(2.3)はRでは以下のように実行できる。 fish %&gt;% mutate(IMD = ifelse(MeanDepth &lt; 2000, &quot;1&quot;,&quot;2&quot;)) %&gt;% mutate(IMD = as.factor(IMD)) -&gt; fish M2_10 &lt;- mgcv::gamm(Dens ~ s(MeanDepth, by = Period) + Period, weights = varIdent(form =~ 1|IMD), data = fish) 結果は、M2_10$lmeとM2_10$gamの2つに格納されている(正直、lmeの方はよくわからない)。 summary(M2_10$lme)のVariance functionで推定されている1.000…と0.134…は、期間1と2の標準偏差(\\(\\sigma_1, \\sigma_2\\))がそれぞれ\\(1.00 \\times \\sigma\\)と\\(0.13 \\times \\sigma\\)であることを示している。\\(\\sigma\\)の推定値はM2_10$lme$sigmaで求められ、0.0059であることから、期間1と2の分散はそれぞれ\\((1.00 \\times 0.0059)^2\\)、\\((0.13 \\times 0.0059)^2\\)である。 summary(M2_10$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## -1354.792 -1330.869 685.3962 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 ## StdDev: 0.00278938 0.00278938 0.00278938 0.00278938 0.00278938 0.00278938 ## Xr7 Xr8 ## StdDev: 0.00278938 0.00278938 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 ## StdDev: 9.208057e-08 9.208057e-08 9.208057e-08 9.208057e-08 9.208057e-08 ## Xr.06 Xr.07 Xr.08 Residual ## StdDev: 9.208057e-08 9.208057e-08 9.208057e-08 0.005961115 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | IMD ## Parameter estimates: ## 1 2 ## 1.0000000 0.1348403 ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) 0.004957091 0.0003399765 143 14.580687 0.0000 ## XPeriod2 -0.002669103 0.0003924738 143 -6.800718 0.0000 ## Xs(MeanDepth):Period1Fx1 -0.003085801 0.0011260515 143 -2.740373 0.0069 ## Xs(MeanDepth):Period2Fx1 -0.001177319 0.0001825878 143 -6.447962 0.0000 ## Correlation: ## X(Int) XPerd2 X(MD):P1 ## XPeriod2 -0.866 ## Xs(MeanDepth):Period1Fx1 -0.444 0.385 ## Xs(MeanDepth):Period2Fx1 0.000 -0.313 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.35949767 -0.40177858 -0.04041883 0.43543146 4.61217288 ## ## Number of Observations: 147 ## Number of Groups: ## g g.0 %in% g ## 1 1 summary(M2_10$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, by = Period) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0049571 0.0003376 14.682 &lt; 2e-16 *** ## Period2 -0.0026691 0.0003898 -6.848 2.14e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth):Period1 3.388 3.388 68.42 &lt;2e-16 *** ## s(MeanDepth):Period2 1.000 1.000 42.16 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.62 ## Scale est. = 3.5535e-05 n = 147 図2.29は標準化残差とモデルからの予測値をプロットしたものである。標準化残差\\(e_i^s\\)は以下のように求められる。\\(\\sigma_j\\)は期間ごとの分散である。プロットから、パターンが消えていることが確認できる。 \\[ \\begin{aligned} e_i &amp;= Dens_i - \\hat{\\alpha} - \\hat{f_1}(Depth_i) -\\hat{f_2}(Depth_i) -\\hat{\\beta} \\times Period_i \\\\ \\epsilon_i^s &amp;= \\frac{e_i}{\\sqrt{\\hat{\\sigma_j}^2}} \\end{aligned} \\] plot(M2_10$lme, col = 1, pch = 16, cex.lab = 1.5) 図2.29: Standardised residuals plotted versus fitted values obtained by the GAMM containing the varIdent residual variance structure. ただし、QQプロットを見ると正規性の仮定は満たされていなさそう? qq_plot(M2_10$gam)+ theme_bw()+ theme(aspect.ratio = 1) 図2.30: QQplot for M2_10 2.9 Transforming and allowing for heterogeinity 変数変換を行ったうえでまた等分散性の仮定が満たされない場合は、加えて式(2.2)のいずれかの方法で分散を調整することもできる。 Bailey et al. (2009) では以下のモデルを適用している。 \\[ \\begin{aligned} \\sqrt{Dens_i} &amp;= \\alpha + f(Depth_i) +f_2(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma_j^2)\\\\ \\sigma^2_j &amp;= \\begin{cases} \\sigma_2^2 &amp; (Depth_i &lt; 2000m)\\\\ \\sigma_1^2 &amp; (Depth_i &gt; 2000m)\\\\ \\end{cases} \\\\ \\end{aligned} \\] Rでは以下のように実行できる。 M2_11 &lt;- gamm(Dens_sqrt ~ s(MeanDepth, by = Period) + Period, weights = varIdent(form =~ 1|IMD), data = fish) モデル診断を実行すると、等分散性の問題も正規性の問題も解決できているように見える(図2.31)。 appraise(M2_11$gam) 図2.31: Model diagnosis for M_11 モデルM2_7, M2_9_a、M2_9_b、M2_11から得られた平滑化曲線を図示したのが図2.32である。 fish %&gt;% pivot_longer(cols = c(Dens,Dens_sqrt,Dens_log), values_to = &quot;Dens&quot;, names_to = &quot;type&quot;) %&gt;% mutate(type = ifelse(str_detect(type,&quot;sqrt&quot;),&quot;B&quot;, ifelse(str_detect(type,&quot;log&quot;),&quot;C&quot;,&quot;A&quot;))) %&gt;% bind_rows(fish %&gt;% select(-Dens,-Dens_log) %&gt;% rename(Dens = Dens_sqrt) %&gt;% mutate(type = &quot;D&quot;)) %&gt;% mutate(Period = str_c(&quot;Period &quot;,Period))-&gt; fish_long fitted_values(M2_7, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;A&quot;) %&gt;% bind_rows(fitted_values(M2_9_a, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;B&quot;)) %&gt;% bind_rows(fitted_values(M2_9_b, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;C&quot;)) %&gt;% bind_rows(fitted_values(M2_11, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;D&quot;)) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish_long, aes(y = Dens, fill = Period), shape = 21, alpha = 0.7, size = 2.5)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ new_scale_fill()+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1.2)+ geom_ribbon(aes(ymin = lower, ymax = upper, fill = Period), alpha = 0.3)+ scale_fill_manual(values = c(&quot;grey45&quot;,&quot;red3&quot;))+ theme_bw(base_size = 13)+ theme(aspect.ratio = 1, strip.text = element_text(hjust = 0), strip.background = element_blank())+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;)), fill = &quot;Period&quot;, linetype = &quot;Period&quot;)+ guides(fill = guide_legend(override.aes = list(size = 3)))+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;) 図2.32: Estimated smoothing curves obtained by a GAM. A: Gaussian GAM, B: Gaussian GAM square root density, C: Gaussian GAM log density, D: Gaussian GAM square root density, varIdent 2.10 What to present in paper 本章で行ったような分析を論文で記すとき、以下のものが含まれていなければいけない。 データを測定したサイトの場所を示した図(図2.1)。 検討した問い データ探索を行ったことと、なぜGAMを適用したかの説明 モデルの数学的な表現、モデルの結果、モデルの診断結果 図2.32のうちのいずれか References "],["Chapter3.html", "3 Technical aspects of GAM using pelagic bioluminescent organisms 3.1 Pelagic bioluminescent organism data 3.2 Lineaar regression 3.3 Polynomial regression model 3.4 Linear spline regression 3.5 Quadratic spline regression 3.6 Cubic regression splines 3.7 The number of knots 3.8 Penalized quadratic spline regression 3.9 Other smoothers 3.10 Cubic smoothing spline 3.11 Summary of smoother types 3.12 Degree of freedom of smoother 3.13 Bias-variance trade-off 3.14 Confidence intervals 3.15 Using the function gam in mgcv 3.16 The danger of using GAM 3.17 Additive models with multiple smoothers", " 3 Technical aspects of GAM using pelagic bioluminescent organisms 本章では、GAMの技術的な側面について説明を行う。 3.1 Pelagic bioluminescent organism data GAMの技術的な側面を解説するため、本章では Heger et al. (2008) が2004年夏に海洋生物の発光について調べた研究を用いる。船で海洋を航行中に検出した蛍光の強度(Source)と、水深(Depth)、温度(Temp)、塩分(Salinity)、酸素(Oxgen)などを測定している。 データは14のステーションでサンプルされている。データは以下の通り。 BL &lt;- read_delim(&quot;data/HegerPierce.txt&quot;) datatable(BL, options = list(scrollX = 20), filter = &quot;top&quot;) 3.2 Lineaar regression まずは線形回帰を行う。ひとまず、ステーションの違いは無視して分析を行う。 図3.1は水深(Depth)と\\(1m^3\\)あたりに確認した生物発光の数をプロットしたものである。データを見る限り直線的な関係があるわけではないことが分かる。 BL %&gt;% ggplot(aes(x = Depth, y = Sources)) + geom_point()+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1) 図3.1: Scatterplot of depth versus bioluminescence sources per m^3 以下のモデリングでは、水深を0から1にスケーリングする(モデルがうまく回らなくなるため)。 BL %&gt;% mutate(Original_Depth = Depth, Depth = Depth/max(Depth)) -&gt; BL 明確に直線的な関係はないが、まずは線形回帰を行う。データには様々な変数があるが、いくつかの変数は強く相関しているため、水深のみを説明変数として用いる(図3.2)。 ggpairs(BL %&gt;% select(Sources, Depth, Salinity, Temp, Oxgen)) 図3.2: Pair plot of the data. モデル式は以下のようになる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta \\times Depth_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のように実行する。 M3_1 &lt;- lm(Sources ~ Depth, data = BL) モデルによって推定された回帰直線をデータに当てはめると、明らかに当てはまりが悪いことが分かる(図3.3)。 nd_M3 &lt;- data.frame(Depth = seq(0,1,length.out = 100)) fitted_M3_1 &lt;- predict(M3_1, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_1, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.3: Fitted line estimated from M3_1 本章の目的は、以下のような式を書いたときに\\(Depth\\)と\\(Sources\\)の関係をうまく説明できる\\(f(Depth_i)\\)という関数を見つけることである。先ほどの線形回帰では\\(f(Depth_i) = \\beta \\times Depth_i\\)だった。次節以降では、\\(f(Depth_i)\\)として何が最適かを探っていき、最終的にGAMの解説を行う。 \\[ Sources_i = \\alpha + f(Depth_i) + \\epsilon_i \\tag{3.1} \\] 3.3 Polynomial regression model 続いて、多項式回帰を行ってみる。モデル式は以下のとおりである。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\beta_3 \\times Depth^3 + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のコードで実行できる。 M3_2 &lt;- lm(Sources ~ poly(Depth,3), data = BL) モデルによって推定された曲線をデータの上に描いたのが図3.4である。先ほどよりは当てはまりがよくなったが、左上と右下の当てはまりが悪いことが分かる。 fitted_M3_2 &lt;- predict(M3_2, newdata = nd_M3,) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_2, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.4: Fitted line estimated from M3_2 次節からは、GAMの数理的な基礎を理解するためにも以下を解説する。 線形スプライン回帰(linear spline regression) 二次スプライン回帰(quadratic spline regression) ノット数(numer of knots) 罰則付きスプライン回帰(penalized spline regression) 3.4 Linear spline regression 線形スプライン回帰とは、x軸をいくつかのセグメントに分け、それぞれのセグメントごとに線形回帰を行う方法である。問題は、いくつのセグメントにどのように分けるべきかということである。 図3.3や図3.4からは、スケール化された水深がだいたい0.2くらいで傾きが変わっている印象を受ける。そこで、0.2を境に傾きが変わるモデルを考える。ただし、このとき回帰直線は0.2でつながっていなければいけない。 実際にモデルを適用する前に、\\((Depth_i - 0.2)_+\\)を以下のように定義する。 \\[ (Depth_i - 0.2)_+ = \\begin{cases} 0 &amp; (Depth_i &lt; 0.2)\\\\ Depth_i - 0.2 &amp; (Depth_i ≧ 0.2)\\\\ \\end{cases} \\] Rでは以下のような関数rhsを作成してこうした変数を作成する。これは、ある変数xについて閾値THを境にそれ以下なら0、それ以上なら\\(x - TH\\)となるような新しい変数を作成する関数である。 rhs &lt;- function(x, TH) { ifelse(x &gt;= TH, x - TH, 0) } モデルは以下のようになる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_{11} \\times (Depth_i - 0.2)_+ + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] Rでこれを実装すると以下のようになる。 M3_3 &lt;- lm(Sources ~ Depth + rhs(Depth, 0.2), data = BL) モデルから推定された回帰曲線は以下のようになる(図3.5)。 fitted_M3_3 &lt;- predict(M3_3, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_3, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.5: Fitted line estimated from M3_3 問題は、モデルM3_3が通常の直線回帰モデル(M3_1)や多項回帰モデル(M3_2)よりもよいモデルかどうかである。赤池情報量規準(AIC)を持ちると3、M3_3はより予測の良いモデルだということが分かる。 AIC(M3_1, M3_2, M3_3) しかし、モデルM3_3にも問題点がいくつかある。\\(Depth = 0.2\\)での傾きの変化が急激であるということと、0.2という数値の選択基準が恣意的である点である。 こうした問題点を解決する手段として、例えばデータを10等分してそれぞれについて回帰直線を当てはめるというようなものが考えられる。この場合、傾きは以下の9ポイント(第1から第9十分位数)で変わることになる。このようなポイントをノット(knot)という。 q_Depth &lt;- quantile(BL$Depth, probs = seq(0.1,0.9,0.1)) このとき、モデル式は以下のように書ける。なお、\\(k_j\\)は第j十分位数を表す。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\sum_{j = 1}^9 \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+ \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルはRで以下のように実装できる。 M3_4 &lt;- lm(Sources ~ Depth + rhs(Depth, q_Depth[1]) + rhs(Depth, q_Depth[2]) + rhs(Depth, q_Depth[3]) + rhs(Depth, q_Depth[4]) + rhs(Depth, q_Depth[5]) + rhs(Depth, q_Depth[6]) + rhs(Depth, q_Depth[7]) + rhs(Depth, q_Depth[8]) + rhs(Depth, q_Depth[9]), data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.6)。 fitted_M3_4 &lt;- predict(M3_4, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_4, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.6: Fitted line estimated from M3_4 先ほどよりもよりデータへの当てはまりはよくなっているが、まだカクカクした線になっている。より細かく\\(Depth\\)を区分することは可能である。 model.matrix(M3_4)によって得られるこのモデルのsmootherの要素となった以下のものは、smootherの基底(smoother)と呼ばれる。 \\[ 1, Depth_i, (Depth_i - k_1)_+, (Depth_i - k_2)_+, \\dots, (Depth_i - k_9)_+ \\] 3.5 Quadratic spline regression 適切な\\(f(Depth_i)\\)を探す試みとして線形スプライン回帰を行ったが、ノットで傾きがカクカクしてしまっていた。これに代わる方法として、二次スプライン回帰(quadratic spline regression)を考えることができる。モデルは以下のように書ける。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\sum_{j = 1}^k \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+^2 \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.2} \\] そのため、\\(Depth_i\\)を10等分するのであれば、このモデルにおける基底は以下の12個になる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^2, (Depth_i - k_2)_+^2, \\dots, (Depth_i - k_9)_+^2 \\] このモデルをRで実装するため、以下の関数を作成する。これは、ある変数xについて閾値THを境にそれ以下なら0、それ以上なら\\((x - TH)^2\\)となるような新しい変数を作成する関数である。 rhs2 &lt;- function(x, TH) { ifelse(x &gt;= TH, (x - TH)^2, 0) } モデルは以下のように実行できる。 M3_5 &lt;- lm(Sources ~ Depth + I(Depth^2) + rhs2(Depth, q_Depth[1]) + rhs2(Depth, q_Depth[2]) + rhs2(Depth, q_Depth[3]) + rhs2(Depth, q_Depth[4]) + rhs2(Depth, q_Depth[5]) + rhs2(Depth, q_Depth[6]) + rhs2(Depth, q_Depth[7]) + rhs2(Depth, q_Depth[8]) + rhs2(Depth, q_Depth[9]), data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.7)。線形スプライン回帰よりもなめらかな曲線になっていることが分かる。 fitted_M3_5 &lt;- predict(M3_5, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_5, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.7: Fitted line estimated from M3_5 以下、モデルの結果を見てみよう。rhs2関数で作られた変数の多くが有意でないのは、これらが強く相関しており多重共線性の問題があることが原因だろう。 summary(M3_5) ## ## Call: ## lm(formula = Sources ~ Depth + I(Depth^2) + rhs2(Depth, q_Depth[1]) + ## rhs2(Depth, q_Depth[2]) + rhs2(Depth, q_Depth[3]) + rhs2(Depth, ## q_Depth[4]) + rhs2(Depth, q_Depth[5]) + rhs2(Depth, q_Depth[6]) + ## rhs2(Depth, q_Depth[7]) + rhs2(Depth, q_Depth[8]) + rhs2(Depth, ## q_Depth[9]), data = BL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.285 -4.850 -1.006 2.705 63.710 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 175.444 28.621 6.130 1.25e-09 *** ## Depth -1410.486 409.840 -3.442 0.000601 *** ## I(Depth^2) 3291.466 1430.389 2.301 0.021584 * ## rhs2(Depth, q_Depth[1]) -549.110 2067.208 -0.266 0.790578 ## rhs2(Depth, q_Depth[2]) -2891.946 1340.997 -2.157 0.031269 * ## rhs2(Depth, q_Depth[3]) 368.134 1190.504 0.309 0.757212 ## rhs2(Depth, q_Depth[4]) -935.978 1061.824 -0.881 0.378262 ## rhs2(Depth, q_Depth[5]) 1197.211 877.679 1.364 0.172843 ## rhs2(Depth, q_Depth[6]) -445.930 730.756 -0.610 0.541842 ## rhs2(Depth, q_Depth[7]) 30.872 592.644 0.052 0.958466 ## rhs2(Depth, q_Depth[8]) 5.152 400.189 0.013 0.989732 ## rhs2(Depth, q_Depth[9]) -152.712 295.507 -0.517 0.605421 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.148 on 1037 degrees of freedom ## Multiple R-squared: 0.6892, Adjusted R-squared: 0.6859 ## F-statistic: 209.1 on 11 and 1037 DF, p-value: &lt; 2.2e-16 式(3.2)のモデルは正規分布の一般化加法モデルといえる。mgvcパッケージではより発展的なsmootherを用いており、多重共線性の問題などが生じないようなっている。 このモデルは第1章のときのように以下のように書ける。なお、\\(\\mathbf{y}\\)は目的変数をすべて含むベクトル、\\(\\mathbf{X}\\)はmodel.matrix(M3_5)によって得られる基底の行列、\\(\\mathbf{\\beta}\\)は回帰係数をすべて含むベクトルである。この表現で書けるということは、第1章と全く同じ方法で標準誤差や自由度、信頼区間、予測区間を算出できるということである。 \\[ \\mathbf{y} = \\mathbf{X} \\times \\mathbf{\\beta} + \\mathbf{\\epsilon} \\] 3.6 Cubic regression splines より回帰曲線を滑らかにするのであれば、3次スプライン回帰を考えることもできる。モデル式は以下の通り。Rでも前節までと同様に実行することができる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\beta_3 \\times Depth_i^3 + \\sum_{j = 1}^k \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+^3 \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.3} \\] Wood (2017) や Zuur (2009) では、さらに発展的な方法として以下のモデルを考えた。 \\[ \\begin{aligned} Sources_i &amp;= \\sum_{j = 1}^K \\Bigl( \\beta_{j} \\times b_j(Depth_i) \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.4} \\] ここで、\\(b_1(Depth_i) = 1, b_2(Depth_i) = Depth\\)であり、\\(j ≧ 2\\)のときは\\(B_j(Depth_i) = R(Depth_i, k_{j-2})\\)である。また、\\(k_{j-2}\\)は\\(j-2\\)番目のノットの値を表す。よって、以下のようにも書ける。 \\[ \\begin{aligned} Sources_i &amp;= \\beta_1 + \\beta_1 \\times Depth_i + \\sum_{j = 2}^K \\Bigl( \\beta_{j} \\times R(Depth_i, k_{j-2}) \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.5} \\] なお、\\((Depth_i, k_{j-2})\\)は以下のように定義される。 \\[ R(X,z) = \\frac{1}{4} \\times \\Bigl( (z - \\frac{1}{2})^2 - \\frac{1}{12} \\Bigl) \\times \\Bigl( (X - \\frac{1}{2})^2 - \\frac{1}{12} \\Bigl) - \\frac{1}{24} \\times \\Bigl( (|X-z| - \\frac{1}{2})^4 - \\frac{1}{2}(|X-z| - \\frac{1}{2})^2 + \\frac{7}{240} \\Bigl) \\] Rでもこの関数を作成する。 rk &lt;-function(x, z){ ((z-0.5)^2-1/12)*((x-0.5)^2-1/12)/4 - ((abs(x-z)-0.5)^4-0.5*(abs(x-z)- 0.5)^2 +7/240)/24 } また、説明変数をすべて含む行列\\(\\mathbf{X}\\)を作成する必要がある。この行列は1列目は全て1、2列目は\\(Depth_i\\)で、3列目以降は\\(R(Depth_i, k_{j-2})\\)である。Rでは以下のように作成できる。 spl.X &lt;-function(x, xk){ q &lt;-length(xk) + 2 n &lt;-length(x) X &lt;-matrix(1, n, q) X[,2] &lt;-x X[,3:q] &lt;-outer(x, xk, FUN = rk) X } X &lt;- spl.X(BL$Depth, q_Depth) Rでモデルを以下のように実行できる。なお、\\(\\mathbf{X}\\)にはすでに切片に相当する1列目が含まれているため、Sources ~ X - 1とする。 M3_6 &lt;- lm(Sources ~ X - 1, data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.8)。2次スプライン回帰の結果と大きくは違わない。 Xp &lt;- spl.X(nd_M3$Depth, q_Depth) fitted_M3_6 &lt;- data.frame(Depth = nd_M3$Depth, fitted = Xp %*% coef(M3_6)) BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_6, aes(x = Depth, y = fitted), linewidth = 1)+ geom_vline(xintercept = q_Depth, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.8: Fitted line estimated from M3_6 3.7 The number of knots 第3.4から3.6節までは\\(Depth_i\\)を10の区間に分けており、両端を除くとノット数は9だった。しかし、この数はあくまでも恣意的に選択したものに過ぎない。それでは、私たちはノット数をいくつに設定するのが適切なのだろうか。 図3.9は両端を除くノット数を変化させたときの回帰曲線を図示したものである。結果を見てみると、ノット数による違いはそこまで大きくないように思える。 num &lt;- c(1,3,5,7,9,11,13,15,17, 19, 31) q_Depth_list &lt;- list() X_list &lt;- list() for(i in seq_along(num)){ q_Depth_list[[i]] &lt;- quantile(BL$Depth, probs = seq(0,1,by = 1/(num[i]+1)))[2:(num[i]+1)] X_list[[i]] &lt;- spl.X(BL$Depth, q_Depth_list[[i]]) } M3_6_list &lt;- list() Xp_list &lt;- list() fitted_list &lt;- list() for(i in seq_along(num)){ M3_6_list[[i]] &lt;- lm(Sources ~ X_list[[i]] - 1, data = BL) Xp_list[[i]] &lt;- spl.X(nd_M3$Depth, q_Depth_list[[i]]) fitted_list[[i]] &lt;- data.frame(Depth = nd_M3$Depth, fitted = Xp_list[[i]] %*% coef(M3_6_list[[i]]), knot = num[i]) } bind_rows(fitted_list[1], fitted_list[[2]], fitted_list[[3]], fitted_list[[4]], fitted_list[[5]], fitted_list[[6]], fitted_list[[7]], fitted_list[[8]], fitted_list[[9]], fitted_list[[10]], fitted_list[[11]]) %&gt;% mutate(knot_text = str_c(&quot;inner knot = &quot;, knot)) %&gt;% mutate(knot_text = fct_reorder(knot_text, knot))-&gt; fitted_all BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_all, aes(x = Depth, y = fitted), linewidth = 1)+ facet_rep_wrap(~knot_text, repeat.tick.labels = TRUE)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.9: Fitted smoothers for a quadratic spline regression model using different numbers of knots. AICなどによってこれらのモデルの比較を行うことはできる(図3.10)。AICとAICcに基づくとノット数が7のモデルが最もよく(値が最も小さく)、そこからノット数が離れるほど予測がよくなくなる(= 値が大きくなる)。BICに基づくとノット数が5のときが最も予測が良い。 compare_performance(M3_6_list[[1]],M3_6_list[[2]],M3_6_list[[3]], M3_6_list[[4]],M3_6_list[[5]],M3_6_list[[6]], M3_6_list[[7]],M3_6_list[[8]],M3_6_list[[9]], M3_6_list[[10]],M3_6_list[[11]]) %&gt;% data.frame() %&gt;% mutate(knot = num) %&gt;% select(knot, AIC, AICc, BIC, R2, R2_adjusted) %&gt;% pivot_longer(c(AIC, AICc, BIC), names_to = &quot;IC&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = knot, y = value))+ geom_point(aes(color = IC, shape = IC), size = 5, stroke = 2, alpha = 0.7)+ scale_shape_manual(values = c(1,5,0))+ scale_x_continuous(breaks = num)+ labs(y = &quot;Information criteria&quot;, color = &quot;&quot;, shape = &quot;&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図3.10: AIC, AICc, BIC of the models with different number of knots. しかし、毎回このように様々なノット数でモデリングを行い、情報量規準などに基づいた比較を行うのは時間がかかってしまう。そこで考えられたのが次節(3.8)で説明するpenalized spline modelと呼ばれるものである。 3.8 Penalized quadratic spline regression 各モデルにおいて、回帰係数などのパラメータは最小二乗法によって推定されている。すなわち、以下で表される残差平方和が最小になるように推定を行っている。 \\[ Minimize\\; over \\;\\mathbf{\\beta} : \\sum_i \\epsilon_i^2 \\] 行列形式で表すと以下のようになる。 \\[ Minimize\\; over \\;\\mathbf{\\beta} : ||\\mathbf{\\epsilon^2}|| = ||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}||^2 \\] このとき、\\(\\mathbf{\\beta}\\)の推定値は以下の通りである(第1章も参照)。 \\[ \\hat{\\mathbf{\\beta}} = (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\times \\mathbf{X^t} \\times y \\] さて、ここで式(3.2)に従う二次スプライン回帰モデルを考える。もし両端を除くノット数がKであるとき、\\((Depth-k_j)_+^2\\)の回帰係数${11}, {12}, , _{1K} $を推定することになる。これらのパラメータは平滑化曲線(回帰曲線)の形に柔軟性を与える(= 形を調整する)役割を担っている。 ノット数を変えることで曲線の形を調整することはできるが、図3.9で見たようにノット数によって曲線の形は大きくは変わらなかった。そこで、ノット数を変えるのではなく、ノット数は固定して推定されるパラメータに制限をかけることでsmootherの形を調整するアプローチを考える。例えば、パラメータ\\(\\beta_{11}, \\beta_{12}, \\dots, \\beta_{1K}\\)の二乗がある定数\\(C\\)以下になるように推定を行うことを考える。 \\[ \\beta_{11}^2 + \\beta_{12}^2 + \\cdots + \\beta_{1K}^2 &lt; C \\tag{3.6} \\] こうした方法は制限付き最適化(constrained optimization)と呼ばれる。 ある条件内で残差平方和を最小化するパラメータはラグランジュの未定乗数法と呼ばれる方法で推定できる。例として、条件下で以下の関数\\(f(x,y)\\)を最大にする\\(x,y\\)の組み合わせを探すことを考える。 \\[ \\begin{aligned} f(x,y) = 2x^2 + 2y^2 \\:\\: subject \\:\\: to \\:\\: x + y = 1 \\end{aligned} \\] まず、以下の関数\\(f(x,y,\\lambda)\\)を考える。 \\[ f(x,y,\\lambda) = 2x^2 + 2y^2 + \\lambda(x + y-1) \\] 次に、\\(f(x,y,\\lambda)\\)をそれぞれの変数について偏微分した値が全て0になるように連立方程式を解く。 \\[ \\begin{aligned} 4x + \\lambda &amp;= 0\\\\ 4y + \\lambda &amp;= 0\\\\ x + y -1 &amp;= 0 \\end{aligned} \\] すると、簡単に\\(x = 1/2, y= 1/2\\)と解けるが、これが条件の下で\\(f(x,y)\\)を最大化する\\(x\\)と\\(y\\)の値である。制限付き最適化についてもまったく同じことを行う。式(3.6)のような条件があるときに\\(||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}||\\)を最小化するパラメータを求めるには、以下を最小化すればよい。 \\[ ||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}|| + \\lambda \\times (\\beta_{11}^2 + \\beta_{12}^2 + \\cdots + \\beta_{1K}^2 + C) \\tag{3.7} \\] 以下のような\\(K+3\\)次元の行列(\\(K\\)はノット数)\\(\\mathbf{D}\\)とベクトル\\(\\mathbf{\\beta}\\)を定義する。 \\[ \\mathbf{D} = \\begin{bmatrix} 0 &amp; \\cdots &amp; \\quad &amp; \\quad &amp; \\cdots&amp; 0\\\\ \\vdots &amp; 0 &amp; \\quad &amp; \\quad &amp; \\quad &amp; \\vdots\\\\ \\quad &amp; \\quad &amp; 0 &amp; \\quad &amp; \\quad &amp; \\quad \\\\ \\quad &amp; \\quad &amp; \\quad &amp; 1 \\quad &amp; \\quad &amp; \\vdots\\\\ \\vdots &amp; \\quad &amp; \\quad &amp; \\quad &amp; \\ddots &amp; 0\\\\ 0 &amp; \\cdots &amp; \\quad &amp; \\cdots &amp; 0 &amp; 1 \\end{bmatrix}, \\quad \\mathbf{\\beta} = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2\\\\ \\beta_3\\\\ \\beta_{11}\\\\ \\vdots\\\\ \\beta_{19} \\end{bmatrix} \\] このとき、式(3.7)は以下のように変形できる。 \\[ ||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}|| + \\lambda \\times (\\mathbf{\\beta^t} \\times \\mathbf{D} \\times \\mathbf{\\beta} - \\mathbf{C}) \\tag{3.8} \\] これを\\(\\mathbf{\\beta}\\)について解くと、その推定値は以下のようになる。もし\\(\\lambda = 0\\)ならば(= 何も条件がなければ)、推定値は通常の最小二乗法によるものと同じになる。 \\[ \\hat{\\mathbf{\\beta}} = (\\mathbf{X^t} \\times \\mathbf{X} + \\lambda \\times \\mathbf{D})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\tag{3.9} \\] \\(\\lambda\\)が特定の値を割り当てれば、smoother(\\(f_{\\lambda}\\))を決定することができる。\\(\\hat{\\beta}\\)は\\(\\lambda\\)の値によって変わるので、\\(f_{\\lambda}\\)も\\(\\lambda\\)によって変わる。\\(\\lambda\\)はペナルティの大きさを表すので、大きいほどスプライン回帰を行わない通常の線形回帰や多項式回帰の結果に近づき、0ならば罰則のないスプライン回帰の結果と同じになる。 \\[ \\hat{f_{\\lambda}} = \\mathbf{X} \\times \\mathbf{\\hat{\\beta}} \\tag{3.10} \\] \\(\\lambda\\)の値ごとの曲線を図示したのが図3.11である。\\(\\lambda\\)が大きくなると2次の項までを含む普通の多項式回帰の結果に近づく。 K &lt;- 9 D &lt;- diag(rep(1, 3 + K)) D[1,1]&lt;-D[2,2]&lt;-D[3,3] &lt;-0 X &lt;- model.matrix(M3_5) lambdas &lt;- c(0, 0.25,0.7, 0.75, 1,10) beta &lt;- list() Yhat &lt;- list() for (i in seq_along(lambdas)){ beta[[i]] &lt;- solve(t(X) %*% X + lambdas[i] * D) %*%t(X) %*% BL$Sources MyDepth &lt;- seq(0.1, 1, length =100) XPred &lt;- model.matrix(~ 1 + MyDepth + I(MyDepth^2)+ rhs2(MyDepth, q_Depth[1]) + rhs2(MyDepth, q_Depth[2]) + rhs2(MyDepth, q_Depth[3]) + rhs2(MyDepth, q_Depth[4]) + rhs2(MyDepth, q_Depth[5]) + rhs2(MyDepth, q_Depth[6]) + rhs2(MyDepth, q_Depth[7]) + rhs2(MyDepth, q_Depth[8]) + rhs2(MyDepth, q_Depth[9])) Yhat[[i]] &lt;- XPred %*% as.vector(beta[[i]]) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% mutate(lambda = lambdas[i], Depth = MyDepth) } fitted_lambda &lt;- bind_rows(Yhat[[1]], Yhat[[2]], Yhat[[3]], Yhat[[4]], Yhat[[5]],Yhat[[6]]) %&gt;% mutate(lambda_text = str_c(&quot;lambda = &quot;, lambda)) BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_lambda, aes(x = Depth, y = fitted), linewidth = 1)+ facet_rep_wrap(~lambda_text, repeat.tick.labels = TRUE)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.11: Three smoothers using different values for λ 3.9 Other smoothers mgcvパッケージやgamlssパッケージで用いられるsmootherには様々な種類がある。本節では、これらのいくつかについてまとめ、次節(3.10)では、3次平滑化スプラインについて詳しく解説する。 二次スプライン回帰(第3.5節)や罰則付きの二次スプライン回帰(第3.8節)では、以下の変数が説明変数(基底)となる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^2, (Depth_i - k_2)_+^2, \\dots, (Depth_i - k_9)_+^2 \\] これは\\(p\\)次までの項を含むモデルについて以下のように一般化できる。このようなモデルはp次スプライン回帰モデルまたは罰則付きp次スプライン回帰と呼ばれる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^p, (Depth_i - k_2)_+^p, \\dots, (Depth_i - k_K)_+^p \\] これらのモデルの問題点は各変数が強く相関している可能性が高いことである(特にノット数が多いときは)。Bスプライン平滑化(B-spline smoothing)と呼ばれる手法は、変数変換を施すことでこの問題を解決する。 絶対値の\\(p\\)乗項を含むモデルを考えることもできる。そのようなsmootherは放射基底平滑化(radial basis smoother)と呼ばれ、以下の基底を含む。 \\[ 1, Depth_i^2, |Depth_i - k_1|^p, |Depth_i - k_2|^p, \\dots, |Depth_i - k_K|^p \\] 3.10 Cubic smoothing spline 第3.8節でやったように\\(\\beta_{11}, \\dots, \\beta_{1K}\\)に制限を設けるのではなく、smootherの二次導関数(二回微分値)の和に制限を設ける方法もある。その場合、以下を最小化するようなパラメータを推定する。このような方法を平滑化スプライン(smoothing spline)という。 \\[ ||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}||^2 + \\lambda \\times 全ポイントでの二次導関数の和 \\tag{3.11} \\] 一般にsmoother(\\(f(x)\\))の二次導関数を\\(f&#39;&#39;(x)\\)とするとき、\\(f&#39;&#39;(x)\\)の値が低いほど\\(f(x)\\)はより直線的であることを示す。全ての\\(x\\)について\\(f&#39;&#39;(x)\\)の値を合計するためには、\\(f&#39;&#39;(x)\\)を積分してやればよい。 そのため、式(3.11)は以下のように書き直せる。 \\[ ||\\mathbf{Y} - \\mathbf{X} \\times \\mathbf{\\beta}||^2 + \\lambda \\times \\int f&#39;&#39;(x) dx \\tag{3.12} \\] Wood (2017) は、この基準で最小になる\\(f(x)\\)が3次スプラインであることを証明している。また、式(3.12)は式(3.8)のように書き直すことが分かっているので、\\(\\beta\\)の推定値を得るのに積分をする必要はなく、式(3.9)で求めることができる。 \\(\\mathbf{\\beta}\\)を推定するためには、\\(\\mathbf{X}\\)とパラメータ\\(\\lambda\\)、罰則を表す行列\\(\\mathbf{D}\\)を知る必要がある。3次平滑化スプライン(cubic smoothing spline)の基本は3次回帰スプライン(cubic regression spline)と同じなので、\\(\\mathbf{X}\\)は同じものを用いることができる。 両端を除くノット数はこれまでと同様に9とする。 X &lt;- spl.X(BL$Depth, q_Depth) \\(\\mathbf{D}\\)は\\(11\\times 11\\)の正方行列で、成分は第3.6で出てきた\\(R(X,z)\\)によって決まる。\\(\\mathbf{D}(i + 2, j + 2)\\)は\\(R(x_i,x_j)\\)によって決まり、\\(x_iとx_j\\)は両端を除くノットの値である。 Rでは以下の関数で計算できる。 spl.S &lt;- function(xk){ q &lt;- length(xk) + 2 S &lt;- matrix(0, nrow = q, ncol = q) S[3:q, 3:q] &lt;- outer(xk, xk, FUN = rk) S } D &lt;- spl.S(q_Depth) 最後に、\\(\\lambda\\)については交差検証(第2.4節を参照)を行うことで最適な値を決定する。例えば、\\(\\lambda\\)を0から0.01の間に25個とるとき、交差検証スコアは以下のように算出できる。 K &lt;- 25 OCV &lt;- vector(length = K) lambda &lt;- seq(0,0.001, length.out = K) N &lt;- nrow(BL) for(j in 1:K){ lambdas &lt;- lambda[j] EP &lt;- vector(length = N) for(i in 1:N){ # i番目のデータを除く Xi &lt;- X[-i, ] betai &lt;- solve(t(Xi) %*% Xi + lambdas * D) %*%t(Xi) %*% BL$Sources[-i] Yi &lt;- X[i,] %*% betai EP[i] &lt;- BL$Sources[i] - Yi } OCV[j] &lt;- sum(EP^2)/N } 図示すると以下のようになり、\\(\\lambda = 0.000208\\)のときに交差検証スコアが最も低くなることが分かる(図3.12)。 data.frame(lambda = lambda, OCV = OCV) %&gt;% arrange(OCV) -&gt; ocv ocv %&gt;% ggplot(aes(x = lambda, y = OCV))+ geom_line()+ geom_point(x= ocv[1,1], y = ocv[1,2], color = &quot;red2&quot;, size = 5)+ annotate(geom = &quot;text&quot;, x= ocv[1,1]+ 0.000002, y = ocv[1,2] + 0.05, label = str_c(&quot;lambda = &quot;, round(ocv[1,1],5)))+ geom_segment(x= ocv[1,1] + 0.00002, y = ocv[1,2] + 0.04, xend = ocv[1,1], yend = ocv[1,2])+ theme_bw()+ theme(aspect.ratio = 1) 図3.12: OCV score plotted versus λ for the cubic smoothing spline. データが多いときには上記の交差検証スコアを算出するのは非常に時間がかかるが、交差検証スコアは以下の式で計算できることが数学的にわかっている。なお、\\(A_{ii}\\)はハット行列\\(\\mathbf{S}\\)の対角成分である(後述)。 \\[ V_0 = \\frac{1}{n}\\sum_{i = 1} ^n (Y_i - \\hat{f(X_i)})^2/(1-A_{ii}) \\] こちらの交差検証スコアは以下のように計算できる。 OCV2 &lt;- vector(length = K) for(i in 1:K){ lambdas &lt;- lambda[i] S &lt;- X%*%solve(t(X) %*% X + lambdas * D) %*%t(X) Sii &lt;- diag(S) fit &lt;- S %*% BL$Sources E &lt;- BL$Sources - fit OCV2[i] &lt;- (1/N) *sum((E/(1-Sii))^2) } これは先ほど計算した交差検証スコアと全く同じ値を与える。 data.frame(lambda = lambda, OCV = OCV, OCV2 =OCV2) さて、ここまでの説明で\\(\\mathbf{X}\\)、\\(\\mathbf{D}\\)、\\(\\lambda\\)を求めることができたので、\\(\\mathbf{\\beta}\\)を求めてsmootherを描くことができる。 ## 先敵のlambda lambda_opt &lt;- ocv[1,1] ## betaの推定値 beta &lt;- solve(t(X) %*% X + lambda_opt*D) %*% t(X) %*% BL$Sources ## 図示用の行列X nd &lt;- data.frame(Depth = seq(min(BL$Depth), max(BL$Depth), length = 100)) Xp &lt;- spl.X(nd$Depth, q_Depth) ## smoother fitted_css &lt;- data.frame(fit = Xp%*%beta) %&gt;% bind_cols(nd) 図3.13は推定された回帰曲線を図示したものである。 BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_css, aes(x = Depth, y = fit), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.13: Estimated cubic smoothing spline for the bioluminescence data. 3.11 Summary of smoother types これまで見てきた手法では、以下の4つの手法でsmootherの形を調整してきた。 移動平均や局所回帰の範囲を変更する。 スプライン回帰のノット数を変更する(= linear or quadratic spline regression)。 パラメータに対して制限を設ける(= 制限付き最適化) 二次導関数に対して制限を設ける(= cubic smoothing spline) 3.12 Degree of freedom of smoother 式(3.9)回帰係数のパラメータ\\(\\mathbf{\\beta}\\)は以下の式で与えられる。 \\[ \\hat{\\mathbf{\\beta}} = (\\mathbf{X^t} \\times \\mathbf{X} + \\lambda \\times \\mathbf{D})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\] また、式(3.10)で見たようにsmootherは以下のように書ける。 \\[ \\hat{f(_{\\lambda})} = \\mathbf{X} \\times \\hat{\\mathbf{\\beta}} \\] これらを合わせると、以下のように書ける。 \\[ \\begin{aligned} \\hat{y} &amp;= \\hat{f_{\\lambda}} = \\mathbf{X} \\times (\\mathbf{X^t} \\times \\mathbf{X} + \\mathbf{\\lambda} \\times \\mathbf{D})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\\\ &amp;= S_{\\mathbf{\\lambda}} \\times \\mathbf{y} \\end{aligned} \\] ここで、\\(\\mathbf{S_{\\lambda}}\\)は重回帰分析のときに出たハット行列(第1章参照)と同じ役割を持っている。第1章で、重回帰分析については自由度はハット行列の対角成分を合計することで得られることを見た。smootherの自由度も\\(\\mathbf{S_{\\lambda}}\\)の対角成分の合計によって求めることができる。 X &lt;- spl.X(BL$Depth, q_Depth) D &lt;- spl.S(q_Depth) lambda_opt &lt;- ocv[1,1] ## Sを求める S.lambda &lt;- X %*% solve(t(X)%*%X + lambda_opt*D) %*%t(X) ## 自由度を求める df1 &lt;- sum(diag(S.lambda)) df1 ## [1] 10.1985 よって、smootherの自由度は10.1985018である。なお、\\(\\lambda\\)の値が大きいほど自由度は小さくなる。\\(\\lambda\\)の値によって自由度がどう変わるかをプロットしたのが図3.14)だが、このことが確かめられる。 df &lt;- vector() lambda &lt;- seq(0,5,length = 200) for(i in seq_along(lambda)){ S.lambda &lt;- X %*% solve(t(X)%*%X + lambda[i]*D) %*%t(X) df[i] &lt;- sum(diag(S.lambda)) } data.frame(lambda = lambda, df = df) %&gt;% ggplot(aes(x = lambda, y = df))+ geom_line()+ theme_bw()+ theme(aspect.ratio = 1) 図3.14: Effective degrees of freedom plotted versus λ. 3.13 Bias-variance trade-off 続いて、smootherの信頼区間を計算することを考える。その前に、“bias-variance trade off”について学ぶ必要がある。 あるsmootherについての平均二乗誤差(mean squared error: MSE)は以下のように定義できる。なお、\\(f(Depth_i)\\)は真のsmootherである。 \\[ MSE(\\hat{f_{\\lambda}}(Depth_i)) = E \\Bigl( \\bigl( \\hat{f_{\\lambda}}(Depth_i) - f(Depth_i) \\bigl)^2 \\Bigl) \\] これは、以下のように変形することができる。式の前半部分はバイアス(推定されたsmootherと真のsmootherの差)を表し、後半部分は推定されたsmootherの分散を表す。\\(\\lambda\\)が小さいとき、推定されたsmootherはより非線形性が強いのでバイアスは小さくなるが、推定されたsmoother内でのばらつきは大きくなる。\\(\\lambda\\)が大きいときはこの逆である。すなわち、バイアスと分散の間にはトレードオフの関係がある。 \\[ MSE(\\hat{f_{\\lambda}}(Depth_i)) = \\Bigl(E \\bigl( \\hat{f_{\\lambda}}(Depth_i) \\bigl)- f(Depth_i) \\Bigl) ^2 + var \\bigl(\\hat{f_{\\lambda}}(Depth_i)\\bigl) \\] 3.14 Confidence intervals 今回取り上げたsmootherについて、モデルから推定される高原の数の推定値(\\(\\hat{\\mathbf{y}}\\))とその分散共分散行列は以下のように書ける。標準偏差は分散共分散行列の対角成分の1/2乗であり、信頼区間はそれの-2倍と2倍した区間となる(正確には自由度を考慮する必要がある)。 \\[ \\begin{aligned} \\hat{\\mathbf{y}} &amp;= \\hat{f} = \\mathbf{S_{\\lambda}} \\times \\mathbf{y}\\\\ cov(\\hat{f}) &amp;= \\sigma^2 \\times \\mathbf{S_{\\lambda}} \\times \\mathbf{S_{\\lambda}}^t \\end{aligned} \\] 分散\\(\\sigma^2\\)を求めるためには、error degrees of freedomを求める必要がある。これは、以下の式で求められる。なお、\\(tr()\\)は行列の対角成分の和を計算する関数である。 \\[ N - tr(2 \\times \\mathbf{S_{\\lambda}} - \\mathbf{S_{\\lambda}} \\times \\mathbf{S_{\\lambda}}^t) \\] 分散の推定値は以下の式で求められる。なお、\\(df_{error}\\)はerror degrees of freedomである。 \\[ (\\mathbf{y} - \\mathbf{X} \\times \\hat{\\beta})^2/df_{error} \\] Rでは以下のように求められる。 ## error degrees of freedom df.Error &lt;- nrow(BL) - sum(diag(2*S.lambda - S.lambda %*% t(S.lambda))) ## sigma sigma2 &lt;- sum((BL$Sources - X%*%beta)^2)/df.Error (sigma &lt;- sqrt(sigma2)) ## [1] 9.11692 さて、それでは\\(\\sigma\\)が求まったのが標準誤差を計算することができる。図3.13で回帰曲線を描いたときに使用した行列\\(X_p\\)について標準誤差を算出すると以下のようになる。se_predYがそれぞれの\\(Depth\\)の値のときの標準誤差である。 Sp.lambda &lt;- Xp %*% solve(t(Xp)%*%Xp + lambda_opt*D) %*%t(Xp) cov_predY &lt;- sigma2 * Sp.lambda %*% t(Sp.lambda) se_predY &lt;- sqrt(diag(cov_predY)) よって、95%信頼区間付きの回帰曲線は以下のように書ける(図3.15)。 fitted_css %&gt;% mutate(lower = fit - se_predY*qt(0.975, df = df1), upper = fit + se_predY*qt(0.975, df = df1)) -&gt; fitted_css2 BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.2, color = &quot;grey54&quot;)+ geom_line(data = fitted_css2, aes(x = Depth, y = fit), linewidth = 1)+ geom_ribbon(data = fitted_css2, aes(x = Depth, y = fit, ymin = lower, ymax = upper), color = &quot;black&quot;, alpha = 0, linetype = &quot;dashed&quot;, linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.15: Estimated cubic smoothing spline for the bioluminescence data with 95% confidence interval. しかし、こうして求めた信頼区間には問題がある。求めた信頼区間は、推定されたsmoother(yfit = Xp %*% beta)がバイアスのない推定値だと仮定したうえで計算されたものである。もしsmootherの推定値にバイアスがあるのであれば、図3.15で図示した区間を信頼区間とはみなせない。 mgcvパッケージでは、バイアスに対処するために補正を行っている。 3.15 Using the function gam in mgcv mgcvパッケージを用いたGAMは以下のように実行できる。gam関数は前節までの方法と似ているが、より洗練された方法を用いてsmootherの推定を行っている。 M3_7 &lt;- gam(Sources ~ s(Depth), data = BL) 推定結果は以下の通り。smootherの自由度は8.496で推定された切片は16.7455である。GCV scoreは、一般化交差検証のスコアである。 summary(M3_7) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(Depth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 16.7455 0.2847 58.83 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Depth) 8.496 8.921 251 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.681 Deviance explained = 68.4% ## GCV = 85.778 Scale est. = 85.001 n = 1049 推定された回帰曲線(smoother)は以下のとおりである(図3.16)。 pred_M3_7 &lt;- fitted_values(M3_7, data = nd) ## 描画 pred_M3_7 %&gt;% ggplot(aes(x = Depth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), color = &quot;black&quot;, alpha = 0, linetype = &quot;dashed&quot;, linewidth = 1) + geom_point(data = BL, aes(y = Sources), size = 2, alpha = 0.2, color = &quot;grey54&quot;)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.16: Estimated smoother obtained by the gam function from the package mgcv for the bioluminescence data. それでは、gam関数では実際にどのような手順で推定が行われているのだろうか。まず、s(Depth)としたときに何が行われているのだろうか。関数s()の引数はいくつかあるが、そのうちデフォルトで与えられているのは以下の3つである。 k = -1, fx = FALSE, bs = \"tp\" fx = FALSEは、罰則付きの回帰スプラインが使われていることを表し、もしfx = TRUEならば自由度を固定した回帰スプラインが行われる。kはsmootherの基底の次元を表し、\\(k-1\\)がsmootherの自由度の上限になる。k = -1ではデフォルトの値が選ばれる。bsは使用されるsmootherが指定される。詳しい説明は?smoother.termsとすれば見ることができる。 つまり、引数を何も指定しないときは罰則付きの回帰スプラインが適用され、自由度は交差検証によって決定される。自由度を固定してGAMを実行するときは以下のようにすればよい。k = 5にするとsmootherの自由度は4になる。 M2_8 &lt;- gam(Sources ~ s(Depth, fx = TRUE, k = 5), data = BL) 使われるsmootherの種類による推定結果の違いは小さいが、データ数によっては種類を変えることで推定が効率的になったりする。デフォルトのbs = \"tp\"では薄板平滑化スプライン(thin plate regression spline)と呼ばれる方法が用いられる。この方法では交互作用項を含めた平滑化を行うことができるようだ(詳しくはこちらやこちら)。 bs = \"cr\"では、罰則付きの3次スプライン回帰が適用され、bs = \"cc\"では説明変数の両端のポイントが接続される場合(例えば月データの分析)に使える3次スプライン回帰である。 さて、最初のモデル(M3_7)の説明に戻ろう。モデルの予測値はfitted()関数で求めることができる。 head(fitted(M3_7), n = 10) ## [1] 59.75170 56.23345 52.72462 49.93488 46.49023 43.12257 39.86806 36.76435 ## [9] 34.41493 31.67422 パラメータ(回帰係数)の推定値は以下のように求められる。 coef(M3_7) ## (Intercept) s(Depth).1 s(Depth).2 s(Depth).3 s(Depth).4 s(Depth).5 ## 16.74551 -46.31747 -56.49162 -34.94561 -43.55188 -38.29367 ## s(Depth).6 s(Depth).7 s(Depth).8 s(Depth).9 ## 38.83802 -31.02217 -83.19786 -55.07702 predict()関数でtype = \"lpmatrix\"とすると、モデルの説明変数を含む行列を得ることができる。 X &lt;- predict(M3_7, type = &quot;lpmatrix&quot;) よって、モデルの予測値は以下のように求めることができる。 mu &lt;- X %*% coef(M3_7) また、予測値の分散共分散行列は\\(\\mathbf{X} \\times cov(\\mathbf{\\beta}) \\times \\mathbf{X^t}\\)で求めることができるので(第1章参照)、以下のように求められる、 cov_mu &lt;- X %*% M3_7$Vp %*% t(X) 3.16 The danger of using GAM これまで様々な方法でsmootherを推定してきたが、その多くではスケール化された水深が0.3から0.4のあたりで光源の数がわずかに増加していると推定された。しかし、これまではサンプリングを行ったステーションの影響は無視して分析を行ってきた(第3.1節も参照)。推定されたsmotherのパターンがこうした影響を受けていることはないだろうか。 まず、モデルの診断を行う。図3.17はモデルの予測値と残差の関係をプロットしたものである。明確なパターンがあり、等分散性の仮定が満たされていないことが分かる。 data.frame(fit = fitted(M3_7), resid = resid(M3_7)) %&gt;% ggplot(aes(x = fit, y = resid))+ geom_point()+ geom_hline(yintercept = 0, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Residuals&quot;, x = &quot;Fitted values&quot;) 図3.17: Residuals plotted versus fitted values for the GAM using only depth as smoother. 図3.18は、ステーションごとの残差をプロットしたものである。ステーションごとにパターン(0以上が多い/0以下が多いなど)があることが分かる。 data.frame(resid = resid(M3_7), Station = as.factor(BL$Station)) %&gt;% ggplot(aes(x = Station, y = resid))+ geom_boxplot()+ geom_hline(yintercept = 0, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Residuals&quot;) 図3.18: Residuals plotted versus station for the GAM using only depth as smoother. また、水深と残差の関係をステーションごとにプロットすると(図3.19)、ステーションごとに違う傾向があることが分かる。以上より、smootherとして\\(f(Depth_i)\\)だけを考えることが適当ではないことが示唆された。 data.frame(resid = resid(M3_7), Station = BL$Station, Depth = BL$Depth) %&gt;% ggplot(aes(x = Depth, y = resid))+ geom_point(alpha = 0.5, shape = 1)+ facet_rep_wrap(~Station, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ labs(y = &quot;Residuals&quot;) 図3.19: Residuals plotted versus depth for each station for the GAM using only depth as smoother. この問題を解決する方法としては、各ステーションに異なるsmootherを適用することなどがあるが、数が多すぎる。他の方法としては、渦巻き(Eddy)の有無によってsmootherを変えるというものである。 図3.20は、渦巻きの有無ごとに水深と光源の数の関係を描いた図である。明らかに渦巻きの有無ごとに傾きが異なっていることが分かる。 BL %&gt;% mutate(Station = as.factor(Station)) %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(aes(color = Station))+ facet_rep_wrap(~Eddy)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0)) 図3.20: Source s profiles plotted versus scaled depth for absence (left) and presence (right) of eddies. Each line corresponds to a station. そこで、以下の渦巻きの有無ごとにsmootherが異なるモデルを考える。なお,\\(j = 1,2\\)で\\(f_1(Depth_i)\\)は渦巻きがないときのsmootherである。Stationは説明変数に入れた。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + f_j(Depth_i) + Station_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] Rでは、第2.6節で見たようにby =とすることで渦巻きの有無ごとのsmootherを推定できる。以下では、渦巻きの有無ごとにsmootherを推定する場合としない場合のモデルを作成する。 M3_8 &lt;- gam(Sources ~ s(Depth) + factor(Station), data = BL) M3_9 &lt;- gam(Sources ~ s(Depth, by = factor(Eddy)) + factor(Station), data = BL) AICを比較すると、渦巻きの有無ごとにsmootherを推定したモデルの方がよいモデルであることが分かる。 AIC(M3_8, M3_9) 推定された渦巻きの有無ごとのsmootherを図示したのが図3.21である。両者が異なるパターンを示していることが分かる。渦巻きがあり(Eddy = 1)のときに水深が深いところで95%信頼区間が狭くなっているのは、そのあたりのデータが少ないからである。 ## M3_8 smooth_estimates(M3_9) %&gt;% add_confint() %&gt;% rename(Eddy = 7) %&gt;% mutate(Eddy = str_c(&quot;Eddy = &quot;, Eddy)) %&gt;% ggplot(aes(x = Depth, y = est))+ geom_line(aes(), linewidth = 1)+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0, color = &quot;black&quot;, linetype = &quot;dashed&quot;, linewidth = 0.7)+ facet_rep_wrap(~Eddy, repeat.tick.labels = TRUE)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0)) 図3.21: Estimated smoothers for depth for absence (left) and presence (right) of eddies. 他の方法はランダム効果を用いる方法であるが、これについては別の本で解説を行っている(Zuur et al. 2014)。 3.17 Additive models with multiple smoothers これまでのモデルは、一つの変数のsmootherのみを用いていた。これを二つ以上の変数のsmootherに拡張するのはシンプルである。 ここでは、蛍光物質(クロロフィル)の量(mg/L)(flcugl)のsmootherも加えたモデルを考える。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + f_1(Depth_i) + f_2(flcugl_i) + Station_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 図3.22はDepthとflcugl、flcuglとSourcesの関係をプロットしたものである。flcuglには一つだけ外れ値があるので、以後の分析ではこれは除く。 BL %&gt;% ggplot(aes(x = Depth, y = flcugl))+ geom_point(shape = 1, alpha = 0.7)+ theme_bw()+ theme(aspect.ratio = 1) -&gt; p1 BL %&gt;% ggplot(aes(x =flcugl, y = Sources))+ geom_point(shape = 1, alpha = 0.7)+ theme_bw()+ theme(aspect.ratio = 1) -&gt; p2 p1 + p2 図3.22: Scatterplot of flcugl versus depth (left) and sources versus flcugl (right). これまでと同様に、それぞれのsmootherは以下のように書ける。それぞれのsmootherについてノットの数と位置を決定する必要があるが、これは同じでも違くてもよい。また、それぞれのsmootherについて基底(\\(b_{1j}(Depth_i),b_{2j}(flcugl_i)\\))を決める必要がある。例えば、\\(Depth\\)については線形スプライン回帰を適用するが、\\(flcugl\\)については3次平滑化スプラインを適用する、ということもできる。 \\[ \\begin{aligned} f_1(Depth_i) &amp;= \\sum_{j =1}^K \\beta_{1j} \\times b_{1j}(Depth_i)\\\\ f_2(flcugl_i) &amp;= \\sum_{j =1}^K \\beta_{2j} \\times b_{2j}(flcugl_i)\\\\ \\end{aligned} \\] モデル全体の切片\\(\\alpha\\)があるので、各smootherの切片は除いて0の周りで周辺化する。各smootherのパラメータ\\(\\lambda_1, \\lambda_2\\)は交差検証によって決定され、自由度もそれに基づいて別々に計算される。 Rでは以下のように実行する。ここでは、両方のsmootherに3次平滑化スプラインを用いる。 BL2 &lt;- BL %&gt;% filter(flcugl &lt; 0.03) M3_10 &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;) + s(flcugl, bs = &quot;cr&quot;) + factor(Station), data = BL2) 推定された各smootherは以下の通り(図3.23)。flcuglのsmootherはゆっくり増加したのち、急激に減少していることが分かる。Depthの方はほとんど変わらない。 draw(M3_10) 図3.23: Estimated cubic smoothing splines for Depth and fclugl. モデルの要約は以下の通り。いずれのsmootherも有意であるが、このモデルでは渦巻きの有無の効果を無視している。flcuglの効果も渦巻きの有無によって異なるかもしれない。 summary(M3_10) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Sources ~ s(Depth, bs = &quot;cr&quot;) + s(flcugl, bs = &quot;cr&quot;) + factor(Station) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.8401 0.8599 26.562 &lt; 2e-16 *** ## factor(Station)53 -2.9374 1.6827 -1.746 0.081177 . ## factor(Station)54 -7.8883 1.1299 -6.981 5.27e-12 *** ## factor(Station)56 7.3880 1.3155 5.616 2.52e-08 *** ## factor(Station)58 -0.6668 1.1631 -0.573 0.566615 ## factor(Station)60 2.8120 1.6417 1.713 0.087039 . ## factor(Station)62 -5.2367 1.3584 -3.855 0.000123 *** ## factor(Station)64 -7.1549 1.1269 -6.349 3.25e-10 *** ## factor(Station)66 -10.3260 1.1471 -9.002 &lt; 2e-16 *** ## factor(Station)68 -11.1717 1.2177 -9.175 &lt; 2e-16 *** ## factor(Station)70 -6.7784 1.2997 -5.216 2.22e-07 *** ## factor(Station)72 -11.4385 1.1723 -9.757 &lt; 2e-16 *** ## factor(Station)74 -10.2104 1.1278 -9.053 &lt; 2e-16 *** ## factor(Station)76 -13.6073 1.5054 -9.039 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Depth) 8.567 8.937 214.603 &lt; 2e-16 *** ## s(flcugl) 5.338 6.529 5.856 3.45e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.791 Deviance explained = 79.7% ## GCV = 57.163 Scale est. = 55.641 n = 1048 そこで、以下の7つのモデルを作成してAICによるモデル比較を行う。交互作用を考慮する2次元のsmootherがあるモデル(M3_11_hとM3_11_i)については第6章で触れる。 ## Depthのみ、Eddyによる違いなし M3_11_a &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;) + factor(Station), data = BL2) ## flcuglのみ、Eddyによる違いなし M3_11_b &lt;- gam(Sources ~ s(flcugl, bs = &quot;cr&quot;) + factor(Station), data = BL2) ## Depthとflcugl。DepthのみEddyによる違いあり M3_11_c &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;, by = factor(Eddy)) + s(flcugl, bs = &quot;cr&quot;) + factor(Station), data = BL2) ## Depthとflcugl。flcuglのみEddyによる違いあり M3_11_d &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;) + s(flcugl, bs = &quot;cr&quot;, by = factor(Eddy)) + factor(Station), data = BL2) ## Depthとflcugl、両方がEddyによって異なる M3_11_e &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;, by = factor(Eddy)) + s(flcugl, bs = &quot;cr&quot;, by = factor(Eddy)) + factor(Station), data = BL2) ## DepthのみでEddyによって異なる。flcuglは普通の説明変数として入れる。 M3_11_f &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;, by = factor(Eddy)) + flcugl + factor(Station), data = BL2) ## DepthのみでEddyによって異なる。flcuglとEddyの交互作用を入れる。 M3_11_g &lt;- gam(Sources ~ s(Depth, bs = &quot;cr&quot;, by = factor(Eddy)) + flcugl*factor(Eddy) + factor(Station), data = BL2) ## Depthとflcuglの交互作用を考える。Eddyによる傾きの違いなし。 M3_11_h &lt;- gam(Sources ~ te(Depth, flcugl) + factor(Station), data = BL2) ## Depthとflcuglの交互作用を考える。Eddyによる傾きの違いあり。 M3_11_i &lt;- gam(Sources ~ te(Depth, flcugl, by = factor(Eddy)) + factor(Station), data = BL2) モデル比較の結果、どちらのsmootherも渦巻きの有無によって異なるM3_11_eが最も良いよう。 AIC(M3_10, M3_11_a, M3_11_b,M3_11_c,M3_11_d,M3_11_e,M3_11_f,M3_11_g,M3_11_h,M3_11_i) %&gt;% data.frame() %&gt;% arrange(AIC) M3_11_eのsmootherを図示すると以下のようになる(図3.24)。 smooth_estimates(M3_11_e) %&gt;% add_confint() %&gt;% pivot_longer(cols = c(Depth, flcugl)) %&gt;% drop_na(value) %&gt;% rename(Eddy = 6) %&gt;% mutate(Eddy = str_c(&quot;Eddy = &quot;, Eddy)) %&gt;% ggplot(aes(x = value, y = est))+ geom_line()+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0, color = &quot;grey29&quot;, linewidth = 0.9, linetype = &quot;dashed&quot;)+ labs(x = &quot;x&quot;, y = &quot;&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_grid(Eddy~name, scales = &quot;free_x&quot;, repeat.tick.labels = TRUE) 図3.24: Estimated smoothers for mM3_11_e. References "],["Chapter4.html", "4 Introducing generalized additive models using deep-sea fishery data 4.1 From additive models to generalized additive models 4.2 Review of GLM 4.3 Start with GLM or GAM ? 4.4 Results of Poisson and negative binomial GLM 4.5 Using offset in a GLM or GAM 4.6 Poisson GLM with offset 4.7 Negative binomial GLM with offset 4.8 Poisson and negative binomial GAM with offset 4.9 What to present in paper", " 4 Introducing generalized additive models using deep-sea fishery data 4.1 From additive models to generalized additive models 前章までは目的変数の分布として正規分布のみを考えていた。本章では、こうした通常の加法モデル(additive model: AM)の目的変数の分布を正規分布以外に拡張した一般化加法モデル(generalized additive model)を解説する。GAMは一般化線形モデル(GLM)で1つ以上の変数がsmoother関数としてモデル化されたものである。 使用するsmootherは前章までと基本的に同じだが、罰則付きスプラインの最適化基準や交差検証の仕方、自由度の計算方法などいくつかの異なる点もある。 4.2 Review of GLM まずはGAMの解説に移る前にGLMについておさらいする。より詳細な説明については他の書籍(Zuur 2009; 久保 2012; 松浦 2012; 馬場 2015; Dunn and Smyth 2018)を参照。 第2で行った漁業データ(Bailey et al. 2009)に対するモデリングでは、分散の不均等性に対処するために変数変換を行ったり、特殊な分散構造をモデルに取り入れたりした。GLMはこうしたことをせずに分散の不均等性に対処することができる。また、第2章ではデータの非線形性に対処する際に変数変換や多項式回帰を適用したりした。GAMはGLMと同様に分散の不均等性に対処しつつ、こうしたデータの非線形性にも対処できる。 GLMやGAMは以下の3つの要素からなる。 目的変数の分布。これによって目的変数の平均や分散が決まる。 共変量(説明変数)の関数(= 予測関数) 目的変数の平均と共変量(説明変数)をつなぐもの(= リンク関数) 4.2.1 Distribution GLMでは、正規分布に加えてポワソン分布や負の二項分布、二項分布、ガンマ分布、逆正規分布などが目的変数の分布として使われる。ポワソン分布と負の二項分布は0以上のカウントデータに対して、二項分布は二値データや0から1の間をとる割合データに対して、ガンマ分布は正の連続値に対して、正規分布は全ての範囲の連続値に対して用いられる。また、あまり一般的ではないが逆正規分布は正の連続値に対して用いられる。これら6つがglm関数のfamily =として使用できる通常の分布である。 それでは、漁業データにはどの分布を当てはめるべきだろうか?魚の密度(Dens)は0以上の整数値である。0をとる可能性があるということはガンマ分布は適当ではない。 魚の密度(Dens)は魚の総捕獲量(TotAbund)を探索面積(SweptArea)で割ったものである。モデルでは、魚の総捕獲量を目的変数として用いることもできる。この場合、捕獲量は0以上の整数になるのでポワソン分布か負の二項分布が適当である。実際の分析では探索努力(具体的には探索面積)を考慮する必要があるが、ここではひとまず置いておく。 総捕獲量と探索面積のdotplot(第1.4.2節参照)を示したのが図4.1である。 fish %&gt;% mutate(sample_number = 1:n()) %&gt;% select(sample_number, SweptArea, TotAbund) %&gt;% pivot_longer(cols=c(2,3)) %&gt;% ggplot(aes(x = value, y= sample_number))+ geom_point(shape = 1, size = 2)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ labs(x = &quot;&quot;, y = &quot;Order of data&quot;) 図4.1: Dotplot of Swept Area and TotAbund また、総捕獲量と探索面積それぞれと水深の関係をプロットしたのが図4.2である。 fish %&gt;% select(MeanDepth, SweptArea, TotAbund) %&gt;% pivot_longer(cols=c(2,3)) %&gt;% ggplot(aes(x = MeanDepth, y= value))+ geom_point(shape = 1, size = 2)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ labs(x = &quot;mean depth&quot;, y = &quot;&quot;) 図4.2: Scatterplot of swept area and total abundance versus mean depth. さて、もし総捕獲量にポワソン分布を当てはめるとき、以下のように書ける(ポワソン分布では、期待値と分散が同じ値になる)。なお、\\(TA_i\\)はi番目のデータの総捕獲量を表す。\\(E()\\)は期待値を、\\(var()\\)は分散を表す。 \\[ \\begin{aligned} TA_i &amp;\\sim Poisson(\\mu_i)\\\\ E(TA_i) &amp;= \\mu_i\\\\ var(TA_i) &amp;= \\mu_i \\end{aligned} \\] 総捕獲量を負の二項分布に当てはめるとすれば、以下のように書ける。負の二項分布ではパラメータ\\(k\\)(\\(= 1/ \\alpha\\))を組み込むことでポワソン分布よりも大きな分散をとることを可能にしている。\\(k\\)が大きくなるほど負の二項分布はポワソン分布に近づく。多くの文献では\\(\\alpha\\)が用いられているが、Rのglm.nb関数では\\(k\\)が用いられている(thetaとして出力される)。 \\[ \\begin{aligned} TA_i &amp;\\sim NB(\\mu_i, k)\\\\ E(TA_i) &amp;= \\mu_i\\\\ var(TA_i) &amp;= \\mu_i + \\frac{\\mu_i^2}{k} = \\mu_i + \\alpha \\times \\mu_i^2 \\end{aligned} \\] 4.2.2 Predictor function 目的変数の分布を決定したら、どの変数を説明変数として含めるかを決め、GAMの場合はどの変数がsmootherとして用いられるかを決める。第2章では、次のような線形回帰モデルを考えた。GLMでも同じような予測関数を用いることができる。 \\[ \\eta_i = \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i \\] GAMの場合は、平滑化関数(smoother)を組み込むことができる。 \\[ \\eta_i = \\alpha + f(Depth_i) + \\beta_1 \\times Period_i \\] 期間によって異なるsmootherを適用することもできる。 4.2.3 Link function リンク関数は、目的変数の期待値と予測関数をつなぐものである。リンク関数を様々に変化させることで、目的変数の期待値がある範囲に収まるように変化させる。 例えば、例えば、ポワソン分布や負の二項分布の期待値は必ず正にならなくてはいけないので、これらのモデルではログ関数がリンク関数に用いられる。 \\[ log(\\mu_i) = \\eta_i \\] 両辺に指数変換を施すと以下のようになる。これからわかるように、リンク関数にログ関数を用いることで期待値(\\(\\mu_i\\))が必ず正の値をとるようになる。 \\[ \\mu_i = e^{\\eta_i} \\] 正規分布では恒等関数(\\(\\mu_i = \\eta_i\\))が、二項分布ではロジット関数がリンク関数に用いられるのが一般的である。ロジット関数をリンク関数にすることで、目的変数の期待値は0から1の範囲に収まるようになる。ロジット関数は以下の通り。 \\[ log(\\frac{\\mu_i}{1-\\mu_i}) = \\eta_i \\] 4.3 Start with GLM or GAM ? それでは、最初の分析としてはGLMとGAMのどちらを適用すべきだろうか。もし、GLMを適用したモデルの残差と説明変数の間に非線形の関係が明確にみられるなら、GAMを適用するのは理にかなっている。また、事前にデータ探索を行ったときに変数間に非線形なパターンが見られたらまずGAMを適用し、変数間の関係が線形か非線形かを見てみるということもできる。もし線形な関係が見られたら、そこからGLMを適用することもできる。 4.4 Results of Poisson and negative binomial GLM 本章では、まずGLMを適用するところから始める。まずはポワソン分布のGLMを適用する。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim Poisson(\\mu_i)\\\\ E(TA_i) &amp;= var(TA_i) = \\mu_i \\\\ log(\\mu_i) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i \\end{aligned} \\tag{4.1} \\] Rでは以下のように実行する。 fish &lt;- mutate(fish, fPeriod = factor(Period)) M4_1 &lt;- glm(TotAbund ~ MeanDepth*fPeriod, family = poisson(link = &quot;log&quot;), data = fish) モデルを実行したら、過分散(overdispersion)の確認を行う必要がある。ポワソン分布は期待値と分散が一致すると仮定しているが、この前提が満たされていない可能性がある。過分散のチェックを行うためには、ピアソン残差(\\(E_i\\))を計算する必要がある。期待値(\\(E(TA_i)\\))と分散(\\(var(TA_i)\\))は式(4.1)から得られる。 \\[ E_i = \\frac{TA_i - E(TA_i)}{\\sqrt{var(TA_i)}} \\] 過分散は以下のdispersion parameter(\\(\\phi\\))を計算することで調べることができる。なお、\\(N\\)はサンプル数、\\(k\\)はパラメータ数である。もし\\(\\phi\\)が1を超えていれば過分散が生じており、1以下であれば過少分散である。通常、\\(\\phi = 1.5\\)くらいまでであれば問題ないと判断される(大東 2010)。 \\[ \\phi = \\frac{\\sum_{i=1}^k E_i}{N - k} \\] 今回のモデルでは、以下のように\\(\\phi = 110.5\\)となり、明確な過分散が存在する。よってモデルがデータにうまく当てはまっていないことが分かる。過分散が生じる原因には、(1)モデルに入れるべき共変量や交互作用が入っていない、(2)外れ値がある、(3)リンク関数がデータに合っていない、(4)非線形なパターンがモデルで説明できていない、(5)ゼロ過剰がある、(6)ポワソン分布で仮定されるよりデータの分散が大きい、などがある。 E &lt;- resid(M4_1, type = &quot;pearson&quot;) phi &lt;- sum(E^2)/(nrow(fish) - length(coef(M4_1))) phi ## [1] 110.5165 過分散の原因はモデルの結果を診断することで見つけることができる。図4.3はピアソン残差と水深の関係を期間ごとにプロットしたものである。水深の深いところでピアソン残差が0以下になる点が多いなど非線形なパターンがみられるので、ポワソン分布のGAMを適用した方がいいかもしれない。しかし、パターンはそこまで明確ではないので、GAMを適用するだけでは過分散の問題が解決されない可能性がある。総捕獲量にそもそも大きなばらつきがあることを考えると、負の二項分布を適用した方がいいだろう。よって、過分散とデータの非線形性という2つの問題に対処するため、負の二項分布のGAMを適用したほうがよいということになる。 data.frame(resid = resid(M4_1, type = &quot;pearson&quot;), depth = fish$MeanDepth, Period = fish$fPeriod) %&gt;% ggplot(aes(x = depth, y = resid))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(yintercept = 0)+ theme_bw()+ scale_fill_manual(values = c(&quot;white&quot;, &quot;black&quot;))+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = &quot;Pearson residuals&quot;) 図4.3: Pearson residuals obtained by the Poisson GLM plotted versus sampling depth. Filled circles are observations from the second sampling period. GAMを適用する前に、まずは負の二項分布のGLMを実行してみる。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim NB(\\mu_i, k)\\\\ E(TA_i) &amp;= \\mu_i , \\; var(TA_i) = \\mu_i + \\frac{\\mu_i^2}{k} \\\\ log(\\mu_i) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i \\end{aligned} \\tag{4.2} \\] RではMASSパッケージのglm.nb()関数で実行できる。 M4_2 &lt;- glm.nb(TotAbund ~ MeanDepth*fPeriod, data = fish) \\(\\phi\\)の推定値はほとんど0であり、過分散の問題が解決されたことが分かる。 E2 &lt;- resid(M4_2, type = &quot;pearson&quot;) phi2 &lt;- sum(E2^2)/(nrow(fish) - length(coef(M4_2))) phi2 ## [1] 0.9815648 図4.4はピアソン残差と水深の関係を期間ごとにプロットしたものである。ポワソン分布のGLMのときに存在したパターンはかなり解消されていることが分かる。 data.frame(resid = resid(M4_2, type = &quot;pearson&quot;), depth = fish$MeanDepth, Period = fish$fPeriod) %&gt;% ggplot(aes(x = depth, y = resid))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(yintercept = 0)+ theme_bw()+ scale_fill_manual(values = c(&quot;white&quot;, &quot;black&quot;))+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = &quot;Pearson residuals&quot;) 図4.4: Pearson residuals obtained by the negative Binomial GLM plotted versus sampling depth. Filled circles are observations from the second sampling period. ただし、ここまでいずれのモデルにおいても探索面積の影響を考慮することはできていなかった。次節ではこれに対処する方法について学ぶ。 4.5 Using offset in a GLM or GAM ポワソン分布は、ある一定の時間\\(\\lambda\\)の間に事象が起こる回数\\(y\\)を以下のように表すことができる。もし\\(\\lambda = 1\\)ならば、先ほどのポワソン分布と一致する。\\(\\lambda\\)あたりに発生する事象の回数の期待値は\\(\\mu \\times \\lambda\\)である。すなわち、\\(\\mu\\)は単位時間あたりに発生する事象の回数の期待値を表す。 \\[ P(Y = y|\\mu, \\lambda) = \\frac{e^{-\\lambda \\times \\mu} \\times (\\lambda \\times \\mu)^y}{y!} \\] 漁業データにおいても同様に、探索面積\\(SA_i\\)あたりの漁獲量\\(TA_i\\)がポワソン分布に従うとき、以下のように書くことができる。 \\[ P(TA_i = y_i|\\mu_i, SA_i) = \\frac{e^{-SA_i \\times \\mu_i} \\times (SA_i \\times \\mu_i)^{y_{i}}}{y_i!} \\] このとき、単位面積当たりの漁獲絵用の期待値は\\(E(\\frac{TA_i}{SA_i}) = \\frac{\\mu_i}{SA_i}\\)となる。ポワソン分布や負の二項分布モデルを考えるとき、ログ関数をリンク関数とし以下のように書くことができる。ここで、\\(log(SA_i)\\)をオフセット項という。ポワソン分布や負の二項分布モデルでもこのようにオフセット項を用いることで、割り算データを扱うことができるようになる。 \\[ \\begin{aligned} log(\\frac{\\mu_i}{SA_i}) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i \\Leftrightarrow \\\\ log(\\mu_i) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i + log(SA_i) \\end{aligned} \\] ここで、探索面積をオフセット項に含めるということは、探索面積を2倍にすれば漁獲量も2倍になると仮定しているということには注意が必要である。もしこれが成り立たないのであれば、探索面積を共変量(説明変数)としてモデルに含める必要がある。今回は単純に単位面積当たりの漁獲量(= 密度)を考えているので、オフセット項を使用するということで問題ない。 4.6 Poisson GLM with offset それでは、まずはオフセット項を含むポワソン分布のGLMを考えていく。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim Poisson(\\mu_i)\\\\ E(TA_i) &amp;= var(TA_i) = \\mu_i \\\\ log(\\mu_i) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i + log(SA_i) \\end{aligned} \\tag{4.3} \\] Rでは以下のように実行する。 M4_3 &lt;- glm(TotAbund ~ MeanDepth*fPeriod + offset(log(SweptArea)), family = poisson(link = &quot;log&quot;), data = fish) このモデルはパラメータ\\(\\phi\\)が121.7もあり、オフセット項を含めても過分散の問題は解決しないことが分かる。 E3 &lt;- resid(M4_3, type = &quot;pearson&quot;) phi3 &lt;- sum(E3^2)/(nrow(fish) - length(coef(M4_3))) phi3 ## [1] 121.6988 4.7 Negative binomial GLM with offset そこで、オフセット項を含む負の二項分布モデルを考える。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim NB(\\mu_i, k)\\\\ E(TA_i) &amp;= \\mu_i , \\; var(TA_i) = \\mu_i + \\frac{\\mu_i^2}{k} \\\\ log(\\mu_i) &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Period_i + \\beta_3 \\times Depth_i \\times Period_i + log(SA_i) \\end{aligned} \\tag{4.4} \\] Rでは以下のように実行する。 M4_4 &lt;- glm.nb(TotAbund ~ MeanDepth*fPeriod + offset(log(SweptArea)), data = fish) \\(\\phi\\)はほぼ1となり過分散の問題は生じていないことが分かる。 E4 &lt;- resid(M4_4, type = &quot;pearson&quot;) phi4 &lt;- sum(E4^2)/(nrow(fish) - length(coef(M4_4))) phi4 ## [1] 0.9972456 ただし、ピアソン残差と水深の関係を期間ごとにプロットした図4.5をみると、わずかに非線形なパターンが見て取れる(とくに期間2)。よって、GAMを適用した方が適切だと考えられる。 data.frame(resid = resid(M4_4, type = &quot;pearson&quot;), depth = fish$MeanDepth, Period = fish$fPeriod) %&gt;% ggplot(aes(x = depth, y = resid))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(yintercept = 0)+ theme_bw()+ scale_fill_manual(values = c(&quot;white&quot;, &quot;black&quot;))+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = &quot;Pearson residuals&quot;) 図4.5: Pearson residuals obtained by the negative Binomial GLM with offset plotted versus sampling depth. Filled circles are observations from the second sampling period. 4.8 Poisson and negative binomial GAM with offset まずはポワソン分布のGAMを適用する。smootherは第2章でやったように期間ごとに分けて推定する。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim Poisson(\\mu_i)\\\\ E(TA_i) &amp;= var(TA_i) = \\mu_i \\\\ log(\\mu_i) &amp;= \\alpha + f_1(Depth_i) + f_2(Depth_i) + \\beta_1 \\times Period_i + log(SA_i) \\end{aligned} \\tag{4.5} \\] Rでは以下のように実行する。 M4_5 &lt;- gam(TotAbund ~ s(MeanDepth, by = fPeriod) + fPeriod + offset(log(SweptArea)), family = poisson(link = &quot;log&quot;), data = fish) 過分散はGLMと同じように調べられる。\\(\\phi\\)はGLM同様に大きいので(100.6)、やはり負の二項分布を適用した方がよさそう。 E5 &lt;- resid(M4_5, type = &quot;pearson&quot;) phi5 &lt;- sum(E5^2)/(nrow(fish) - length(coef(M4_5))) phi5 ## [1] 100.6062 結果に出てくる2つの自由度(edfとRef.df)は自由度の定義の違いによるもの。\\(\\chi^2\\)検定が残差逸脱度を利用してsmootherの有意性を判定している。smootherの自由度は一般化交差検証(GCV)スコアを用いて決定される。 summary(M4_5) ## ## Family: poisson ## Link function: log ## ## Formula: ## TotAbund ~ s(MeanDepth, by = fPeriod) + fPeriod + offset(log(SweptArea)) ## ## Parametric coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.82135 0.01003 -580.39 &lt;2e-16 *** ## fPeriod2 -0.49759 0.02043 -24.36 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df Chi.sq p-value ## s(MeanDepth):fPeriod1 8.887 8.995 13849 &lt;2e-16 *** ## s(MeanDepth):fPeriod2 8.891 8.995 4697 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.35 Deviance explained = 73.7% ## UBRE = 81.8 Scale est. = 1 n = 147 推定されたsmootherは以下の通り(図??)。 draw(M4_5) 続いて、負の二項分布のGAMを実行する。モデル式は以下の通り。 \\[ \\begin{aligned} TA_i &amp;\\sim NB(\\mu_i, k)\\\\ E(TA_i) &amp;= \\mu_i , \\; var(TA_i) = \\mu_i + \\frac{\\mu_i^2}{k} \\\\ log(\\mu_i) &amp;= \\alpha + f_1(Depth_i) + f_2(Depth_i) + \\beta_1 \\times Period_i + log(SA_i) \\end{aligned} \\tag{4.6} \\] Rでは以下のように実行する。mgcvパッケージで負の二項分布をフィットさせる方法は2つある(performance iterationとouter iteration)。詳しくは?negbinで検索。performance iterationを利用する場合はfamily = negbin()、outer iterationを利用する場合はfamily = nb()を使用するよう。 前者ではまずsmootherのパラメータが推定され、\\(\\phi\\)が1になるように\\(k\\)(Rではtheta)が推定される。この場合、一方で、後者は\\(k\\)がsmootherのパラメータと一緒に最尤推定法または制限付き最尤推定法で推定される。 今回は後者の方法でthetaを推定する。Rでは以下の通り実行できる4。 M4_6 &lt;- gam(TotAbund ~ s(MeanDepth, by = fPeriod) + fPeriod + offset(log(SweptArea)), family = nb(link = &quot;log&quot;), data = fish) モデルの結果は以下の通り。\\(k = 2.048\\)と推定され、モデルはデータのばらつきの69.4%を説明している。 summary(M4_6) ## ## Family: Negative Binomial(2.048) ## Link function: log ## ## Formula: ## TotAbund ~ s(MeanDepth, by = fPeriod) + fPeriod + offset(log(SweptArea)) ## ## Parametric coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.77295 0.07181 -80.393 &lt; 2e-16 *** ## fPeriod2 -0.45494 0.12417 -3.664 0.000249 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df Chi.sq p-value ## s(MeanDepth):fPeriod1 2.810 3.493 324.9 &lt;2e-16 *** ## s(MeanDepth):fPeriod2 3.019 3.739 158.4 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.318 Deviance explained = 69.4% ## -REML = 880.49 Scale est. = 1 n = 147 \\(\\phi\\)は1.10であり、モデルに過分散の問題はないよう。 E6 &lt;- resid(M4_6, type = &quot;pearson&quot;) phi6 &lt;- sum(E6^2)/(nrow(fish) - length(coef(M4_6))) phi6 ## [1] 1.100135 smootherを期間ごとに分ける必要があるかを調べるため、期間ごとにsmootherを分けないモデルを作成して先ほどのモデルと比較する。\\(k\\)(theta)の値を固定する必要があるため、 M4_7 &lt;- gam(TotAbund ~ s(MeanDepth) + fPeriod + offset(log(SweptArea)), family = nb(link = &quot;log&quot;, theta = 2.048), data = fish) AICでモデル比較をしたところ、期間ごとにsmootherを分ける方がAICが低いことが分かる。 AIC(M4_6, M4_7) M4_6によって推定されたパラメータを基にモデル式を描くと以下のようになる。 \\[ \\begin{aligned} TA_i &amp;\\sim NB(\\mu_i, 2.048)\\\\ E(TA_i) &amp;= \\mu_i , \\; var(TA_i) = \\mu_i + \\frac{\\mu_i^2}{2.048} \\\\ Period1: log(\\mu_i) &amp;= -5.77 + f_1(Depth_i) + log(SA_i)\\\\ Period2: log(\\mu_i) &amp;= -5.77 -0.45 + f_2(Depth_i) + log(SA_i) \\end{aligned} \\tag{4.7} \\] 期間ごとに推定されたsmootherを描くと図4.6のようになる。 draw(M4_6) 図4.6: Estimated smoother for depth 図4.7はモデルから推定された回帰曲線を実際のデータ上に描いたものである。 nd_M4 &lt;- crossing(MeanDepth = seq(min(fish$MeanDepth), max(fish$MeanDepth), length = 100), fPeriod = factor(c(1,2))) %&gt;% mutate(SweptArea = ifelse(fPeriod == &quot;1&quot;, mean(fish %&gt;% filter(fPeriod == &quot;1&quot;) %&gt;% .$SweptArea), mean(fish %&gt;% filter(fPeriod == &quot;2&quot;) %&gt;% .$SweptArea))) fitted_values(M4_6, data = nd_M4) %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line(aes(linetype = fPeriod))+ geom_ribbon(aes(ymin = lower, ymax = upper, fill = fPeriod), alpha = 0.3)+ scale_fill_manual(values = c(&quot;grey21&quot;,&quot;grey65&quot;))+ new_scale_fill()+ geom_point(data = fish %&gt;% mutate(fPriod = factor(Period)), aes(y = TotAbund, fill = fPeriod), shape = 21)+ scale_fill_manual(values = c(&quot;black&quot;,&quot;white&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;, &quot;dashed&quot;))+ labs(y = &quot;Total abundance&quot;, x = &quot;Mean depth (m)&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ guides(fill = guide_legend(override.aes = list(size = 3))) 図4.7: Fitted values for the negative binomial GAM with offset variable. 最後にモデル診断を行う。ピアソン残差とモデルから推定される予測値、水深、期間の関係とピアソン残差のヒストグラムをプロットしたのが図4.8である。明確なパターンは見られないよう。 data.frame(resid = resid(M4_6, type = &quot;pearson&quot;), MeanDepth = fish$MeanDepth, fitted = fitted(M4_6), Period = fish$fPeriod) -&gt; dat_resid dat_resid %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 21, aes(fill = Period))+ scale_fill_manual(values = c(&quot;black&quot;,&quot;white&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Pearson residuals&quot;, title =&quot;A&quot;) -&gt; p1 dat_resid %&gt;% ggplot(aes(x = MeanDepth, y = resid))+ geom_point(shape = 21, aes(fill = Period))+ scale_fill_manual(values = c(&quot;black&quot;,&quot;white&quot;))+ geom_hline(yintercept = 0, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean depth (m)&quot;, y = &quot;Pearson residuals&quot;, title =&quot;B&quot;) -&gt; p2 dat_resid %&gt;% ggplot(aes(x = Period, y = resid))+ geom_boxplot(outlier.shape = 1)+ stat_boxplot(geom = &quot;errorbar&quot;, width = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Period&quot;, y = &quot;Pearson residuals&quot;, title =&quot;C&quot;) -&gt; p3 dat_resid %&gt;% ggplot(aes(x = resid))+ geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Pearson residuals&quot;, y = &quot;Frequency&quot;, title =&quot;D&quot;) -&gt; p4 (p1 + p2)/(p3 + p4) 図4.8: A: Pearson residuals versus fitted values. B: Pearson residuals versus mean depth. C: Pearson residuals versus period. D: Histogram of the Pearson residuals. QQプロットもおおむねよく当てはまっている? qq_plot(M4_6, type = &quot;pearson&quot;) 4.9 What to present in paper 第2.10を参照。 References "],["Chapter5.html", "5 Additive modelling applied on stable isotope ratios of ocean squid 5.1 Stable isotope ratios of squid 5.2 The variables 5.3 Data exploration 5.4 Brain storming 5.5 Applying the multiple linear regression model 5.6 Applying an additive model 5.7 Testing linearity versus non-linearity 5.8 Consequence of ignoring collinearity in the additive model 5.9 Discussion 5.10 What to present in a paper", " 5 Additive modelling applied on stable isotope ratios of ocean squid 5.1 Stable isotope ratios of squid 同位体(isotope)とは、同じ原子であるが異なる中性子数を持つものを指す。そのうち、原子核が安定していて放射能を持たないものを安定同位体(stable isotope)という。例えば、炭素には2つの安定同位体(\\(^{12}\\rm{C}\\)と\\(^{13}\\rm{C}\\))が存在する。 同位体は同じ化学的性質を持つが、中性子の数が異なるので重さがわずかに異なる。重い同位体の方が体に残りやすいため、食物連鎖の上位に位置する動物ほど体組織に占める重い方の同位体の割合が多くなる。そのため、生態学では生態系におけるその種の栄養段階を調べるために、体組織中の2つの窒素同位体(\\(^{15}\\rm{N}\\)と\\(^{14}\\rm{N}\\))の比が用いられることがある。一方、栄養段階による安定同位体比の変化は炭素よりも窒素で大きいため、食物連鎖の下の方の生物には炭素同位体比が用いられることが多い。また、炭素の安定同位体比はその生物が生息する環境(海水域、淡水域、沿岸域、沖合など)によっても異なるため、その動物が属する生態系を特定するために炭素同位体比が用いられることもある。 ここでは、北大西洋の北極圏及び亜北極圏に豊富に生息し、様々な捕食者の餌となっているイカ(Gonatus fabricii)の安定同位体比(\\(\\delta^{13}\\rm{C}, \\delta^{15}\\rm{N}\\))を測定したMendes( Zuur (2012) の著者の一人)らの研究データを用いる。この研究は、井戸や水深、体サイズによって個体群内の安定同位体比が変わるかを調べることを目的としている。 5.2 The variables データは以下の通り。 Lat：緯度 Depth: サンプルを採集した水深 ML: イカの外套膜の長さ d15N: 窒素同位体比(\\(^{15}\\rm{N}\\)の占める割合) Squid &lt;- read_delim(&quot;data/SquidNorway.txt&quot;) datatable(Squid, options = list(scrollX = 20), filter = &quot;top&quot;) 5.3 Data exploration まずはデータ探索を行う。 図5.1は各変数のdotplotを示したものである。いずれの変数も外れ値のようなものはなさそうに見える。ただし、latとDepthについては連続値にもかかわらず同じ値のデータがたくさんある。これは、同時に(同じクルーズ中に)複数の検体を採集していることがあるからであり、これはデータの非独立性を生んでいる可能性がある。もし同じ場所で採集された検体が似た環境条件にさらされているとすると、これを考慮する必要がある。ひとまず今回は、全ての観察が独立であると仮定して分析を行う。 Squid %&gt;% mutate(no_sample = 1:n()) %&gt;% pivot_longer(cols = c(ML, d15N, Lat, Depth)) %&gt;% ggplot(aes(x = value, y = no_sample))+ geom_point(shape = 1, alpha = 0.5)+ theme_bw()+ theme(aspect.ratio = 1)+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ labs(x = &quot;Values&quot;, y = &quot;Order of the data&quot;) 図5.1: Cleveland dotplots for all variables. There are no clear outliers. 変数同士の散布図を示したのが図5.2である。図から、水深と緯度が中程度の相関を持っていることが分かるので、いずれかをモデルから除く方がよい。今回は水深を除く(6つの値しか取らないため)。ただし、第5.8節では両方含めた場合の結果も確認する。 ggpairs(Squid) 図5.2: Multi-panel scatterplot with Pearson correlation coefficients. 目的変数(d15N)とそのほかの変数の関係をより詳しく調べる(図5.3)。水深と緯度は窒素同位体比とあまり関係がなさそうだが、外套膜の長さは安定同位体比と強く関連しているように見える。この関係は線形と非線形のどちらだろうか?また、分散は外套膜が長いほど大きくなっているように見えるが、実際にそうだろうか? Squid %&gt;% pivot_longer(cols = c(Depth, Lat, ML)) %&gt;% ggplot(aes(x = value, y = d15N))+ geom_point()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ geom_smooth(method = &quot;loess&quot;, se = FALSE, span = 0.9) 図5.3: Multi-panel scatterplot showing the relationship between d15N and the three covariates. A LOESS smoother was added to aid visual interpretation. 5.4 Brain storming さて、以下では窒素同位体比(d15N)を緯度(Lat)と外套膜の長さ(ML)の関数としてモデリングする。図5.3を見る限りはMLとd15Nの関係は線形だが、もしかすると緯度と外套膜長の交互作用を考えると、変数間の関係は非線形になるかもしれない。 まずは交互作用がなく、smootherが2つあるGAMが考えられる。 \\[ \\begin{aligned} d15N_i &amp;= \\alpha + f_1(Lat_i) + f_2(ML_i) + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\tag{5.1} \\] しかし、緯度は9つの値しか取らないのでsmootherを推定するには不十分である。よって以下のモデルの方が適当だろう。 \\[ \\begin{aligned} d15N_i &amp;= \\alpha + \\beta \\times Lat_i + f_2(ML_i) + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\tag{5.2} \\] あるいは、いずれも線形な関係を持つと仮定するモデルを考えることもできる。 \\[ \\begin{aligned} d15N_i &amp;= \\alpha + \\beta_1 \\times Lat_i + \\beta_2 \\times ML_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\tag{5.3} \\] 以下では、式(5.2)と式(5.3)のモデルについてみていく。まずは重回帰分析を行ったのち(式(5.2))、加法モデルを適用してどちらが適切かを考えていく。 5.5 Applying the multiple linear regression model 式(5.3)のモデルは以下のように実行できる。 M5_1 &lt;- lm(d15N ~ ML + Lat, data = Squid) まずはモデル診断を行う。標準化残差とモデルの予測値、外套膜の長さの関係をプロットしたのが図5.4である。図5.4のAを見る限り、残差は概ね均等に分布しているように見える。すなわち、分散の不均等性はないようだ。図5.4のBにもパターンは見られず、外套膜長と窒素同位体比に非線形性はないように思える。 data.frame(resid = rstandard(M5_1), fitted = fitted(M5_1)) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p1 data.frame(resid = rstandard(M5_1), ML = Squid$ML) %&gt;% ggplot(aes(x = ML, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mantel length&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p2 p1 + p2 図5.4: A: Residuals versus fitted values. B: Residuals versus mantle length. しかし、実際に非線形性がないかはきちんと調べる必要がある。調べる一つの方法は、標準化残差に対して以下のモデルを適用することである。モデルに切片を含めなかったのは、標準化残差は平均が0になるからである。 \\[ \\begin{aligned} e_i &amp;= f(ML_i) + \\eta_i\\\\ \\eta &amp;\\sim N(0,\\sigma_{\\eta}^2) \\end{aligned} \\] Rでは以下のように実行できる。 E &lt;- rstandard(M5_1) T1 &lt;- gam(E ~ -1 + s(ML), data = Squid) 結果は以下の通り。smootherは有意であることから、標準化残差と外套膜長の関係は非線形であることが分かる。 summary(T1) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## E ~ -1 + s(ML) ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(ML) 2.537 3.19 4.861 0.0029 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.141 Deviance explained = 15.4% ## GCV = 0.89241 Scale est. = 0.87084 n = 105 図5.5は推定されたsmootherを図示したものである。 draw(T1)+ theme_bw()+ theme(aspect.ratio = 1) 図5.5: Smoothing function of ML obtained by applying an additive model on the residuals of the multiple linear regression model in Equation (5.3). 5.6 Applying an additive model それでは、加法モデルを適用する。式(5.2)のモデルは以下のように実行できる。 M5_2 &lt;- gam(d15N ~ s(ML) + Lat, data = Squid) 結果は以下の通り。緯度は5%水準で窒素同位体比と有意に正に関連していた。また、smootherの自由度は2.57であり有意だった。\\(R^2\\)値は0.578であり、データのばらつきの60%近くがモデルによって説明されている。smootherは薄板平滑化スプラインによって推定されている。 summary(M5_2) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## d15N ~ s(ML) + Lat ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.81246 1.45034 6.076 2.22e-08 *** ## Lat 0.05409 0.02086 2.593 0.0109 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(ML) 2.577 3.246 43.71 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.578 Deviance explained = 59.2% ## GCV = 0.40038 Scale est. = 0.38293 n = 105 図5.6は推定されたsmootherである。smootherは外套膜長と窒素同位体比の関係が非線形であることを示唆している。 draw(M5_2)+ theme_bw()+ theme(aspect.ratio = 1) 図5.6: Estimated thin plate regression spline for mantle length. Residuals are added. モデル診断を行う。図5.7は残差とモデルの予測値、共変量、水深の関係をプロットしたものと、残差のヒストグラムを描いたものである。特にパターンは見られず、モデルの前提が満たされているように見える。 data.frame(resid = resid(M5_2), fitted = fitted(M5_2)) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;A&quot;) -&gt; p1 data.frame(resid = resid(M5_2), ML = Squid$ML) %&gt;% ggplot(aes(x = ML, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mantel length&quot;, y = &quot;Residuals&quot;, title = &quot;B&quot;) -&gt; p2 data.frame(resid = resid(M5_2), Lat = Squid$Lat) %&gt;% ggplot(aes(x = Lat, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Latitude&quot;, y = &quot;Residuals&quot;, title = &quot;C&quot;) -&gt; p3 data.frame(resid = resid(M5_2), Depth = Squid$Depth) %&gt;% ggplot(aes(x = Depth, y = resid))+ geom_point(shape =1)+ geom_hline(yintercept = 0, linetype = &quot;dashed&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;, title = &quot;D&quot;) -&gt; p4 data.frame(resid = resid(M5_2)) %&gt;% ggplot(aes(x = resid))+ geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;, bins = 12)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Reisduals&quot;, y = &quot;Frequency&quot;, title = &quot;E&quot;) -&gt; p5 data.frame(resid = resid(M5_2)) %&gt;% arrange(resid) %&gt;% mutate(n = 1:n()) %&gt;% ggplot(aes(x = n, y = resid))+ geom_col()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Sorted residuals&quot;, y = &quot;Residuals&quot;, title = &quot;F&quot;) -&gt; p6 (p1+p2+p3)/(p4+p5+p6) 図5.7: Model validation graphs for the additive model in Equation ( 5.2). A: Residuals versus fitted values. B: Residuals versus ML. C: Residuals versus latitude. D: Residuals versus depth. E: Histogram of residuals. F: Sorted residuals. QQプロットもおおむねよく当てはまっている。 qq_plot(M5_2) 5.7 Testing linearity versus non-linearity 加法モデルで推定されたsmootherの自由度は2.577であり、線形モデルの場合(= 1)と大きく違うわけではない。どのようなときに線形モデルではなく加法モデルを使った方がよいと判断すべきだろうか。 以下の事実は加法モデルを使うべきだとする主張を支持する。 重回帰分析の結果から、外套膜長と標準化残差に非線形の関係がみられることが確かめられた。 加法モデルのモデル診断では問題が見つからなかった。 gam関数の交差検証によって、自由度が2.577だと推定された。 これらに加えて、AICも加法モデルがより良いモデルであることを示唆している。 AIC(M5_1, M5_2) また、F検定によってそちらのモデルが優れているかを判断することもできる。ただし、この結果の解釈には注意が必要である。一般にp値が0.001以下であればsmootherの効果が十分にあるといえる。 anova(M5_1, M5_2, test = &quot;F&quot;) 他の種類のsmootherでも同様の結果がみられるか確かめることで、加法モデルの方が線形モデルより適切かを検討することもできる。例えば、以下のように3次回帰スプラインでも自由度は2.57と推定され、データに非線形な関係があることが支持される。 M5_3 &lt;- gam(d15N ~ s(ML, bs = &quot;cr&quot;) + Lat, data = Squid) M5_3 ## ## Family: gaussian ## Link function: identity ## ## Formula: ## d15N ~ s(ML, bs = &quot;cr&quot;) + Lat ## ## Estimated degrees of freedom: ## 2.57 total = 4.57 ## ## GCV score: 0.400323 5.7.1 Programming a smoother manually 最後に、手動で加法モデルを適用してみることで加法モデルの方が線形モデルより適切であることを確かめる。 第3章で見たように、smootherは基底を\\(b_j(ML_i)\\)のように書くとき、以下のように表すことができる。 \\[ f(ML_i) = \\sum_{j = 1}^K \\beta_j \\times b_j(ML_i) \\] 例えば、二次スプライン回帰であればsmootherは以下のように書けた(第3.5節)。ここで、\\(k_j\\)は内側のノットである。 \\[ f(ML_i) = \\alpha + \\beta_1 \\times ML_i + \\beta_2 \\times ML_i^2 + \\sum_{j = 1}^K \\beta_{1j} (ML_i - \\kappa_j)_+^2 \\] よって、式(5.2)のモデルは以下のように書ける。 \\[ \\begin{aligned} d15N_i &amp;= \\alpha + \\beta_0 \\times Lat_i + \\beta_1 \\times ML_i + \\beta_2 \\times ML_i^2 + \\sum_{j = 1}^K \\beta_{1j} (ML_i - \\kappa_j)_+^2 + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\tag{5.4} \\] ここから、式(5.3)の線形モデルと加法モデル(式(5.4))はネストしていることが分かる。よって、この2つのモデルにF検定をするとき、式(5.4)で\\(\\beta_2 = \\beta_{11} = \\beta_{12} = \\cdots = 0\\)という帰無仮説を検定していることになっている。他の加法モデルについても基本的に同様のことが言える。 以下では、3次自然スプラインを手動で適用することでこのことを確かめる。以下のモデルでは、数学的な問題を回避するために外套膜長を0から1にスケールする。 Squid %&gt;% mutate(MLsc = (ML - min(ML))/(max(ML) - min(ML))) -&gt; Squid また、内側のノットは3つにする。外側を含めたノットの値は以下の通り。 q_ML &lt;- quantile(Squid$MLsc, probs = seq(0,1,length = 5)) q_ML ## 0% 25% 50% 75% 100% ## 0.0000000 0.1708333 0.2916667 0.4708333 1.0000000 3次自然スプラインにおいて規定は以下のように定義される。なお、\\(K\\)は内側のノット数である。 \\[ \\begin{aligned} b_1(MLsc_i) &amp;= 1\\\\ b_2(MLsc_i) &amp;= MLsc_i\\\\ b_{k+2}(MLsc_i) &amp;= d_k(MLsc_i) - d_{K-1}(MLsc_i)\\\\ d_k(MLsc_i) &amp;= \\frac{(MLsc_i - \\kappa_k)_+^3 - (MLsc_i - \\kappa_K)_+^3}{\\kappa_K - \\kappa_k} \\end{aligned} \\] なお、第@red(c3)で見たように、\\((MLsc_i - \\kappa)_+\\)は以下のように定義される。 \\[ (MLsc_i - \\kappa)_+ = \\begin{cases} 0 &amp; (MLsc_i &lt; \\kappa)\\\\ MLsc_i - \\kappa &amp; (MLsc_i ≧ 0\\kappa\\\\ \\end{cases} \\] Rで\\((MLsc_i - \\kappa)_+\\)、\\(d_k\\)を作成する関数と、基底\\(b_k(MLsc_i)\\)を作成する関数を作成する。 rhs &lt;- function(x, TH){ifelse(x &gt;= TH, (x-TH)^3, 0)} dk &lt;- function(x, TH, K){(rhs(x,TH) - rhs(x, K))/(K - TH)} ## 以下、誤っている可能性。教科書通りの定義ならK-1はK-1番目のκを指定する必要がある。 bj &lt;- function(x, TH, K){dk(x, TH, K) - dk(x, K-1, K)} これらを利用して3次自然スプラインを適用すると以下のようになる。 M5_4 &lt;- lm(d15N ~ 1 + Lat + MLsc + bj(MLsc, q_ML[2], q_ML[4]) + bj(MLsc, q_ML[3], q_ML[4]), data = Squid) \\(b_j\\)を含む説明変数の行列は以下のように取り出せる。 X &lt;- model.matrix(M5_4) head(X) ## (Intercept) Lat MLsc bj(MLsc, q_ML[2], q_ML[4]) ## 1 1 62.98 0.6583333 -1.3037500 ## 2 1 64.67 0.3291667 -0.6191341 ## 3 1 64.67 0.4750000 -0.9187500 ## 4 1 64.67 0.3166667 -0.5947996 ## 5 1 64.67 0.5125000 -0.9975000 ## 6 1 64.67 0.2416667 -0.4568322 ## bj(MLsc, q_ML[3], q_ML[4]) ## 1 -1.4296181 ## 2 -0.6320708 ## 3 -0.9781597 ## 4 -0.6050507 ## 5 -1.0705035 ## 6 -0.4580169 推定された回帰係数は以下の通り。 coef(M5_4) ## (Intercept) Lat ## 6.96611562 0.05567002 ## MLsc bj(MLsc, q_ML[2], q_ML[4]) ## 4.19388641 -17.04870266 ## bj(MLsc, q_ML[3], q_ML[4]) ## 15.64702422 smootherは切片を含めない場合以下のように計算できる。 smoother &lt;- X[,3:5] %*% coef(M5_4)[3:5] gam()関数の結果で出力されるようにsmootherを中心化するには以下のようにする。 smoother_center &lt;- smoother - mean(smoother) smootherを図示すると以下のようになる(図5.8)。図5.6とよく似た曲線が推定された。 data.frame(MLsc = Squid$MLsc, fitted = smoother_center, resid = resid(M5_4) + smoother_center) %&gt;% ggplot()+ geom_line(aes(x = MLsc, y = fitted), linewidth = 1)+ geom_point(aes(x = MLsc, y = resid), shape = 1)+ geom_vline(data = data.frame(MLsc = q_ML), aes(xintercept = MLsc))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Scaled ML&quot;, y = &quot;Smoothing function ML&quot;) 図5.8: Estimated cubic spline using our self-programmed code. さて、ここで3次自然スプラインモデルを通常の線形回帰モデルと比較する。 M5_5 &lt;- lm(d15N ~ Lat + MLsc, data = Squid) F検定を行うと有意だった。これは、\\(b_3\\)と\\(b_4\\)にかかる回帰係数が0であるという帰無仮説が棄却されたことを表す。このことから、加法モデルを適用することがより適切だということができる。 anova(M5_4, M5_5, test = &quot;F&quot;) 5.8 Consequence of ignoring collinearity in the additive model さて、ここまでのモデルは水深と緯度に相関があるため緯度のみをモデルに含めてきた。これらを同時にモデルに含めるとどうなるのだろうか。 以下のモデルを考える。 \\[ \\begin{aligned} d15N_i &amp;= \\alpha + f_1(Lat_i) + f_2(ML_i) + f_3(Depth_i) + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] しかし、Rで実行すると以下のようなエラーが出る。これは、緯度と水深がとる固有の値が少ないからである。 M5_6 &lt;- gam(d15N ~ s(Lat)+ s(Depth) + s(ML), data = Squid) ## Error in smooth.construct.tp.smooth.spec(object, dk$data, dk$knots): A term has fewer unique covariate combinations than specified maximum degrees of freedom ここで、緯度と水深をsmootherにしないという選択肢もあるが、ここでは自由度の上限を決めることで対処する。 M5_6 &lt;- gam(d15N ~ s(Lat, k = 4)+ s(Depth, k = 4) + s(ML), data = Squid) 結果は以下の通り。水深のsmootherの自由度は1なので、有意ではないが線形であると推定されている。緯度のsmootherの自由度は1.49なので、わずかに非線形である。外套膜長のsmootherの自由度は先ほどとほとんど変わっていない。この結果は、この例では緯度と水深の多重共線性が加法モデルにおいてそこまで大きな問題を引き起こしていないことを示している。おそらく今回は外套膜長のみが窒素同位体比と強い関係を持っていたため、多重共線性の影響を受けることがなかったのだろう。いずれにしても、推定結果に大きな影響を及ぼすこともあるので多重共線性には常に注意を払う必要がある。 summary(M5_6) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## d15N ~ s(Lat, k = 4) + s(Depth, k = 4) + s(ML) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.56952 0.06025 208.6 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Lat) 1.491 1.776 2.369 0.0621 . ## s(Depth) 1.000 1.000 0.209 0.6486 ## s(ML) 2.566 3.233 39.058 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.58 Deviance explained = 60% ## GCV = 0.40446 Scale est. = 0.38113 n = 105 5.9 Discussion 加法モデルの結果は外套膜長と窒素同位体比の間に非線形的な関係があることを示し、緯度と炭素同位体比の間には明確な関係がみられなかった。この分析では同じ場所でサンプルされたデータを独立なものだとみなしたが、もしこれらが独立でないならば採集場所の情報をランダム効果に含める必要がある。なお、今回のデータはサンプルサイズも大きくないのでランダム効果を含めて混合モデルにするには適していない。 5.10 What to present in a paper 実際の論文では以下のことに言及する必要がある。 方法ではデータ探索を行い、外れ値や多重共線性、変数間の関係について調べたことに言及する必要がある。結果では緯度と水深の多重共線性に触れる必要がある。 方法で加法モデルのモデル式を示し、データに独立性があることに言及する必要がある。結果では推定されたsmootherの情報と結果をプロットした図を示す必要がある。 方法ではモデル診断を行ったこと、またその結果を報告する必要がある。ただし、論文中に図を含める必要はない(場合によってはsupplementaryに)。 モデルが序論で提示されたリサーチクエスチョンに合致しており、考察が結果に対応しているかを確認する。 考察では、緯度に見られたわずかな効果が水深の効果である可能性にも言及する必要がある。これらは相関しているからである。 References "],["Chapter6.html", "6 Generalized Additive Models applied on northern gannets 6.1 Northern Gannet in the north sea 6.2 The variables 6.3 Brainstorming 6.4 Data exploration 6.5 Building up the complexity of the GAMs 6.6 Zero-inflated GAM 6.7 Discussion", " 6 Generalized Additive Models applied on northern gannets 6.1 Northern Gannet in the north sea Camphuysen and Powell は北海のキタカツオドリ(Morus bassanus)を対象に探索採食戦術の研究を行った。研究では300m幅のトランゼクトで確認された個体数が記録されている。リサーチクエスチョンは、カツオドリはいつコロニーの近くで採食をするのか、である。 6.2 The variables データは以下の通り。各行のデータが各トランゼクトのデータを表している。目的変数はトランゼクト内のカツオドリの数である。 Day: 観察した日 Month: 観察した月 Year: 観察した年 Hours: 観察時の時間 Minutes: 観察時の分 Latitude、Y: 緯度 Longtitude、X: 経度 Area_surveyedkm2: 探索エリアの面積 Seastate: 海の状態 Gannets_in_transect: トランゼクト内のカツオドリの数 Gannets &lt;- read_delim(&quot;data/Gannets2.txt&quot;) datatable(Gannets, options = list(scrollX = 20), filter = &quot;top&quot;) 6.3 Brainstorming まず、データを収集したトランゼクトの場所が年ごとに違っていないかを確かめる。図6.1を見る限りは概ね同じエリアでデータが採集されていたことが分かる。 Gannets %&gt;% ggplot(aes(x = Longitude, y = Latitude))+ geom_count(alpha = 0.5)+ theme_bw()+ theme(aspect.ratio = 1.5)+ facet_rep_wrap(~Year, repeat.tick.labels = TRUE, ncol = 5) 図6.1: Spatial position of each transect per year. 最初に考えなければならないのは、トランゼクトごとに探索努力が異なるということである。探索努力はトランゼクトのサイズとして定量化されている。図6.2を見るとトランゼクトのサイズは大きくばらついているので、これを考慮する必要がある。 Gannets %&gt;% mutate(no_samples = 1:n()) %&gt;% ggplot(aes(x = Area_surveyedkm2, y = no_samples))+ geom_point(alpha = 0.5)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Area&quot;, y = &quot;Order of the data&quot;) 図6.2: Clevela nd dotplot illustrating the sizes of the transects. 第4章で見たように、もしトランゼクトサイズが10倍になったら確認できる鳥の数も10倍になると考えられるなら、トランゼクトサイズの対数をオフセット項として含めることができる。一方で、もしそうでないならばトランゼクトサイズは共変量として説明変数に含める必要がある。今回はオフセット項で用いるが、サイズが0のもの(定点観測を行ったデータ)も存在するので、それは除外する。また、時刻を表す列も作成する。また、1年の中でのユリウス通日(1月1日からの経過日数)と1991年1月1日からの経過日数も算出する。 Gannets %&gt;% filter(Area_surveyedkm2 &gt; 0) %&gt;% mutate(LArea = log(Area_surveyedkm2)) %&gt;% mutate(Time = Hours + Minutes/60) %&gt;% mutate(Xkm = X/1000, Ykm = Y/1000) %&gt;% mutate(Date = as.POSIXct(str_c(Year,&quot;-&quot;,Month,&quot;-&quot;,Day))) %&gt;% ## 年内のユリウス通日 mutate(DayInYear = strptime(Date, &quot;%Y-%m-%d&quot;)$yday + 1) %&gt;% ## 1991年1月1日からの経過日数 mutate(DaySince0 = ceiling(julian(strptime(Date, format = &quot;%Y-%m-%d&quot;), orogin = as.Date(&quot;1991-01-01&quot;)))) %&gt;% rename(G = Gannets_in_transect) -&gt; Gannets2 データは1991年から2004年の6から7月、4時から20時間に収集されている。カツオドリの数は年と日付、時間、トランゼクトの位置によって異なる。そこで、以下のモデル式を考える。このモデルは日付の効果は年に依らず同じで、時間の効果は年や月に依らずに同じで、トランゼクトの位置の効果は時間によって変化しないことを仮定している(= 交互作用を入れていない)。調査は6月と7月にしか行われていないので、日付の効果が時間によって変わらないという仮定は妥当だろう。これは、\\(f(Day_i, Hour_i)\\)を含めないということを意味する。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year) + f_2(Day_i) + f_3(Hours_i) + f_4(X_i,Y_i) + \\beta \\times SeaState_i + log(Area_i) \\end{aligned} \\] もしトランゼクトの場所の効果が年によって異なると仮定するなら、以下のようなモデルになる。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year, X_i, Y_i) + f_2(Day_i) + f_3(Hours_i) + \\beta \\times SeaState_i + log(Area_i) \\end{aligned} \\] ひとまず、以下ではデータ探索を行ったうえで、最も適切だと思えるモデルを考えていく。 6.4 Data exploration 図6.3は、地点ごとのカツオドリの密度を点の大きさで表したものである。年によって密度が高い場所は異なっているように見える。これは、\\(f(Priod_1, X_i, Y_i)\\)という3次元smootherが必要であることを示唆している。 Gannets2 %&gt;% mutate(Density = G/Area_surveyedkm2) %&gt;% ggplot(aes(x = Xkm, y = Ykm))+ geom_point(aes(size = Density), alpha = 0.7)+ scale_size(range = c(0,12))+ theme_bw()+ theme(aspect.ratio = 1.5)+ facet_rep_wrap(~Year, repeat.tick.labels = TRUE, ncol = 4)+ labs(x = &quot;Xkm&quot;, y = &quot;Ykm&quot;) 図6.3: Gannet density plotted versus spatial coordinates and year. The size of a dot is proportional to the gannet density. 図6.4は、時間とその年の1月1日からの経過日数によって密度がどのように異なるかを年ごとに可視化したものである。年によって密度が高い日や時間帯が異なっていることが分かる。 Gannets2 %&gt;% mutate(Density = G/Area_surveyedkm2) %&gt;% ggplot(aes(x = Hours, y = DayInYear))+ geom_point(aes(size = Density), alpha = 0.7)+ scale_size(range = c(0,12))+ theme_bw()+ theme(aspect.ratio = 1.5)+ facet_rep_wrap(~Year, repeat.tick.labels = TRUE, ncol = 4)+ labs(x = &quot;Hour&quot;, y = &quot;Day&quot;) 図6.4: Gannet density plotted versus hour, day, and year. The size of a dot is proportional to the gannet density. また、データにゼロ過剰がないかも確認する必要がある。カツオドリの数が0のデータは全体の0.81に及ぶ。もしモデルが仮定するよりも過剰にゼロがあると過分散の問題を引き起こすので、ゼロ過剰モデルを適用する必要がある。まずは普通のポワソン分布を適用し、ゼロ過剰でないかを確認する。 多重共線性の問題も考える必要がある。例えば、時刻や日付が海の状態と関連している可能性はあるが、図6.5を見る限りは問題なさそう。 Gannets2 %&gt;% dplyr::select(Time, DayInYear, Seastate) %&gt;% pivot_longer(1:2) %&gt;% mutate(Seastate = as.factor(Seastate)) %&gt;% ggplot(aes(x = Seastate, y = value))+ geom_boxplot()+ facet_rep_wrap(~name, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;)+ theme_bw()+ theme(aspect.ratio = 1.2) 図6.5: Boxplot of Time conditional on Seastate and DayInYear conditional on Seastate. 確認されたカツオドリの数を見てみると、いくつかかなり大きいものがあることが分かる。また、前述したように0が多い。次節ではまずポワソン分布のGAMから入るが、おそらくゼロ過剰負の二項分布のGAMを適用する必要があると思われる。 Gannets2 %&gt;% mutate(no_samples = 1:n()) %&gt;% ggplot(aes(x = G, y = no_samples))+ geom_point(alpha = 0.5)+ theme_bw()+ theme(aspect.ratio = 1) 図6.6: Cleveland dotplot of gannet abundance. 6.5 Building up the complexity of the GAMs まずはポワソン分布のGAMを適用する。GLMではなくGAMを適用するのは、日付や月、年による変化は明確に非線形だからである。まずは年のsmootherだけを含む以下のモデルを考える。\\(G_i\\)は確認されたカツオドリの数、\\(LSA_i\\)はトランゼクトのサイズの対数である。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + LSA_i \\\\ \\end{aligned} \\] Rでは以下のように実行する。 M6_1 &lt;- gam(G ~ s(Year) + offset(LArea), family = poisson, data = Gannets2) まずは過分散を確認する。分散パラメータ\\(\\phi\\)を算出すると(第4.4節参照)、高い数値をとっており、過分散が生じていることが分かる。 E1 &lt;- resid(M6_1, type = &quot;pearson&quot;) sum(E1^2)/M6_1$df.residual ## [1] 36.92865 ゼロ過剰モデルや負の二項分布モデルを考える前に、他の共変量を加えることで過分散が解決するかを確認する。次は海の状態を加えた以下のモデルを考える。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\] Rでは以下のように実行する。 M6_2 &lt;- gam(G ~ s(Year) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E2 &lt;- resid(M6_2, type = &quot;pearson&quot;) sum(E2^2)/M6_2$df.residual ## [1] 29.7664 続いて、時刻のsmootherも追加したモデルを考える。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\] Rでは以下のように実行する。 M6_3 &lt;- gam(G ~ s(Year) + s(Time) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E3 &lt;- resid(M6_3, type = &quot;pearson&quot;) sum(E3^2)/M6_3$df.residual ## [1] 26.70897 続いて、1年の中での経過年数のsmootherもモデルに加える。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i) + f_3(DayInYear_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\] Rでは以下のように実行する。 M6_4 &lt;- gam(G ~ s(Year) + s(Time) + s(DayInYear) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E4 &lt;- resid(M6_4, type = &quot;pearson&quot;) sum(E4^2)/M6_4$df.residual ## [1] 23.05207 次に、緯度と経度の2次元smootherも追加する。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i) + f_3(DayInYear_i) + f_4(X_i,Y_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\tag{6.1} \\] Rでは以下のように実行する。GAMではそれぞれのsmootherに罰則が与えられているが、2次元smootherの2つの共変量はそれぞれ同様に罰則を与えられるべきである。特に、二つの共変量が異なるスケールを持つときにはこれに気を付ける必要がある。このようなときは、いわゆる非等方性スムーザー(non-isotopic smoother)を用いるべきである。ここでは、テンソル積smoother(te())を用いる。これについては、こちらが詳しい。テンソル積smootherは、異なるスケールを持つ共変量の2次元smootherを用いる場合に有用である。ただし、2つの共変量が同じスケールを持つ場合にはs()を用いる方がよいようである。今回はXkmとYkmが異なるスケールを持つため、テンソル積smootherを用いる。 Rでは以下のように実行する。 M6_5 &lt;- gam(G ~ s(Year) + s(Time) + s(DayInYear) + te(Xkm, Ykm) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E5 &lt;- resid(M6_5, type = &quot;pearson&quot;) sum(E5^2)/M6_5$df.residual ## [1] 20.07788 モデルに多重共演性や独立性などの問題がないかを確かめるには、ここまでの全てのモデルで同じようなsmootherが推定されているかを確かめればよい。図6.7は2つ以上のモデルによって推定されたsmootherを図示したものである。それぞれのモデルのsmootherは非常に似たパターンを示していることが分かる。 smooth_estimates(M6_1, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_1&quot;) %&gt;% bind_rows(smooth_estimates(M6_2, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_2&quot;)) %&gt;% bind_rows(smooth_estimates(M6_3, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_3&quot;)) %&gt;% bind_rows(smooth_estimates(M6_4, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_4&quot;)) %&gt;% bind_rows(smooth_estimates(M6_5, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_5&quot;)) %&gt;% ggplot(aes(x = Year, y = est))+ geom_line(aes(color = model))+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci,fill = model), alpha = 0.4)+ scale_color_nejm()+ scale_fill_nejm()+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(1991,2004,2)) -&gt; p_year smooth_estimates(M6_3, smooth = &quot;s(Time)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_3&quot;) %&gt;% bind_rows(smooth_estimates(M6_4, smooth = &quot;s(Time)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_4&quot;)) %&gt;% bind_rows(smooth_estimates(M6_5, smooth = &quot;s(Time)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_5&quot;)) %&gt;% ggplot(aes(x = Time, y = est))+ geom_line(aes(color = model))+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci,fill = model), alpha = 0.4)+ scale_color_nejm()+ scale_fill_nejm()+ theme_bw()+ theme(aspect.ratio = 1) -&gt; p_time smooth_estimates(M6_4, smooth = &quot;s(DayInYear)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_4&quot;) %&gt;% bind_rows(smooth_estimates(M6_5, smooth = &quot;s(DayInYear)&quot;) %&gt;% add_confint() %&gt;% mutate(model = &quot;M6_5&quot;)) %&gt;% ggplot(aes(x = DayInYear, y = est))+ geom_line(aes(color = model))+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci,fill = model), alpha = 0.4)+ scale_color_nejm()+ scale_fill_nejm()+ theme_bw()+ theme(aspect.ratio = 1) -&gt; p_day p_year + p_time + p_day + plot_layout(ncol = 2) 図6.7: Smoothers estimated by GAM さて、次に以下のような3次元smootherを含めたモデルを考える。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Times_i) + f_2(DayInYear_i) + f_3(X_i,Y_i, Year_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\] Rでは以下のように実行する。 M6_6 &lt;- gam(G ~ s(Time) + s(DayInYear) + te(Xkm, Ykm, Year) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) このモデルでは、3次元smootherの自由度は123とかなり大きくなる。 summary(M6_6) ## ## Family: poisson ## Link function: log ## ## Formula: ## G ~ s(Time) + s(DayInYear) + te(Xkm, Ykm, Year) + offset(LArea) + ## factor(Seastate) ## ## Parametric coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.51861 0.04676 -11.091 &lt; 2e-16 *** ## factor(Seastate)1 0.01075 0.04488 0.240 0.81060 ## factor(Seastate)2 -0.30140 0.04530 -6.653 2.87e-11 *** ## factor(Seastate)3 -0.34641 0.04708 -7.358 1.87e-13 *** ## factor(Seastate)4 -0.56874 0.05160 -11.022 &lt; 2e-16 *** ## factor(Seastate)5 -0.20972 0.06664 -3.147 0.00165 ** ## factor(Seastate)6 -0.52544 0.10116 -5.194 2.06e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df Chi.sq p-value ## s(Time) 8.970 9 428.8 &lt;2e-16 *** ## s(DayInYear) 8.964 9 1028.6 &lt;2e-16 *** ## te(Xkm,Ykm,Year) 123.478 124 8278.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.0597 Deviance explained = 29.9% ## UBRE = 1.6513 Scale est. = 1 n = 12820 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E6 &lt;- resid(M6_6, type = &quot;pearson&quot;) sum(E6^2)/M6_6$df.residual ## [1] 12.07028 次に、式(6.1)の拡張として、TimeとDayInYearの2次元smootherを考えることもできる。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i, DayInYear_i) + f_3(X_i,Y_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\tag{6.2} \\] Rでは以下のように実行する。 M6_7 &lt;- gam(G ~ s(Year) + te(Time, DayInYear) + te(Xkm, Ykm) + offset(LArea) + factor(Seastate), family = poisson, data = Gannets2) 分散パラメータ\\(\\phi\\)を計算すると、まだ過分散は解決されていない。 E7 &lt;- resid(M6_7, type = &quot;pearson&quot;) sum(E7^2)/M6_7$df.residual ## [1] 17.8385 モデルM6_7の残差と予測値の関係を図示したのが図6.8である。いくつか残差の大きなデータがあることが分かり、図6.6と合わせるとこれらのデータが過分散の原因になっているのではないかと思われる。 data.frame(resid = resid(M6_7, type = &quot;pearson&quot;), fitted = fitted(M6_7)) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Pearson residuals&quot;) 図6.8: Pearson residuals plotted versus fitted values for the Poisson GAM in Equation (6.7). そのため、次のステップとして自然なのはポワソン分布よりも大きな分散をとりうる負の二項分布を目的変数の分布として仮定することである。 \\[ \\begin{aligned} G_i &amp;\\sim Poisson(\\mu_i)\\\\ E(G_i) &amp;= \\mu_i \\;\\; and \\;\\;var(G_i) = \\mu_i + \\frac{\\mu_i^2}{k} \\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i, DayInYear_i) + f_3(X_i,Y_i) + \\beta \\times Seastate_i + LSA_i \\\\ \\end{aligned} \\tag{6.3} \\] Rではパラメータ\\(k\\)がthetaとして推定される。以下のように実行できる。 M6_8 &lt;- gam(G ~ s(Year) + te(Time, DayInYear) + te(Xkm, Ykm) + offset(LArea) + factor(Seastate), family = nb, data = Gannets2) モデルの分散パラメータ\\(\\phi\\)は3.44である。 E8 &lt;- resid(M6_8, type = &quot;pearson&quot;) sum(E8^2)/M6_8$df.residual ## [1] 3.441738 結果は以下のとおりである。モデルのsmootherは全て有意であり、\\(k\\)(theta)は0.151と推定された。smootherの自由度はUBRE(unbiased risk estimator)に基づいて推定されている。 print(summary(M6_8), digits = 3) ## ## Family: Negative Binomial(0.151) ## Link function: log ## ## Formula: ## G ~ s(Year) + te(Time, DayInYear) + te(Xkm, Ykm) + offset(LArea) + ## factor(Seastate) ## ## Parametric coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.42313 0.10208 -4.15 3.4e-05 *** ## factor(Seastate)1 0.35118 0.12656 2.77 0.0055 ** ## factor(Seastate)2 -0.10057 0.11859 -0.85 0.3964 ## factor(Seastate)3 -0.00582 0.11539 -0.05 0.9597 ## factor(Seastate)4 -0.26035 0.12001 -2.17 0.0301 * ## factor(Seastate)5 -0.12681 0.14264 -0.89 0.3740 ## factor(Seastate)6 -0.41042 0.18740 -2.19 0.0285 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df Chi.sq p-value ## s(Year) 6.79 7.83 99.1 &lt;2e-16 *** ## te(Time,DayInYear) 20.43 22.58 167.3 &lt;2e-16 *** ## te(Xkm,Ykm) 15.40 17.93 517.8 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.0259 Deviance explained = 23.6% ## -REML = 10345 Scale est. = 1 n = 12820 残差と予測値の関係を図示したのが図6.8である。赤い点はカツオドリの数が25以上のポイントである。この図から、モデルはカツオドリの数が大きいポイントをうまくフィットできていないことが示唆される。 data.frame(resid = resid(M6_8, type = &quot;pearson&quot;), fitted = fitted(M6_8), G = Gannets2$G) %&gt;% ggplot(aes(x = fitted, y = resid))+ geom_point(shape = 1, aes(color = G &gt;= 25), stroke = 1.1, alpha = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Pearson residuals&quot;)+ scale_color_manual(values = c(&quot;black&quot;, &quot;red3&quot;)) 図6.9: Pearson residuals plotted versus fitted values for the negative binomial GAM in Equation (6.8). The values plotted with a red dot are observations for which the gannet abundance exceeds 25. また、残差に空間的な相関がないかを確かめるため、ピアソン残差を利用したバリオグラムを描いたのが図6.10である。図からは、深刻な空間的相関があるようには見えない。 mydata &lt;- data.frame(resid = resid(M6_8, type = &quot;pearson&quot;), Xkm = Gannets2$Xkm, Ykm = Gannets2$Ykm) sp::coordinates(mydata) &lt;- c(&quot;Xkm&quot;,&quot;Ykm&quot;) Vario_M6_8 &lt;- variogram(resid ~ 1, mydata, cutoff = 5, robust = TRUE) Vario_M6_8 %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(aes(size = np))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(y = &quot;Semi-variogram&quot;, x = &quot;Distance (km)&quot;) 図6.10: Sample variogram of Pearson residuals from the negative binomial GAM. Point size is proportional to the number of combinations of sites used for calculating the sample variogram at a particular distance. 推定されたte(DayInYear, Time)のsmootherは以下のとおりである(図6.11。解釈は難しいが、日付や時刻によってばらつきがかなりあることが分かる。 smooth_estimates(M6_8, smooth = &quot;te(Time,DayInYear)&quot;) %&gt;% plot_ly() %&gt;% add_trace(x = ~DayInYear, y = ~Time, z = ~est, type = &quot;mesh3d&quot;) 図6.11: Estimated sm oothers te(DayInYear, TimeH) for the negative binomial GAM. 推定されたte(Xkm, Ykm)のsmootherは以下のとおりである図6.12)。こちらは、南西のエリアでカツオドリがよく目撃されていることを示している。 smooth_estimates(M6_8, smooth = &quot;te(Xkm,Ykm)&quot;) %&gt;% plot_ly() %&gt;% add_trace(x = ~Xkm, y = ~Ykm, z = ~est, type = &quot;mesh3d&quot;) 図6.12: Estimated smoot hers te(Xkm, Ykm) for the negative binomial GAM. 観察年(Year)のsmootherは図6.13の通り。カツオドリの数は1993年から1997年ごろにかけて急増し、その後減少したが2000年ごろからもう一度増加するというパターンをとっていた。 smooth_estimates(M6_8, smooth = &quot;s(Year)&quot;) %&gt;% add_confint() %&gt;% ggplot(aes(x = Year, y = est))+ geom_line()+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_x_continuous(breaks = seq(1991,2006,by=2)) 図6.13: Estimated smoothers s(Y ear) for the negative binomial GAM. 6.6 Zero-inflated GAM 前節で適用した負の二項分布モデルは依然として過分散であった。過分散には様々な原因があるが、 Zuur et al. (2012) は外れ値、必要な共変量が入っていない、交互作用がひっていない、リンク関数が誤っている、目的変数のばらつきが大きすぎる、時空間的な相関がモデルで考慮されていない、ゼロ過剰などが過分散の要因の大部分を占めると論じている。 空間的な相関とゼロ過剰はしばしば交絡しやすい(隣のトランゼクトが0を持つ確率が高くなるなど)[Zuur2012b]。そのため、空間的な構造を考慮したGAMをモデリングすることも可能である(e.g., CARモデルなど)。一方で、ゼロ過剰モデルを作ることも可能である。両方を適用すると問題が生じることが多いので、生物学的な知識に基づいてどちらを適用すべきか決める必要がある。 空間的な相関を取り入れるモデルはベイズ統計を必要とし、本稿の範囲を超えるので今回はゼロ過剰モデルを適用する。 6.6.1 A zero-inflated model for the gannet data ゼロ過剰モデルにはいくつかの種類があるが、ここではいわゆる混合モデル(mixture model)を適用する。混合モデルは偽物のゼロと真のゼロを区別する。偽物のゼロは、サンプリングが間違ったときに行われた(e.g., カツオドリがいない冬に観察を行った)、観察エラー(e.g., 天候などで視界が悪い)、動物のエラー(e.g., カツオドリがいるはずだがいなかった)などのときに生じる。真のゼロはそうした要因以外に動物がいないときに生じる。 混合ゼロ過剰モデルでは2つのGLM(またはGAM)がくっつけられている。真のゼロとゼロより大きい値に対して適用するポワソンまたは負の二項GLM(GAM)とそれでは説明できない偽物のゼロに対して適用される二項分布モデルである。詳しくはこちらや Zuur et al. (2012) も参照。 混合ゼロ過剰モデルでは、まず偽物のゼロが得られる確率\\(\\pi_i\\)を二項分布モデルでモデリングする。ここでは、\\(\\pi_i\\)が一つのパラメータ\\(\\gamma\\)のみで決まると仮定しているが、様々な共変量によって変化するとモデリングすることも可能である(e.g., \\(logit(\\pi_i) = \\gamma_0 + \\gamma_1 \\times Seastate_i + f_\\gamma(Year)\\))。これは、生物学的知識に基づいて行われる必要がある。 \\[ \\begin{aligned} logit(\\pi_i) &amp;= \\gamma\\\\ \\end{aligned} \\] そのうえで、ゼロ過剰モデルでは偽物のゼロ以外(真のゼロと0より大きい値)についてポワソン分布または負の二項分布を適用する。例えばポワソン分布を適用するとき、平均\\(\\mu_i\\)のポワソン分布で値\\(Y_i\\)をとる確率は\\(P(Y_i|\\mu_i) = \\frac{\\mu_i^{Y_i} \\times r^{-\\mu_i}}{Y_i!}\\)なので、真のゼロが得られる確率は以下のようになる。 \\[ \\frac{\\mu_i^0 \\times e^{-\\mu_i}}{0!} = e^{-\\mu_i} \\] よって、ゼロ過剰モデルでゼロ(偽物+真)が得られる確率は、偽物のゼロ以外が得られる確率が\\(1-\\pi_i\\)であることを考えると以下のようになる。 \\[ \\pi_i + (1-\\pi_i) \\times e^{-\\mu_i} \\] ゼロ以外の値についてはポワソン分布や負の二項分布が通常通り適用される。合わせると、ゼロ過剰ポワソンGAMのモデル式は以下のように書ける。なお、\\(G_i \\sim ZIP(\\mu_i, \\pi_i)\\)はポワソン分布の平均が\\(\\mu_i\\)、偽物のゼロが得られる確率が\\(\\pi_i\\)の混合モデルからカツオドリの数が得られることを指す。 \\[ \\begin{aligned} G_i &amp;\\sim ZIP(\\mu_i, \\pi_i)\\\\ log(\\mu_i) &amp;= \\alpha + f_1(Year_i) + f_2(Times_i, DayInYear_i) + f_3(X_i,Y_i) + \\beta \\times Seastate_i + LSA_i \\\\ logit(\\pi_i) &amp;= \\gamma\\\\ E(G_i) &amp;= (1-\\pi_i) \\times \\mu_i \\;\\; and \\;\\;var(G_i) = (1-\\pi_i) \\times(\\mu_i + \\pi_i \\times \\mu_i)\\\\ \\end{aligned} \\tag{6.4} \\] ゼロ過剰GAMを実行できるRパッケージはCOZIGAM、VGAM、gamlssなどがあるが、本章ではgamlssパッケージを用いて実行する。 ⇒ 現在ではmgvcパッケージでもゼロ過剰ポワソン分布がサポートされているが、リンク関数は恒等関数しかないよう。 6.6.2 ZIP GAM using gamlss 2次元smootherを導入するためには、gamlssのヘルパーパッケージであるgamlss.addも読み込む必要がある。以下、式(6.4)のモデル式をRで実行したものである。gamlssではmgcvのように交差検証による自由度の選択は行ってくれず、使用者が上限を指定する必要がある。以下のモデルでは、M6_8の結果をもとに自由度を\\(k =\\)で指定している。2次元smootherはga(~te(Time, DayInYear))のように式に加える。座標の2次元smootherはte(Xkm,Ykm)とするとエラーが出て実行できなかったので、s(Xkm,Ykm)。これらの変数は異なるスケールを持つため、前述したようにこれは問題になりうる。 モデルは収束せず…。 ## iterationの数を設定 con &lt;- gamlss.control(n.cyc = 200) #M6_9 &lt;- gamlss(G ~ cs(Year, df = 8) + ga(~te(Time, DayInYear, fx = TRUE, k = 28)) + # ga(~s(Xkm,Ykm, fx = TRUE, k=28)) + factor(Seastate) + offset(LArea), # family = ZIP(), data = Gannets2, control = con) ベイズモデリングでの実装はbrmsパッケージでできる。brmsではテンソル積smootherとしてte()は実装していないが、代わりにt2()が使える。詳しくはこちら。 以下のように実行できる。こちらもかなり長い時間を要する。 ## 高速化オプション rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) M6_9 &lt;- brm(G ~ s(Year) + t2(Time, DayInYear) + t2(Xkm, Ykm) + offset(LArea) + factor(Seastate), family = &quot;zero_inflated_poisson&quot;, data = Gannets2, backend = &quot;cmdstanr&quot;, control=list(adapt_delta = 0.99, max_treedepth = 15), file = &quot;result/M6_9&quot;) 結果は以下の通り。Population Effect Levelとして推定されているのは回帰係数のようだ。sdsの部分はsmootherの自由度のようなものを推定しているよう。詳しい見方は不明である。偽物のゼロが得られる確率(zi)は0.75と推定された。 summary(M6_9) ## Family: zero_inflated_poisson ## Links: mu = log; zi = identity ## Formula: G ~ s(Year) + t2(Time, DayInYear) + t2(Xkm, Ykm) + offset(LArea) + factor(Seastate) ## Data: Gannets2 (Number of observations: 12820) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(sYear_1) 13.19 3.51 7.66 21.21 1.00 1338 ## sds(t2TimeDayInYear_1) 34.80 8.09 22.89 54.08 1.00 1164 ## sds(t2TimeDayInYear_2) 16.93 4.66 10.43 28.85 1.00 1749 ## sds(t2TimeDayInYear_3) 10.91 3.31 6.29 18.58 1.00 1835 ## sds(t2XkmYkm_1) 10.72 2.92 6.43 17.95 1.00 1592 ## sds(t2XkmYkm_2) 10.27 3.03 6.23 17.55 1.00 1807 ## sds(t2XkmYkm_3) 1.30 1.11 0.05 4.18 1.00 1473 ## Tail_ESS ## sds(sYear_1) 1959 ## sds(t2TimeDayInYear_1) 1567 ## sds(t2TimeDayInYear_2) 2149 ## sds(t2TimeDayInYear_3) 2069 ## sds(t2XkmYkm_1) 1986 ## sds(t2XkmYkm_2) 2297 ## sds(t2XkmYkm_3) 2375 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.14 0.09 0.97 1.31 1.00 2258 2668 ## factorSeastate1 0.01 0.05 -0.08 0.10 1.00 3162 2939 ## factorSeastate2 -0.12 0.05 -0.21 -0.03 1.00 3345 3108 ## factorSeastate3 -0.33 0.05 -0.42 -0.23 1.00 2941 2916 ## factorSeastate4 -0.54 0.05 -0.64 -0.44 1.00 3047 3143 ## factorSeastate5 -0.57 0.06 -0.70 -0.45 1.00 3820 3365 ## factorSeastate6 -1.03 0.11 -1.25 -0.82 1.00 5619 3356 ## sYear_1 2.66 2.94 -3.00 8.29 1.00 5011 3299 ## t2TimeDayInYear_1 -0.07 0.04 -0.14 0.00 1.00 2325 2198 ## t2TimeDayInYear_2 -0.08 0.05 -0.17 0.01 1.00 1744 2530 ## t2TimeDayInYear_3 0.03 0.03 -0.04 0.09 1.00 1836 2197 ## t2XkmYkm_1 0.07 0.07 -0.07 0.20 1.00 2480 2339 ## t2XkmYkm_2 -0.32 0.06 -0.45 -0.21 1.00 1938 1917 ## t2XkmYkm_3 -0.09 0.10 -0.27 0.11 1.00 2066 1708 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## zi 0.75 0.00 0.74 0.76 1.00 6762 2642 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). DHARMaパッケージを用いて過分散の検定を行うことができる。その結果、過分散はまだ解消されていないようだ。 testDispersion(dh_check_brms(M6_9, plot = FALSE)) ## ## DHARMa nonparametric dispersion test via sd of residuals fitted vs. ## simulated ## ## data: simulationOutput ## dispersion = 8.3151, p-value &lt; 2.2e-16 ## alternative hypothesis: two.sided 次のオプションとして、ゼロ過剰負の二項分布のGAMを用いることができる。brmsのみで実装できるようだ。こちらも長い時間を要する。 Gannets2 &lt;- Gannets2 %&gt;% mutate(fSeastate = factor(Seastate)) M6_10 &lt;- brm(G ~ s(Year) + t2(Time, DayInYear) + t2(Xkm, Ykm) + offset(LArea) + fSeastate, family = &quot;zero_inflated_negbinomial&quot;, data = Gannets2, backend = &quot;cmdstanr&quot;, control=list(adapt_delta = 0.99, max_treedepth = 15), file = &quot;result/M6_10&quot;) 結果は以下の通り。偽物のゼロが得られる確率はほとんどない(0.01)と推定されている。 summary(M6_10) ## Family: zero_inflated_negbinomial ## Links: mu = log; shape = identity; zi = identity ## Formula: G ~ s(Year) + t2(Time, DayInYear) + t2(Xkm, Ykm) + offset(LArea) + fSeastate ## Data: Gannets2 (Number of observations: 12820) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Smooth Terms: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sds(sYear_1) 5.85 2.33 2.54 11.59 1.00 1156 ## sds(t2TimeDayInYear_1) 2.78 1.78 0.68 7.21 1.00 990 ## sds(t2TimeDayInYear_2) 7.55 2.77 3.73 14.43 1.00 1492 ## sds(t2TimeDayInYear_3) 1.58 1.16 0.07 4.36 1.00 1174 ## sds(t2XkmYkm_1) 1.56 1.25 0.06 4.62 1.01 1062 ## sds(t2XkmYkm_2) 7.10 2.29 3.65 12.57 1.00 1456 ## sds(t2XkmYkm_3) 4.00 1.88 0.88 8.37 1.00 924 ## Tail_ESS ## sds(sYear_1) 2206 ## sds(t2TimeDayInYear_1) 1679 ## sds(t2TimeDayInYear_2) 1711 ## sds(t2TimeDayInYear_3) 1515 ## sds(t2XkmYkm_1) 1911 ## sds(t2XkmYkm_2) 2343 ## sds(t2XkmYkm_3) 710 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept -0.63 0.16 -0.93 -0.31 1.00 1092 1825 ## fSeastate1 0.37 0.13 0.10 0.62 1.00 1707 2531 ## fSeastate2 -0.13 0.12 -0.38 0.10 1.00 1625 2650 ## fSeastate3 -0.03 0.12 -0.27 0.19 1.00 1555 2198 ## fSeastate4 -0.31 0.12 -0.56 -0.07 1.00 1602 2554 ## fSeastate5 -0.13 0.15 -0.43 0.16 1.00 1905 2726 ## fSeastate6 -0.45 0.20 -0.84 -0.06 1.00 2623 3123 ## sYear_1 -1.79 4.36 -10.67 6.57 1.00 2574 2470 ## t2TimeDayInYear_1 -0.29 0.06 -0.40 -0.18 1.00 1879 2447 ## t2TimeDayInYear_2 -0.04 0.06 -0.16 0.08 1.00 2452 2694 ## t2TimeDayInYear_3 -0.08 0.05 -0.17 0.03 1.00 2185 2875 ## t2XkmYkm_1 0.30 0.13 0.06 0.56 1.00 934 1512 ## t2XkmYkm_2 -0.52 0.11 -0.73 -0.31 1.00 832 1165 ## t2XkmYkm_3 -0.35 0.18 -0.73 -0.01 1.00 869 1402 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## shape 0.15 0.00 0.14 0.16 1.00 5725 3006 ## zi 0.01 0.01 0.00 0.03 1.00 3312 2424 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). DHARMaパッケージを用いて過分散の検定を行うことができる。過分散はかなり改善されたがまだ少し残っているようだ。 testDispersion(dh_check_brms(M6_10, plot = FALSE)) ## ## DHARMa nonparametric dispersion test via sd of residuals fitted vs. ## simulated ## ## data: simulationOutput ## dispersion = 2.7193, p-value = 0.012 ## alternative hypothesis: two.sided 年のsmoother(s(Year))の推定結果は以下のようになる(図6.14)。M6_8とほとんど変わらない。 plot(conditional_smooths(M6_10, smooths = &quot;s(Year)&quot;)) -&gt; p_Year 図6.14: Estimated smoother of s(Year) based on M6_10 緯度と経度の2次元smoother(t2(Xkm,Ykm))の推定結果は以下のようになる(図6.15)。 conditional_effects(M6_10, effects = &quot;Xkm:Ykm&quot;)[[1]] %&gt;% plot_ly() %&gt;% add_trace(x = ~Xkm, y = ~Ykm, z = ~estimate__, type = &quot;mesh3d&quot;) 図6.15: Estimated smoother of t2(Xkm,Ykm) based on M6_10 最後に、時刻と日付の2次元smoother(t2(Time,DayInYear))の推定結果は以下のようになる(図6.15)。 conditional_effects(M6_10, effects = &quot;Time:DayInYear&quot;)[[1]] %&gt;% plot_ly() %&gt;% add_trace(x = ~Time, y = ~DayInYear, z = ~estimate__, type = &quot;mesh3d&quot;) 図6.16: Estimated smoother of t2(Time,DayInYear) based on M6_10 6.7 Discussion ここまで様々なモデルを適用してきたが、過分散は解消できなかった。過分散の要因としては、共変量やその交互作用が不足しているものが考えられる。しかし、モデルに交互作用を加えると推定にかなり時間を要することになるだろう。 References "],["Chapter7.html", "7 Generalized Additive Models applied on parasites of Argentine hake 7.1 Parasites of Argentine hake in the Argentine Sea", " 7 Generalized Additive Models applied on parasites of Argentine hake 7.1 Parasites of Argentine hake in the Argentine Sea Sardella and Timi (2004) は、4か所のアルゼンチン沖に生息するメルルーサ(hake, Merluccius hubbsi)の寄生虫を調べ、それをもとにメルルーサの個体群を分別することができるかを調べた。メルルーサは乱獲によって激減しており、メルルーサがどの個体群から来たものなのかを識別することは個体群の維持にとって重要である。 魚334匹が4か所(アルゼンチン-ウルグアイ間、サン・ジョージ湾、パタゴニアン大陸棚、サン・マティアス湾)でトロール網によって捕獲され、26種の寄生虫が発見された。本章では、Elytrophalloides oatesiという吸虫の有無を二項分布のGAMによってモデリングする。リサーチクエスチョンは、吸虫の有無が魚のサイズ、性別、捕獲場所によって影響を受けるかである。 References "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] parallel splines stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] fontregisterer_0.3 systemfonts_1.0.4 ## [3] extrafont_0.18 gganimate_1.0.8 ## [5] lemon_0.4.6 ggsci_2.9 ## [7] concaveman_1.1.0 ggforce_0.4.1 ## [9] ggdag_0.2.7 dagitty_0.3-1 ## [11] kableExtra_1.3.4 knitr_1.43 ## [13] DT_0.27 patchwork_1.1.2 ## [15] GGally_2.1.2 ggnewscale_0.4.9 ## [17] htmlwidgets_1.6.2 plotly_4.10.1 ## [19] sp_1.5-1 data.table_1.14.6 ## [21] see_0.7.5.5 report_0.5.7.4 ## [23] parameters_0.20.3 performance_0.10.3 ## [25] modelbased_0.8.6.3 insight_0.19.1.4 ## [27] effectsize_0.8.3.6 datawizard_0.7.1.1 ## [29] correlation_0.8.4 bayestestR_0.13.1 ## [31] easystats_0.6.0.8 forcats_1.0.0 ## [33] stringr_1.5.0 dplyr_1.1.2 ## [35] purrr_1.0.0 readr_2.1.3 ## [37] tidyr_1.2.1 tibble_3.2.1 ## [39] ggplot2_3.4.2 tidyverse_1.3.2 ## [41] DHARMa.helpers_0.0.0.9000 DHARMa_0.4.6 ## [43] cmdstanr_0.5.3 rstan_2.26.13 ## [45] StanHeaders_2.26.13 brms_2.18.0 ## [47] Rcpp_1.0.11 gstat_2.1-1 ## [49] gratia_0.8.1.34 gamlss_5.4-12 ## [51] gamlss.dist_6.0-5 MASS_7.3-58.1 ## [53] gamlss.data_6.0-2 mgcv_1.8-41 ## [55] nlme_3.1-160 ## ## loaded via a namespace (and not attached): ## [1] utf8_1.2.2 tidyselect_1.2.0 lme4_1.1-31 ## [4] grid_4.2.2 munsell_0.5.0 codetools_0.2-18 ## [7] miniUI_0.1.1.1 withr_2.5.0 Brobdingnag_1.2-9 ## [10] colorspace_2.0-3 highr_0.10 rstudioapi_0.15.0 ## [13] stats4_4.2.2 Rttf2pt1_1.3.8 bayesplot_1.10.0 ## [16] labeling_0.4.2 emmeans_1.8.3 polyclip_1.10-4 ## [19] bit64_4.0.5 farver_2.1.1 bridgesampling_1.1-2 ## [22] coda_0.19-4 vctrs_0.6.2 generics_0.1.3 ## [25] xfun_0.39 timechange_0.1.1 R6_2.5.1 ## [28] markdown_1.7 reshape_0.8.9 cachem_1.0.6 ## [31] assertthat_0.2.1 vroom_1.6.0 promises_1.2.0.1 ## [34] scales_1.2.1 googlesheets4_1.0.1 gtable_0.3.3 ## [37] processx_3.8.0 ggokabeito_0.1.0 tidygraph_1.2.2 ## [40] rlang_1.1.1 extrafontdb_1.0 lazyeval_0.2.2 ## [43] gargle_1.2.1 broom_1.0.2 checkmate_2.1.0 ## [46] inline_0.3.19 yaml_2.3.7 reshape2_1.4.4 ## [49] abind_1.4-5 modelr_0.1.10 threejs_0.3.3 ## [52] crosstalk_1.2.0 backports_1.4.1 httpuv_1.6.7 ## [55] tensorA_0.36.2 tools_4.2.2 bookdown_0.34 ## [58] ellipsis_0.3.2 RColorBrewer_1.1-3 jquerylib_0.1.4 ## [61] posterior_1.3.1 plyr_1.8.8 progress_1.2.2 ## [64] base64enc_0.1-3 ps_1.7.2 prettyunits_1.1.1 ## [67] zoo_1.8-11 haven_2.5.1 fs_1.5.2 ## [70] magrittr_2.0.3 magick_2.7.4 spacetime_1.3-0 ## [73] colourpicker_1.2.0 reprex_2.0.2 mvnfast_0.2.8 ## [76] googledrive_2.0.0 mvtnorm_1.1-3 matrixStats_0.63.0 ## [79] hms_1.1.3 shinyjs_2.1.0 mime_0.12 ## [82] evaluate_0.20 xtable_1.8-4 shinystan_2.6.0 ## [85] readxl_1.4.1 gridExtra_2.3 rstantools_2.2.0 ## [88] compiler_4.2.2 V8_4.2.2 crayon_1.5.2 ## [91] minqa_1.2.5 htmltools_0.5.4 later_1.3.0 ## [94] tzdb_0.3.0 RcppParallel_5.1.6 lubridate_1.9.0 ## [97] DBI_1.1.3 tweenr_2.0.2 dbplyr_2.2.1 ## [100] boot_1.3-28 Matrix_1.5-1 cli_3.6.0 ## [103] igraph_1.3.5 pkgconfig_2.0.3 xml2_1.3.3 ## [106] svglite_2.1.1 dygraphs_1.1.1.6 bslib_0.4.2 ## [109] webshot_0.5.4 estimability_1.4.1 rvest_1.0.3 ## [112] distributional_0.3.2 callr_3.7.3 digest_0.6.31 ## [115] rmarkdown_2.23 cellranger_1.1.0 intervals_0.15.4 ## [118] curl_4.3.3 shiny_1.7.4 gtools_3.9.4 ## [121] nloptr_2.0.3 lifecycle_1.0.3 jsonlite_1.8.4 ## [124] viridisLite_0.4.2 fansi_1.0.3 pillar_1.9.0 ## [127] lattice_0.20-45 loo_2.5.1 fastmap_1.1.0 ## [130] httr_1.4.4 pkgbuild_1.4.0 survival_3.5-5 ## [133] glue_1.6.2 xts_0.12.2 FNN_1.1.3.2 ## [136] shinythemes_1.2.0 bit_4.0.5 stringi_1.7.8 ## [139] sass_0.4.5 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
