[["index.html", "Introduction to GAM using R 本稿の目的", " Introduction to GAM using R Tsubasa Yamaguchi 2023-07-13 本稿の目的 本稿で扱うのは、以下の内容である。 参考にしたのは主に以下の文献である。 なお、本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿では、基本的にネットワークデータのハンドリングにはtidygraphパッケージを用いる。このパッケージを使うことで、データフレームとしてネットワークデータを扱うことができるので非常に便利である。ネットワークグラフの描画にはggraphパッケージを用いる。このパッケージでは、基本的にggplot2と同じ文法でネットワークグラフを描くことができる。 各指標の算出や統計分析には、主にasnipeパッケージ、ANTsパッケージ、igraphパッケージ、snaパッケージを用いる。 tidygraph ggraph asnipe(Farine, 2013) ANTS(Sosa et al., 2020) igraph(Csardi et al., 2006) sna(Butts, 2008) ## GAM library(mgcv) library(tidygraph) library(ggraph) library(asnipe) library(sna) library(ANTs) library(igraph) library(clValid) library(assortnet) library(hwig) ## データハンドリング library(tidyverse) library(easystats) library(data.table) ## グラフや表関連 library(plotly) library(GGally) library(patchwork) library(DT) library(knitr) library(kableExtra) library(dagitty) library(ggdag) library(ggforce) library(concaveman) library(ggsci) library(lemon) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Butts, C. T. (2008). Social network analysis with sna. J. Stat. Softw., 24, 1–51. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Csardi, G., Nepusz, T., &amp; Others. (2006). The igraph software package for complex network research. InterJournal, Complex Systems, 1695(5), 1–9. Farine, D. R. (2013). Animal social network inference and permutations for ecologists inRusingasnipe. Methods Ecol. Evol., 4(12), 1187–1194. Sosa, S., Puga-Gonzalez, I., Hu, F., Pansanel, J., Xie, X., &amp; Sueur, C. (2020). A multilevel statistical toolkit to study animal social networks: The animal network toolkit software (ANTs) R package. Sci. Rep., 10(1), 12507. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 Review of multiple linear regressions 1.1 Light levels and size of the human visual system 1.2 The variables 1.3 Protocol for the analysis 1.4 Data exploration 1.5 Multiple linear regression 1.6 Finding the optimal model 1.7 Degree of freedom 1.8 Model validation 1.9 Model interpretation", " 1 Review of multiple linear regressions 本章では、一般化加法モデル(GAM)の説明に入る前に、多くの人に馴染みのある重回帰分析(multiple linear regression)について説明する、なぜなら、GAMは重回帰分析を拡張したものだからである。 1.1 Light levels and size of the human visual system Pearce &amp; Dunbar (2012) は、ヒトの集団が住んでいる標高と眼窩の容量に正の関連があることから、住んでいる環境の光量がヒトの視覚システムの進化の原動力になっていると結論付けた。本章ではこの論文のデータを用いて重回帰分析について説明を行う。重回帰分析でデータを探索し、モデルを構築し、モデルを当てはめ、モデル選択を行い、モデルの妥当性を確認する方法はGAMでもほとんど同じように適用できる。 1.2 The variables Pearce &amp; Dunbar (2012) は、オックスフォード大学博物館にある55人の成人の頭蓋骨から、頭蓋の容量(cranial capacity: CC)と眼窩容量(orbital volume)、大後頭孔(foramen magnum: FM)などの測定を行った。 データは以下のとおりである。平均眼窩容量(mean orbital volume)が目的変数であり、それ以外の変数は説明変数である1。AbsoluteLatitudeとMinimum_Tempreture_celsiusはそれぞれ 頭蓋が発見された場所の標高と最低気温、FMarea_intercondyleは体格の大きさを示す指標、Minimum_Illuminanceはlogスケールで表した光の強度、Genderは頭蓋の性別である。 hvs &lt;- read_delim(&quot;data/HVS.txt&quot;) datatable(hvs, filter = &quot;top&quot;, options = list(scrollX = 20)) 変数名が長いので、以下のように短く変更する。 hvs %&gt;% rename(OrbitalV = MeanOrbitalVolume, LatAbs = AbsoluteLatitude, CC = CranialCapacity, Illuminance = Minimum_Illuminance, Temperature = Minimum_Temperature_celsius, FM = FMarea_intercondyle) %&gt;% mutate(fPopulation = factor(Population), fGender = factor(Gender)) -&gt; hvs 新しい列名は以下の通り。 colnames(hvs) ## [1] &quot;Museum&quot; &quot;Findsite&quot; &quot;Gender&quot; &quot;Population&quot; &quot;Latitude&quot; ## [6] &quot;LatAbs&quot; &quot;CC&quot; &quot;FM&quot; &quot;OrbitalV&quot; &quot;Illuminance&quot; ## [11] &quot;Temperature&quot; &quot;fPopulation&quot; &quot;fGender&quot; 1.3 Protocol for the analysis いかなるデータ分析も、以下の手順に沿って行わなければならない。 Data exploration 外れ値がないか、多重共線性(説明変数同士の強い相関)がないか、目的変数と説明変数の関係がどうか、ゼロ過剰はないか、サンプリングの収集が時間や場所によってばらついていないか、などをチェックする必要がある。 Model application 1の作業で分かったことや研究仮説をもとに、適切なモデルを適用する。今回は重回帰分析を行うが、様々なモデルを適用可能である。 Check the result モデルを当てはめたら、どの変数が有意な影響を持つかを調べ、そうでなかった変数についてはどうするかを考える。 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。満たしていれば結果の解釈や結果の作図を行い、満たしていなければモデルを改善する必要がある(GAM、GLM、GLMを使うなど)。 1.4 Data exploration まずは手順1のデータ探索を行う。データ探索については Zuur et al. (2010) に詳しい。 1.4.1 欠損値の確認 まず、欠損値がないかを調べる。 colSums(is.na(hvs)) ## Museum Findsite Gender Population Latitude LatAbs ## 0 0 0 0 0 0 ## CC FM OrbitalV Illuminance Temperature fPopulation ## 0 1 0 0 0 0 ## fGender ## 0 FMの列に1つ欠損値があるので取り除く。 hvs_b &lt;- na.omit(hvs) 1.4.2 外れ値の確認 続いて、外れ値がないかを確認する。ここでは、連続値の説明変数(Latitude、CC、FM、Illuminance、Temperature)についてCleveland Dotplotを作成する。Dotplotは縦軸にサンプル番号、横軸に実際の値をとる。 図は以下のとおりである(図1.1)。図を見る限り、外れ値はなさそうだ。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature) %&gt;% mutate(sample_number = 1:n()) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = sample_number))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Values of the variable&quot;, y = &quot;Sample number&quot;)+ theme(aspect.ratio = 1) 図1.1: Cleveland dotplot for covariates. 1.4.3 多重共線性の確認 次に、多重共線性(説明変数同士の強い相関)がないかを調べる。もしあると、推定結果にバイアスが生じてしまう。 説明変数同士の関連を調べたところ(図1.2)、LatAbsとIlluminance、IlluminanceとTemperature、TemperatureとLatAbsに強い相関があることが分かる。また、CCは男性で高い傾向があることが分かったので、CCとfGenderを同じモデルに説明変数として入れない方がよさそうである(今回はfGenderを用いない)。 ggpairs(hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, fGender)) 図1.2: correlation between covariates 1.4.4 目的変数と説明変数の関係の確認 最後に、目的変数と説明変数の関連を調べる(図1.3)。図には局所回帰(LOESS)による回帰曲線を追加している。 図から、LatAbsとOrbitalVの間に線形の関係がありそうだということが分かる(’CC’も?)。IlluminanceやTemperatureにも同様のことがいえるが、これは変数間に強い相関があることを考えれば当然だろう。多重共線性を考慮し、Pearce &amp; Dunbar (2012) にもとづいて解析ではLatAbsを用いてIlluminanceとTemperatureは用いないこととする。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, OrbitalV) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = OrbitalV))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Explanatory Variables&quot;, y = &quot;OrbitalV&quot;)+ theme(aspect.ratio = 1)+ geom_smooth(method = &quot;loess&quot;, se= F, color = &quot;grey32&quot;, span = 0.9) 図1.3: Relationship between explanatory variables and orbital volume (OrbitalV). A LOESS smoother was added to the plot. 1.5 Multiple linear regression 1.5.1 Underlying statistical theory それでは、重回帰分析を行う。まずは説明のために説明変数が1つだけのモデル(= 単回帰)を考えよう。 標高のみを説明変数とする単回帰モデルは以下のように実行できる。 M1 &lt;- lm(OrbitalV ~ LatAbs, data = hvs_b) summary(M1) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9893 -1.4166 -0.1616 1.5037 3.8887 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.91064 0.51412 44.563 &lt; 2e-16 *** ## LatAbs 0.06598 0.01411 4.677 2.11e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.253 on 52 degrees of freedom ## Multiple R-squared: 0.2961, Adjusted R-squared: 0.2825 ## F-statistic: 21.87 on 1 and 52 DF, p-value: 2.111e-05 これは、実際には何をやっているのだろうか? lm関数で短回帰を実行するとき、私たちは下記のモデルを実行している。なお、\\(i\\)はサンプル番号(今回は55個の頭蓋がある)を、2行目は\\(\\epsilon_i\\)が平均0、分散\\(\\sigma^2\\)の正規分布に従うことを表す。 \\[ \\begin{aligned} OrvitalV_i &amp;= \\alpha + \\beta\\times LatAbs_i + \\epsilon_i \\;\\; (i = 1,2,\\dots, 55)\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルで推定するパラメータは\\(\\alpha\\)、\\(\\beta\\)、\\(\\sigma\\)である。\\(\\beta\\)は標高(LatAbs)が眼窩容量(OrbitalV)に与える影響の大きさを表し、式からわかるように標高が1増えると眼窩容量が\\(\\beta\\)増えることを表す。先ほどlm関数で実行した結果でEstimateの下に書かれていた数字(\\(22.91...と0.065...\\))は\\(\\alphaと\\beta\\)の推定値を示しているのである。 もし以下のように行列を定義すると、 \\[ \\begin{aligned} \\mathbf{y} = \\begin{pmatrix} OrbitalV_1\\\\ OrbitalV_2\\\\ \\vdots\\\\ OrvitalV_{55} \\end{pmatrix} , \\mathbf{X} = \\begin{pmatrix} 1 &amp; LatAbs_1\\\\ 1 &amp; LatAbs_2\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; LatAbs_{55} \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_{55} \\end{pmatrix} \\end{aligned} \\] モデル式は以下のように書ける。 \\[ \\mathbf{y = X\\times\\beta + \\epsilon} \\] \\(\\mathbf{X}\\)はRで以下のように求められる。 head(model.matrix(M1)) ## (Intercept) LatAbs ## 1 1 1.33 ## 2 1 5.42 ## 3 1 5.42 ## 4 1 28.51 ## 5 1 28.51 ## 6 1 28.51 パラメータは最小二乗法(ordinary least square)で求められる。最小二乗法は、残差の二乗和(実際の測定値と推定されたモデルによる予測値の差、ここでは\\(\\sum_i^{55}( y_i - \\alpha + \\beta \\times OrbitalV_i)\\))が最小になるようにパラメータを推定する方法である。 \\(bfmath(\\beta)\\)の推定値は数学的に以下のように求められる。なお、\\(\\mathbf{X^t}\\)は\\(\\mathbf{X}\\)の転置行列を、\\(\\mathbf{X^{-1}}\\)はは\\(\\mathbf{X}\\)の逆行列を表す。 \\[ \\mathbf{\\hat{\\beta}} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\tag{1.1} \\] なお、\\(\\mathbf{\\hat{\\beta}}\\)は\\(\\mathbf{\\beta}\\)の推定値であることを表し、便宜的にここでは\\(\\mathbf{\\hat{\\beta}} = \\begin{pmatrix}a\\\\b \\end{pmatrix}\\)とする。 Rでは\\(\\mathbf{\\hat{\\beta}}\\)を以下のように求められ、lm関数で推定した場合と同じ推定値が得られることが分かる。 X &lt;- model.matrix(M1) solve(t(X) %*% X) %*% t(X) %*% hvs_b$OrbitalV ## [,1] ## (Intercept) 22.9106427 ## LatAbs 0.0659754 よって、モデルによって推定された眼窩容量(\\(\\hat{y_i}\\))は以下のように表せる。 \\[ Fitted OrbitalV_i = 22.930 + 0.066 \\times LatAbs_i \\] すなわち、モデルの推定値から得られた残差\\(e_i\\)は以下のように表せる。 \\[ e_i = OrbitalV_i - a + b\\times LatAbs_i \\] \\(\\mathbf{\\hat{y}} = \\mathbf{X}\\times \\mathbf{\\beta}\\)と書けるので、残差の行列\\(\\mathbf{e}\\)は\\(\\mathbf{H} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t}\\)とするとき以下のように書ける。 \\[ \\mathbf{e} = \\mathbf{y} - \\mathbf{\\hat{y}} = \\mathbf{y} - \\mathbf{H\\times y} = \\mathbf{(1-H)\\times y} \\tag{1.2} \\] モデル式より、\\(\\mathbf{y}\\)の分散共分散行列は\\(\\sigma^2 \\times \\mathbf{I}\\)と表せるので(\\(\\mathbf{I}\\)は単位行列)、\\(\\mathbf{e}\\)の分散共分散行列は以下のように表せる。 \\[ cov(\\mathbf{e}) = \\sigma^2 \\times (\\mathbf{1 - H}) \\] また、以下の値を標準化残差(standardized residuals)という。なお、\\(H_{ii}\\)は\\(\\mathbf{H}\\)の\\(i\\)番目の対角成分を表す。 \\[ e_i ^* = \\frac{e_i}{\\hat{\\sigma} \\sqrt{(1-H_{ii})}} \\] もしモデルが正しいとき、標準化残差は標準正規分布に従うので、その値のほとんどは-2から2の間に収まるはずである。 Rでは、残差と標準化残差を以下のように求められる。 e &lt;- resid(M1) estd &lt;- rstandard(M1) 実際、1つのデータを除いて-2から2の範囲に収まっている(図1.4)。 data.frame(estd = estd) %&gt;% ggplot(aes(x = estd))+ geom_histogram(binwidth = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_y_continuous(breaks = seq(0,10,1)) 図1.4: 標準化残差の分布 1.5.1.1 外れ値のチェック モデルに極端な外れ値がないかを調べるときには、LeverageとCook’s distanceが用いられることが多い。 *everageは\\(\\mathbf{H}\\)の対角成分で0から1の値をとり、大きいほどそのデータポイントが結果に大きな影響を与える外れ値であることを示す。特に極端な値はないよう(図1.5)。 data.frame(h = diag(H), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = h))+ geom_col(width = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Leverage&quot;) 図1.5: Leveragevalue for each observation 式(1.2)より、以下のように書ける。すなわち、\\(i\\)番目の観察に対してモデルから予測される値(fitted value)は元データの観測値の加重平均であり、重みは行列\\(\\mathbf{H}\\)により与えられる。 \\[ \\hat{y_i} = H_{i1} \\times y_1 + H_{i2} \\times y_2 + \\dots + H_{i55} \\times y_55 \\tag{1.3} \\] 特に\\(H_{ii}\\)は観測値\\(y_i\\)がモデルからの予測値\\(\\hat{y_i}\\)に与える影響の大きさを表している。そのため、\\(H_{ii}\\)が高いことは、その観測値がモデルの推定に大きな影響を及ぼしていることを示しているのである。 ある観測値がモデルの推定に影響を与えている度合いを表すのがCook’s distanceで、以下の式で表せる。\\(\\hat{y_{(i)}}\\)は式(1.3)から\\(H_{ii}\\times y_i\\)を除いたものである。また、\\(p\\)はモデルの回帰式の中のパラメータ数である。 \\[ D_i = \\frac{||\\hat{y_i} - \\hat{y_{(i)}}||}{p \\times \\hat{\\sigma^2}} \\] Cook’s distanceはRで以下のように取得できる。 D &lt;- cooks.distance(M1) data.frame(cookD = D, n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cookD))+ geom_col(width = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.6: Cook’s distance for each observation 1.5.1.2 95%信頼区間と予測区間の算出 \\(\\mathbf{\\beta}\\)の推定値の分散共分散行列は\\(\\mathbf{y}\\)の分散共分散行列が\\(\\mathbf{\\sigma^2 \\times I}\\)であることを考えると、式(1.1)より以下のようになる。 \\[ \\begin{aligned} cov(\\mathbf{\\hat{\\beta}}) &amp;= \\mathbf(X^t \\times X)^{-1} \\times \\mathbf{X^t} \\times cov(\\mathbf{y}) \\times \\mathbf{X} \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\\\ &amp;= \\sigma^2 \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\end{aligned} \\] \\(\\hat{\\beta}\\)の標準偏差は上式から得られる行列の対角成分の1/2乗である。この値は、lm関数を利用した結果(Std. Errorの下の数値)と一致する。 SE &lt;-summary(M1)$sigma * sqrt(diag(solve(t(X) %*% X))) SE ## (Intercept) LatAbs ## 0.51411731 0.01410749 95%信頼区間は、モデル式より\\(\\beta\\)が正規分布に従うので以下のように求められる。 Z &lt;- rbind(coef(M1) + 1.96*SE, coef(M1) - 1.96*SE) %&gt;% data.frame() rownames(Z) &lt;- c(&quot;Upper bound&quot;, &quot;Lower bound&quot;) Z ## X.Intercept. LatAbs ## Upper bound 23.91831 0.09362607 ## Lower bound 21.90297 0.03832472 ただし、これはサンプルサイズが十分に大きいときのみ成り立つ。実際は、\\(\\hat{\\beta}\\)は自由度\\(55-2\\)(サンプル数 - パラメータ数)のt分布に従うので、より正確に95%信頼区間を求めるには、1.96ではなく2.005746…を用いる必要がある。 qt(1- 0.05/2, df = 55-2) ## [1] 2.005746 95％信頼区間は、もし100回同様の方法で実験/観察を行ってそれぞれについて95%信頼区間を算出するとき、そのうち95個には真の値が含まれていることを表す。95%信頼区間に0が含まれていないとき、\\(\\hat{\\beta}\\)が有意に0とは違うということができる。 同様に、モデルに基づいた予測値の分散共分散行列は以下のように求められ、その対角成分の1/2乗が予測値の標準誤差(SE)になる。 \\[ cov(\\mathbf{\\hat{y}}) = \\mathbf{X} \\times cov(\\mathbf{\\hat{\\beta}}) \\times \\mathbf{X^t} \\tag{1.4} \\] 予測値の95%信頼区間はある標高(LatAbs)に対して100回データをサンプリングすれば95個のデータが含まれる範囲を表し、予測値が自由度55-2のt分布に従うので、\\(予測値 ± 2.0057 \\times SE\\)で求められる。 一方で95%予測区間は新たにデータをサンプリングしたときにデータの95%が収まる範囲を指す。予測区間を求める際の標準誤差には式(1.4)に\\(\\hat{\\sigma^2}\\)を足したものを用いればよい。 Rでは予測値と95%信頼区間、95%予測区間は以下のように求められる。 ## 係数の分散共分散行列 covbeta &lt;- vcov(M1) data &lt;- data.frame(LatAbs = seq(0,65,length.out = 100)) X &lt;- model.matrix(~LatAbs, data = data) t &lt;- qt(1-0.05/2, df = 55-2) data %&gt;% ## 予測値 mutate(p = X %*% coef(M1)) %&gt;% ## se(信頼区間) mutate(se.ci = sqrt(diag(X %*% covbeta %*% t(X)))) %&gt;% ## se(予測区間) mutate(se.pi = sqrt(diag(X %*% covbeta %*% t(X)) + summary(M1)$sigma^2)) %&gt;% mutate(ci_upper = p + t*se.ci, ci_lower = p - t*se.ci, pi_upper = p + t*se.pi, pi_lower = p - t*se.pi) -&gt; pred 図示すると以下のようになる(図1.7)。 pred %&gt;% ggplot(aes(x = LatAbs, y = p))+ geom_line()+ geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(aes(ymin = pi_lower, ymax = pi_upper), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point(data = hvs_b, aes(y = OrbitalV))+ theme(aspect.ratio = 1)+ theme_bw()+ labs(y = &quot;OrbitalV&quot;) 図1.7: 95%信頼区間と予測区間 predict関数を用いて簡単に求めることができる。 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; conf_M1 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; pred_M1 hvs_b %&gt;% ggplot(aes(x = LatAbs, y = OrbitalV))+ geom_line(data = conf_M1, aes(y = fit))+ geom_ribbon(data = conf_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(data = pred_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point()+ theme(aspect.ratio = 1)+ theme_bw() 図1.8: 95%信頼区間と予測区間(predict関数を使用) 1.5.2 Multiple linear regression それでは、2つ以上の変数を含めたモデリングを行う。データ探索や先行研究の知見から、モデルにはLatAbs、CC、FMを説明変数として入れ、2変数の交互作用を全ての組み合わせについて含めた。 \\[ \\begin{aligned} OrbitalV_i &amp;= \\alpha + \\beta_1 \\times LatAbs_i + \\beta_2 \\times CC_i + \\beta_3 \\times FM_i \\\\ &amp; + \\beta_4 \\times LatAbs_i \\times CC_i\\\\ &amp; + \\beta_5 \\times LatAbs_i \\times FM_i \\\\ &amp; + \\beta_6 \\times CC_i \\times FM_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 1.5.3 Fitting the model in R and estimate parameters モデルのパラメータは、先ほどと同様にlm関数で推定できる。推定は前節で行ったのと全く同じ方法(最小二乗法)で行う。 M2 &lt;- lm(OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM, data = hvs_b) 結果は以下の通り。Estimateはパラメータの推定値を、t valueは5%水準でパラメータが有意に0と異なっているかを判断する際に用いられる。P値(Pr(&gt;|t|))を見ると、有意な変数は一つもなかった。 print(summary(M2), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + ## CC:FM, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.79 -1.50 -0.23 1.40 4.63 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.19e+01 2.24e+01 0.97 0.335 ## LatAbs -2.51e-01 1.60e-01 -1.56 0.124 ## CC 9.37e-04 1.65e-02 0.06 0.955 ## FM 2.16e-03 3.50e-02 0.06 0.951 ## LatAbs:CC 2.37e-04 1.30e-04 1.83 0.074 ## LatAbs:FM -4.49e-05 1.57e-04 -0.29 0.776 ## CC:FM -1.56e-06 2.50e-05 -0.06 0.951 ## ## Residual standard error: 2.14 on 47 degrees of freedom ## Multiple R-squared: 0.427, Adjusted R-squared: 0.354 ## F-statistic: 5.84 on 6 and 47 DF, p-value: 0.000131 1.6 Finding the optimal model さて、先ほどのモデルでは1つも有意に0と異なるパラメータ(\\(\\alpha, \\beta_1 \\sim \\beta_6\\))はなかった(= 目的変数に有意な影響を持つ説明変数変数がなかった)。このようなとき、選択肢がいくつかある。 そのままのモデルを採用し、全ての交互作用が5%水準では有意ではなかったと報告する。 AICを利用して古典的なモデル選択を行う。 仮説検定の結果に基づいて変数選択を行う(効果のなさそうな変数を外す)。 交互作用についてのみモデル選択を行う。 情報理論的アプローチを用い、モデル平均化などを行う(c.f., Burnham et al. (2011) )。 ここでは、 Pearce &amp; Dunbar (2012) に従い、AICを用いたモデル選択を行うことにする。 Rでは、step関数を用いることでステップワイズ法(AICが最も低くなるまで説明変数を1つずつ増減させる方法)を用いた変数選択を行うことができる。分析の結果、LatAbs、CC、これらの交互作用のみを含むモデルが最もAICが低い(= 予測精度が高い)と判断された。 step(M2) ## Start: AIC=88.54 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM ## ## Df Sum of Sq RSS AIC ## - CC:FM 1 0.0177 214.75 86.547 ## - LatAbs:FM 1 0.3756 215.11 86.637 ## &lt;none&gt; 214.74 88.543 ## - LatAbs:CC 1 15.2596 230.00 90.250 ## ## Step: AIC=86.55 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM ## ## Df Sum of Sq RSS AIC ## - LatAbs:FM 1 0.4172 215.17 84.652 ## &lt;none&gt; 214.75 86.547 ## - LatAbs:CC 1 15.2501 230.00 88.252 ## ## Step: AIC=84.65 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## - FM 1 0.5409 215.71 82.788 ## &lt;none&gt; 215.17 84.652 ## - LatAbs:CC 1 16.8268 232.00 86.718 ## ## Step: AIC=82.79 ## OrbitalV ~ LatAbs + CC + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 215.71 82.788 ## - LatAbs:CC 1 17.24 232.95 84.940 ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + LatAbs:CC, data = hvs_b) ## ## Coefficients: ## (Intercept) LatAbs CC LatAbs:CC ## 2.323e+01 -2.552e-01 -5.829e-05 2.201e-04 そこで、選ばれた変数のみを用いたモデルを作成し、分析を行う。 M3 &lt;- lm(OrbitalV ~ LatAbs*CC, data = hvs_b) 分析の結果は以下のとおりである。交互作用項の係数の推定値のP値が0.051であり、わずかに交互作用項の影響があることが示唆された? print(summary(M3), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs * CC, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.759 -1.504 -0.098 1.513 4.588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.32e+01 5.23e+00 4.44 4.9e-05 ## LatAbs -2.55e-01 1.53e-01 -1.67 0.101 ## CC -5.83e-05 3.94e-03 -0.01 0.988 ## LatAbs:CC 2.20e-04 1.10e-04 2.00 0.051 ## ## Residual standard error: 2.08 on 50 degrees of freedom ## Multiple R-squared: 0.425, Adjusted R-squared: 0.39 ## F-statistic: 12.3 on 3 and 50 DF, p-value: 3.81e-06 1.7 Degree of freedom モデルの自由度はサンプル数(55)からパラメータ数(今回は4)を引いた値なので51である。しかし、このような自由度の求め方はGAMではできない。一般に、パラメータ数は\\(\\mathbf{H}\\)の対角成分の和(= trace)で求めることができる。 \\[ p = \\sum_{i =1} ^{55} \\mathbf{H_{ii}} \\] 確かに4になっている。 X &lt;- model.matrix(M3) H &lt;- X %*% solve(t(X) %*% X) %*% t(X) sum(diag(H)) ## [1] 4 1.8 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。残差には普通の残差のほかに、標準化残差、スチューデント化残差などがあるが、ここでは標準化残差を用いる。 等分散性が成り立つか (→ モデルに基づく予測値と残差をプロットする) モデルがデータに当てはまっているか (→ 残差とモデルに含まれる説明変数、モデルに含まれない説明変数の関係をプロットする) データの独立性があるか(→ 自己相関があるかを確認する) 残差が正規分布に従うかを確認する(→ QQプロットを書く) モデルへの影響が大きいデータがないか確認する(→ Cook’s distanceやLeverage) まず、モデルによる予測値と標準化残差の関係をプロットする(図1.9)。このときプロットにパターンがあってはいけない(e.g., 広がっていく、ばらつきが不均等など)。もし前提を満たしていれば、0を中心に均等にばらつくはずである。図からは、明確なパターンは見られない(横軸が26~27で負の残差がほとんどないなどを除けば)。 data.frame(fitted = fitted(M3), resstd = rstandard(M3)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;) 図1.9: Standardized residuals versus fitted values to assess homogeneity 続いて、Cook`s distanceを用いて影響の大きいデータがないか確認する。Cook’s distanceは通常1を超えると影響が大きいと判断される2。ほんもでるではそのような値をとる観測値はない(図1.10)。 data.frame(cook = cooks.distance(M3), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cook))+ geom_col(width = 0.2)+ geom_hline(yintercept = 1, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Observations&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.10: Cook’s disance for each observation 残差の正規性は、ヒストグラムとQQプロットを基に判断される。QQプロットとは、「得られたデータ(今回の場合は標準化残差)と理論分布(今回の場合は標準正規分布)を比較し、その類似度を調べるためのグラフ」である。詳細についてはこちら。もし類似度が高ければ、点が直線上に乗る。そこまで大きくは外れていなさそう。 qqnorm(rstandard(M3)) qqline(rstandard(M3)) 図1.11: QQplot for M3 続いて、(モデルに入れていない説明変数を含めた)各連続変数と標準化残差の関連を図示する(図1.12)。いずれも関連はないようで、これはモデルによって説明できない部分(= 残差)はこうした変数とも関連がないことを示している。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(CC, LatAbs, FM, Illuminance, Temperature, resstd) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_point()+ geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;)+ facet_rep_wrap(~var, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.12: Multiple scatterplots of the standardized residuals versus each continuous variables これは、離散的な変数についても同様のようである(図1.13)。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(fPopulation, fGender, resstd) %&gt;% pivot_longer(1:2, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_boxplot()+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.13: Boxplot of standardized residuals versus discrete variable 自己相関も大きくなさそうである。 acf(hvs_b$OrbitalV) 1.9 Model interpretation モデルの推定値に基づくと、眼窩容量の予測値は以下のように書ける。 \\[ OrbitalV_i = 23.23 -0.25 \\times LatAbs_i -0.000058 \\times CC_i + 0.00022 \\times LatAbs_i \\times CC_i \\] モデルに基づく回帰平面を描くと以下のようになる(図1.14)。 data_M3 &lt;- crossing(LatAbs = seq(0.02,65, length.out = 100), CC = seq(1100,1700, length.out = 100)) pred &lt;- predict(M3, newdata = data_M3) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(data_M3) %&gt;% pivot_wider(names_from = CC, values_from = pred) %&gt;% select(-1) plot_ly(hvs_b, x = ~LatAbs, y = ~CC, z = ~OrbitalV, type = &quot;scatter3d&quot;, size = 2) %&gt;% add_trace(z = as.matrix(pred), x = seq(0.02,65, length.out = 100), y = seq(1100,1700, length.out =100), type = &quot;surface&quot;) -&gt; p knitr::include_graphics(&quot;image/newplot.png&quot;) 図1.14: Regression surface from the result of the model References Burnham, K. P., Anderson, D. R., &amp; Huyvaert, K. P. (2011). AIC model selection and multimodel inference in behavioral ecology: Some background, observations, and comparisons. Behav. Ecol. Sociobiol., 65(1), 23–35. Dunn, P. K., &amp; Smyth, G. K. (2018). Generalized linear models with examples in R. Springer New York. Pearce, E., &amp; Dunbar, R. (2012). Latitudinal variation in light levels drives human visual system size. Biol. Lett., 8(1), 90–93. Zuur, A. F., Ieno, E. N., &amp; Elphick, C. S. (2010). A protocol for data exploration to avoid common statistical problems. Methods Ecol. Evol., 1(1), 3–14. 説明変数(独立変数)とは、物事の原因となっている変数のこと、目的変数(応答変数)とは説明変数の影響を受けて発生した結果となっている変数のことである。今回の場合は、様々な標高など(= 説明変数)が眼窩容量(= 目的変数)に与える影響をモデリングする。↩︎ より正確には、F分布の50パーセンタイルが基準になるが、多くの場合その値は1に近い(Dunn &amp; Smyth, 2018)。↩︎ "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] GGally_2.1.2 mgcv_1.8-41 nlme_3.1-160 ## [4] fontregisterer_0.3 systemfonts_1.0.4 extrafont_0.18 ## [7] lemon_0.4.6 ggsci_2.9 concaveman_1.1.0 ## [10] ggforce_0.4.1 ggdag_0.2.7 dagitty_0.3-1 ## [13] kableExtra_1.3.4 knitr_1.42 DT_0.27 ## [16] patchwork_1.1.2 data.table_1.14.6 see_0.7.5.5 ## [19] report_0.5.7.4 parameters_0.20.3 performance_0.10.3 ## [22] modelbased_0.8.6.3 insight_0.19.1.4 effectsize_0.8.3.6 ## [25] datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 ## [28] easystats_0.6.0.8 forcats_1.0.0 stringr_1.5.0 ## [31] dplyr_1.1.2 purrr_1.0.0 readr_2.1.3 ## [34] tidyr_1.2.1 tibble_3.2.1 tidyverse_1.3.2 ## [37] hwig_0.0.2 assortnet_0.12 clValid_0.7 ## [40] cluster_2.1.4 igraph_1.3.5 ANTs_0.0.1 ## [43] sna_2.7 network_1.18.0 statnet.common_4.7.0 ## [46] asnipe_1.1.16 ggraph_2.1.0 ggplot2_3.4.2 ## [49] tidygraph_1.2.2 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.4.1 backports_1.4.1 plyr_1.8.8 ## [4] splines_4.2.2 digest_0.6.31 htmltools_0.5.4 ## [7] viridis_0.6.2 fansi_1.0.3 magrittr_2.0.3 ## [10] googlesheets4_1.0.1 tzdb_0.3.0 graphlayouts_0.8.4 ## [13] modelr_0.1.10 Kendall_2.2.1 extrafontdb_1.0 ## [16] svglite_2.1.1 timechange_0.1.1 colorspace_2.0-3 ## [19] rvest_1.0.3 ggrepel_0.9.2 haven_2.5.1 ## [22] xfun_0.36 tcltk_4.2.2 crayon_1.5.2 ## [25] jsonlite_1.8.4 lme4_1.1-31 glue_1.6.2 ## [28] polyclip_1.10-4 gtable_0.3.3 gargle_1.2.1 ## [31] emmeans_1.8.3 webshot_0.5.4 V8_4.2.2 ## [34] Rttf2pt1_1.3.8 scales_1.2.1 mvtnorm_1.1-3 ## [37] DBI_1.1.3 Rcpp_1.0.9 viridisLite_0.4.1 ## [40] xtable_1.8-4 htmlwidgets_1.6.1 httr_1.4.4 ## [43] RColorBrewer_1.1-3 reshape_0.8.9 pkgconfig_2.0.3 ## [46] farver_2.1.1 sass_0.4.5 dbplyr_2.2.1 ## [49] utf8_1.2.2 tidyselect_1.2.0 rlang_1.1.1 ## [52] munsell_0.5.0 cellranger_1.1.0 tools_4.2.2 ## [55] visNetwork_2.1.2 cachem_1.0.6 cli_3.6.0 ## [58] generics_0.1.3 broom_1.0.2 evaluate_0.20 ## [61] fastmap_1.1.0 yaml_2.3.7 fs_1.5.2 ## [64] xml2_1.3.3 compiler_4.2.2 rstudioapi_0.14 ## [67] curl_4.3.3 reprex_2.0.2 tweenr_2.0.2 ## [70] bslib_0.4.2 stringi_1.7.8 lattice_0.20-45 ## [73] Matrix_1.5-1 nloptr_2.0.3 vctrs_0.6.2 ## [76] pillar_1.9.0 lifecycle_1.0.3 jquerylib_0.1.4 ## [79] estimability_1.4.1 R6_2.5.1 bookdown_0.31 ## [82] gridExtra_2.3 codetools_0.2-18 boot_1.3-28 ## [85] MASS_7.3-58.1 gtools_3.9.4 assertthat_0.2.1 ## [88] withr_2.5.0 hms_1.1.3 grid_4.2.2 ## [91] coda_0.19-4 class_7.3-20 minqa_1.2.5 ## [94] rmarkdown_2.20 googledrive_2.0.0 lubridate_1.9.0 References Burnham, K. P., Anderson, D. R., &amp; Huyvaert, K. P. (2011). AIC model selection and multimodel inference in behavioral ecology: Some background, observations, and comparisons. Behav. Ecol. Sociobiol., 65(1), 23–35. Butts, C. T. (2008). Social network analysis with sna. J. Stat. Softw., 24, 1–51. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Csardi, G., Nepusz, T., &amp; Others. (2006). The igraph software package for complex network research. InterJournal, Complex Systems, 1695(5), 1–9. Dunn, P. K., &amp; Smyth, G. K. (2018). Generalized linear models with examples in R. Springer New York. Farine, D. R. (2013). Animal social network inference and permutations for ecologists inRusingasnipe. Methods Ecol. Evol., 4(12), 1187–1194. Pearce, E., &amp; Dunbar, R. (2012). Latitudinal variation in light levels drives human visual system size. Biol. Lett., 8(1), 90–93. Sosa, S., Puga-Gonzalez, I., Hu, F., Pansanel, J., Xie, X., &amp; Sueur, C. (2020). A multilevel statistical toolkit to study animal social networks: The animal network toolkit software (ANTs) R package. Sci. Rep., 10(1), 12507. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” Zuur, A. F., Ieno, E. N., &amp; Elphick, C. S. (2010). A protocol for data exploration to avoid common statistical problems. Methods Ecol. Evol., 1(1), 3–14. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
