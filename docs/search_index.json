[["index.html", "Introduction to GAM using R 本稿の目的", " Introduction to GAM using R Tsubasa Yamaguchi 2023-07-27 本稿の目的 本稿は、一般化加法モデル(GAM)の概要を解説し、それをRで実行する方法を学ぶことを目的とする。GAMは一般化線形モデル(GLMに代表される線形なモデルを拡張し、変数間の関係をより柔軟な形で表現できるようにしたものである。そのため、GLMで仮定されるような単調増加または単調減少の関係だけでなく、非線形な関係を調べることができる。 霊長類の行動のような複雑なデータでは変数間の関係が非線形になることがしばしばあるため、GAMは多くの研究で用いられている(e.g., Matsumoto 2017; Taniguchi and Matsumoto-Oda 2018; Hongo et al. 2022)。GLMのように線形性を仮定するモデルがデータに当てはまらない場合には、GAMなどの非線形性を許容するモデルを使用する必要性が生じてくるだろう。 本稿は、Alain Zuurが執筆した”A beginner’s guide to generalized additive models with R”(Zuur 2012)の内容を基に執筆している。本書はなるべく数学的な説明を省きつつ、実際の生態学のデータを用いてGAMについてわかりやすく解説したもので、GAMの入門として非常によい書籍である。より詳細な情報を知りたい場合は原著にアクセスしていただきたい。 本稿の内容はこちらから読むことができる。 References "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham and Grolemund 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al. 2021) 出版社サイト 使用するパッケージは以下のとおりである。GAMの実行は主にgamパッケージ(Hastie and Hastie 2018)を用い、結果の作図についてはggplotパッケージでGAMの結果を可視化することに特化したgratiaパッケージを用いる。 ## GAM library(mgcv) library(gratia) library(gstat) ## データハンドリング library(tidyverse) library(easystats) library(data.table) ## グラフや表関連 library(sp) library(plotly) library(htmlwidgets) library(ggnewscale) library(GGally) library(patchwork) library(DT) library(knitr) library(kableExtra) library(dagitty) library(ggdag) library(ggforce) library(concaveman) library(ggsci) library(lemon) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) References "],["Chapter1.html", "1 Review of multiple linear regressions 1.1 Light levels and size of the human visual system 1.2 The variables 1.3 Protocol for the analysis 1.4 Data exploration 1.5 Multiple linear regression 1.6 Finding the optimal model 1.7 Degree of freedom 1.8 Model validation 1.9 Model interpretation 1.10 What to do if things go wrong", " 1 Review of multiple linear regressions 本章では、一般化加法モデル(GAM)の説明に入る前に、多くの人に馴染みのある重回帰分析(multiple linear regression)について説明する、なぜなら、GAMは重回帰分析を拡張したものだからである。 1.1 Light levels and size of the human visual system Pearce and Dunbar (2012) は、ヒトの集団が住んでいる標高と眼窩の容量に正の関連があることから、住んでいる環境の光量がヒトの視覚システムの進化の原動力になっていると結論付けた。本章ではこの論文のデータを用いて重回帰分析について説明を行う。重回帰分析でデータを探索し、モデルを構築し、モデルを当てはめ、モデル選択を行い、モデルの妥当性を確認する方法はGAMでもほとんど同じように適用できる。 1.2 The variables Pearce and Dunbar (2012) は、オックスフォード大学博物館にある55人の成人の頭蓋骨から、頭蓋の容量(cranial capacity: CC)と眼窩容量(orbital volume)、大後頭孔(foramen magnum: FM)などの測定を行った。 データは以下のとおりである。平均眼窩容量(mean orbital volume)が目的変数であり、それ以外の変数は説明変数である1。AbsoluteLatitudeとMinimum_Tempreture_celsiusはそれぞれ 頭蓋が発見された場所の標高と最低気温、FMarea_intercondyleは体格の大きさを示す指標、Minimum_Illuminanceはlogスケールで表した光の強度、Genderは頭蓋の性別である。 hvs &lt;- read_delim(&quot;data/HVS.txt&quot;) datatable(hvs, filter = &quot;top&quot;, options = list(scrollX = 20)) 変数名が長いので、以下のように短く変更する。 hvs %&gt;% rename(OrbitalV = MeanOrbitalVolume, LatAbs = AbsoluteLatitude, CC = CranialCapacity, Illuminance = Minimum_Illuminance, Temperature = Minimum_Temperature_celsius, FM = FMarea_intercondyle) %&gt;% mutate(fPopulation = factor(Population), fGender = factor(Gender)) -&gt; hvs 新しい列名は以下の通り。 colnames(hvs) ## [1] &quot;Museum&quot; &quot;Findsite&quot; &quot;Gender&quot; &quot;Population&quot; &quot;Latitude&quot; ## [6] &quot;LatAbs&quot; &quot;CC&quot; &quot;FM&quot; &quot;OrbitalV&quot; &quot;Illuminance&quot; ## [11] &quot;Temperature&quot; &quot;fPopulation&quot; &quot;fGender&quot; 1.3 Protocol for the analysis いかなるデータ分析も、以下の手順に沿って行わなければならない。 Data exploration 外れ値がないか、多重共線性(説明変数同士の強い相関)がないか、目的変数と説明変数の関係がどうか、ゼロ過剰はないか、サンプリングの収集が時間や場所によってばらついていないか、などをチェックする必要がある。 Model application 1の作業で分かったことや研究仮説をもとに、適切なモデルを適用する。今回は重回帰分析を行うが、様々なモデルを適用可能である。 Check the result モデルを当てはめたら、どの変数が有意な影響を持つかを調べ、そうでなかった変数についてはどうするかを考える。 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。満たしていれば結果の解釈や結果の作図を行い、満たしていなければモデルを改善する必要がある(GAM、GLM、GLMを使うなど)。 1.4 Data exploration まずは手順1のデータ探索を行う。データ探索については Zuur et al. (2010) に詳しい。 1.4.1 欠損値の確認 まず、欠損値がないかを調べる。 colSums(is.na(hvs)) ## Museum Findsite Gender Population Latitude LatAbs ## 0 0 0 0 0 0 ## CC FM OrbitalV Illuminance Temperature fPopulation ## 0 1 0 0 0 0 ## fGender ## 0 FMの列に1つ欠損値があるので取り除く。 hvs_b &lt;- na.omit(hvs) 1.4.2 外れ値の確認 続いて、外れ値がないかを確認する。ここでは、連続値の説明変数(Latitude、CC、FM、Illuminance、Temperature)についてCleveland Dotplotを作成する。Dotplotは縦軸にサンプル番号、横軸に実際の値をとる。 図は以下のとおりである(図1.1)。図を見る限り、外れ値はなさそうだ。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature) %&gt;% mutate(sample_number = 1:n()) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = sample_number))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Values of the variable&quot;, y = &quot;Sample number&quot;)+ theme(aspect.ratio = 1) 図1.1: Cleveland dotplot for covariates. 1.4.3 多重共線性の確認 次に、多重共線性(説明変数同士の強い相関)がないかを調べる。もしあると、推定結果にバイアスが生じてしまう。 説明変数同士の関連を調べたところ(図1.2)、LatAbsとIlluminance、IlluminanceとTemperature、TemperatureとLatAbsに強い相関があることが分かる。また、CCは男性で高い傾向があることが分かったので、CCとfGenderを同じモデルに説明変数として入れない方がよさそうである(今回はfGenderを用いない)。 ggpairs(hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, fGender)) 図1.2: correlation between covariates 1.4.4 目的変数と説明変数の関係の確認 最後に、目的変数と説明変数の関連を調べる(図1.3)。図には局所回帰(LOESS)による回帰曲線を追加している。 図から、LatAbsとOrbitalVの間に線形の関係がありそうだということが分かる(’CC’も?)。IlluminanceやTemperatureにも同様のことがいえるが、これは変数間に強い相関があることを考えれば当然だろう。多重共線性を考慮し、Pearce and Dunbar (2012) にもとづいて解析ではLatAbsを用いてIlluminanceとTemperatureは用いないこととする。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, OrbitalV) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = OrbitalV))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Explanatory Variables&quot;, y = &quot;OrbitalV&quot;)+ theme(aspect.ratio = 1)+ geom_smooth(method = &quot;loess&quot;, se= F, color = &quot;grey32&quot;, span = 0.9) 図1.3: Relationship between explanatory variables and orbital volume (OrbitalV). A LOESS smoother was added to the plot. 1.5 Multiple linear regression 1.5.1 Underlying statistical theory それでは、重回帰分析を行う。まずは説明のために説明変数が1つだけのモデル(= 単回帰)を考えよう。 標高のみを説明変数とする単回帰モデルは以下のように実行できる。 M1 &lt;- lm(OrbitalV ~ LatAbs, data = hvs_b) summary(M1) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9893 -1.4166 -0.1616 1.5037 3.8887 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.91064 0.51412 44.563 &lt; 2e-16 *** ## LatAbs 0.06598 0.01411 4.677 2.11e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.253 on 52 degrees of freedom ## Multiple R-squared: 0.2961, Adjusted R-squared: 0.2825 ## F-statistic: 21.87 on 1 and 52 DF, p-value: 2.111e-05 これは、実際には何をやっているのだろうか? lm関数で短回帰を実行するとき、私たちは下記のモデルを実行している。なお、\\(i\\)はサンプル番号(今回は55個の頭蓋がある)を、2行目は\\(\\epsilon_i\\)が平均0、分散\\(\\sigma^2\\)の正規分布に従うことを表す。 \\[ \\begin{aligned} OrvitalV_i &amp;= \\alpha + \\beta\\times LatAbs_i + \\epsilon_i \\;\\; (i = 1,2,\\dots, 55)\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルで推定するパラメータは\\(\\alpha\\)、\\(\\beta\\)、\\(\\sigma\\)である。\\(\\beta\\)は標高(LatAbs)が眼窩容量(OrbitalV)に与える影響の大きさを表し、式からわかるように標高が1増えると眼窩容量が\\(\\beta\\)増えることを表す。先ほどlm関数で実行した結果でEstimateの下に書かれていた数字(\\(22.91...と0.065...\\))は\\(\\alphaと\\beta\\)の推定値を示しているのである。 もし以下のように行列を定義すると、 \\[ \\begin{aligned} \\mathbf{y} = \\begin{pmatrix} OrbitalV_1\\\\ OrbitalV_2\\\\ \\vdots\\\\ OrvitalV_{55} \\end{pmatrix} , \\mathbf{X} = \\begin{pmatrix} 1 &amp; LatAbs_1\\\\ 1 &amp; LatAbs_2\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; LatAbs_{55} \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_{55} \\end{pmatrix} \\end{aligned} \\] モデル式は以下のように書ける。 \\[ \\mathbf{y = X\\times\\beta + \\epsilon} \\] \\(\\mathbf{X}\\)はRで以下のように求められる。 head(model.matrix(M1)) ## (Intercept) LatAbs ## 1 1 1.33 ## 2 1 5.42 ## 3 1 5.42 ## 4 1 28.51 ## 5 1 28.51 ## 6 1 28.51 パラメータは最小二乗法(ordinary least square)で求められる。最小二乗法は、残差の二乗和(実際の測定値と推定されたモデルによる予測値の差、ここでは\\(\\sum_i^{55}( y_i - \\alpha + \\beta \\times OrbitalV_i)\\))が最小になるようにパラメータを推定する方法である。 \\(bfmath(\\beta)\\)の推定値は数学的に以下のように求められる。なお、\\(\\mathbf{X^t}\\)は\\(\\mathbf{X}\\)の転置行列を、\\(\\mathbf{X^{-1}}\\)はは\\(\\mathbf{X}\\)の逆行列を表す。 \\[ \\mathbf{\\hat{\\beta}} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\tag{1.1} \\] なお、\\(\\mathbf{\\hat{\\beta}}\\)は\\(\\mathbf{\\beta}\\)の推定値であることを表し、便宜的にここでは\\(\\mathbf{\\hat{\\beta}} = \\begin{pmatrix}a\\\\b \\end{pmatrix}\\)とする。 Rでは\\(\\mathbf{\\hat{\\beta}}\\)を以下のように求められ、lm関数で推定した場合と同じ推定値が得られることが分かる。 X &lt;- model.matrix(M1) solve(t(X) %*% X) %*% t(X) %*% hvs_b$OrbitalV ## [,1] ## (Intercept) 22.9106427 ## LatAbs 0.0659754 よって、モデルによって推定された眼窩容量(\\(\\hat{y_i}\\))は以下のように表せる。 \\[ Fitted OrbitalV_i = 22.930 + 0.066 \\times LatAbs_i \\] すなわち、モデルの推定値から得られた残差\\(e_i\\)は以下のように表せる。 \\[ e_i = OrbitalV_i - a + b\\times LatAbs_i \\] \\(\\mathbf{\\hat{y}} = \\mathbf{X}\\times \\mathbf{\\beta}\\)と書けるので、残差の行列\\(\\mathbf{e}\\)は\\(\\mathbf{H} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t}\\)とするとき以下のように書ける。 \\[ \\mathbf{e} = \\mathbf{y} - \\mathbf{\\hat{y}} = \\mathbf{y} - \\mathbf{H\\times y} = \\mathbf{(1-H)\\times y} \\tag{1.2} \\] モデル式より、\\(\\mathbf{y}\\)の分散共分散行列は\\(\\sigma^2 \\times \\mathbf{I}\\)と表せるので(\\(\\mathbf{I}\\)は単位行列)、\\(\\mathbf{e}\\)の分散共分散行列は以下のように表せる。 \\[ cov(\\mathbf{e}) = \\sigma^2 \\times (\\mathbf{1 - H}) \\] また、以下の値を標準化残差(standardized residuals)という。なお、\\(H_{ii}\\)は\\(\\mathbf{H}\\)の\\(i\\)番目の対角成分を表す。 \\[ e_i ^* = \\frac{e_i}{\\hat{\\sigma} \\sqrt{(1-H_{ii})}} \\] もしモデルが正しいとき、標準化残差は標準正規分布に従うので、その値のほとんどは-2から2の間に収まるはずである。 Rでは、残差と標準化残差を以下のように求められる。 e &lt;- resid(M1) estd &lt;- rstandard(M1) 実際、1つのデータを除いて-2から2の範囲に収まっている(図1.4)。 data.frame(estd = estd) %&gt;% ggplot(aes(x = estd))+ geom_histogram(binwidth = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_y_continuous(breaks = seq(0,10,1)) 図1.4: 標準化残差の分布 1.5.1.1 外れ値のチェック モデルに極端な外れ値がないかを調べるときには、LeverageとCook’s distanceが用いられることが多い。 *everageは\\(\\mathbf{H}\\)の対角成分で0から1の値をとり、大きいほどそのデータポイントが結果に大きな影響を与える外れ値であることを示す。特に極端な値はないよう(図1.5)。 data.frame(h = diag(H), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = h))+ geom_col(width = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Leverage&quot;) 図1.5: Leveragevalue for each observation 式(1.2)より、以下のように書ける。すなわち、\\(i\\)番目の観察に対してモデルから予測される値(fitted value)は元データの観測値の加重平均であり、重みは行列\\(\\mathbf{H}\\)により与えられる。 \\[ \\hat{y_i} = H_{i1} \\times y_1 + H_{i2} \\times y_2 + \\dots + H_{i55} \\times y_55 \\tag{1.3} \\] 特に\\(H_{ii}\\)は観測値\\(y_i\\)がモデルからの予測値\\(\\hat{y_i}\\)に与える影響の大きさを表している。そのため、\\(H_{ii}\\)が高いことは、その観測値がモデルの推定に大きな影響を及ぼしていることを示しているのである。 ある観測値がモデルの推定に影響を与えている度合いを表すのがCook’s distanceで、以下の式で表せる。\\(\\hat{y_{(i)}}\\)は式(1.3)から\\(H_{ii}\\times y_i\\)を除いたものである。また、\\(p\\)はモデルの回帰式の中のパラメータ数である。 \\[ D_i = \\frac{||\\hat{y_i} - \\hat{y_{(i)}}||}{p \\times \\hat{\\sigma^2}} \\] Cook’s distanceはRで以下のように取得できる。 D &lt;- cooks.distance(M1) data.frame(cookD = D, n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cookD))+ geom_col(width = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.6: Cook’s distance for each observation 1.5.1.2 95%信頼区間と予測区間の算出 \\(\\mathbf{\\beta}\\)の推定値の分散共分散行列は\\(\\mathbf{y}\\)の分散共分散行列が\\(\\mathbf{\\sigma^2 \\times I}\\)であることを考えると、式(1.1)より以下のようになる。 \\[ \\begin{aligned} cov(\\mathbf{\\hat{\\beta}}) &amp;= \\mathbf(X^t \\times X)^{-1} \\times \\mathbf{X^t} \\times cov(\\mathbf{y}) \\times \\mathbf{X} \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\\\ &amp;= \\sigma^2 \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\end{aligned} \\] \\(\\hat{\\beta}\\)の標準偏差は上式から得られる行列の対角成分の1/2乗である。この値は、lm関数を利用した結果(Std. Errorの下の数値)と一致する。 SE &lt;-summary(M1)$sigma * sqrt(diag(solve(t(X) %*% X))) SE ## (Intercept) LatAbs ## 0.51411731 0.01410749 95%信頼区間は、モデル式より\\(\\beta\\)が正規分布に従うので以下のように求められる。 Z &lt;- rbind(coef(M1) + 1.96*SE, coef(M1) - 1.96*SE) %&gt;% data.frame() rownames(Z) &lt;- c(&quot;Upper bound&quot;, &quot;Lower bound&quot;) Z ただし、これはサンプルサイズが十分に大きいときのみ成り立つ。実際は、\\(\\hat{\\beta}\\)は自由度\\(55-2\\)(サンプル数 - パラメータ数)のt分布に従うので、より正確に95%信頼区間を求めるには、1.96ではなく2.005746…を用いる必要がある。 qt(1- 0.05/2, df = 55-2) ## [1] 2.005746 95％信頼区間は、もし100回同様の方法で実験/観察を行ってそれぞれについて95%信頼区間を算出するとき、そのうち95個には真の値が含まれていることを表す。95%信頼区間に0が含まれていないとき、\\(\\hat{\\beta}\\)が有意に0とは違うということができる。 同様に、モデルに基づいた予測値の分散共分散行列は以下のように求められ、その対角成分の1/2乗が予測値の標準誤差(SE)になる。 \\[ cov(\\mathbf{\\hat{y}}) = \\mathbf{X} \\times cov(\\mathbf{\\hat{\\beta}}) \\times \\mathbf{X^t} \\tag{1.4} \\] 予測値の95%信頼区間はある標高(LatAbs)に対して100回データをサンプリングすれば95個のデータが含まれる範囲を表し、予測値が自由度55-2のt分布に従うので、\\(予測値 ± 2.0057 \\times SE\\)で求められる。 一方で95%予測区間は新たにデータをサンプリングしたときにデータの95%が収まる範囲を指す。予測区間を求める際の標準誤差には式(1.4)に\\(\\hat{\\sigma^2}\\)を足したものを用いればよい。 Rでは予測値と95%信頼区間、95%予測区間は以下のように求められる。 ## 係数の分散共分散行列 covbeta &lt;- vcov(M1) data &lt;- data.frame(LatAbs = seq(0,65,length.out = 100)) X &lt;- model.matrix(~LatAbs, data = data) t &lt;- qt(1-0.05/2, df = 55-2) data %&gt;% ## 予測値 mutate(p = X %*% coef(M1)) %&gt;% ## se(信頼区間) mutate(se.ci = sqrt(diag(X %*% covbeta %*% t(X)))) %&gt;% ## se(予測区間) mutate(se.pi = sqrt(diag(X %*% covbeta %*% t(X)) + summary(M1)$sigma^2)) %&gt;% mutate(ci_upper = p + t*se.ci, ci_lower = p - t*se.ci, pi_upper = p + t*se.pi, pi_lower = p - t*se.pi) -&gt; pred 図示すると以下のようになる(図1.7)。 pred %&gt;% ggplot(aes(x = LatAbs, y = p))+ geom_line()+ geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(aes(ymin = pi_lower, ymax = pi_upper), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point(data = hvs_b, aes(y = OrbitalV))+ theme(aspect.ratio = 1)+ theme_bw()+ labs(y = &quot;OrbitalV&quot;) 図1.7: 95%信頼区間と予測区間 predict関数を用いて簡単に求めることができる。 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; conf_M1 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; pred_M1 hvs_b %&gt;% ggplot(aes(x = LatAbs, y = OrbitalV))+ geom_line(data = conf_M1, aes(y = fit))+ geom_ribbon(data = conf_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(data = pred_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point()+ theme(aspect.ratio = 1)+ theme_bw() 図1.8: 95%信頼区間と予測区間(predict関数を使用) 1.5.2 Multiple linear regression それでは、2つ以上の変数を含めたモデリングを行う。データ探索や先行研究の知見から、モデルにはLatAbs、CC、FMを説明変数として入れ、2変数の交互作用を全ての組み合わせについて含めた。 \\[ \\begin{aligned} OrbitalV_i &amp;= \\alpha + \\beta_1 \\times LatAbs_i + \\beta_2 \\times CC_i + \\beta_3 \\times FM_i \\\\ &amp; + \\beta_4 \\times LatAbs_i \\times CC_i\\\\ &amp; + \\beta_5 \\times LatAbs_i \\times FM_i \\\\ &amp; + \\beta_6 \\times CC_i \\times FM_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 1.5.3 Fitting the model in R and estimate parameters モデルのパラメータは、先ほどと同様にlm関数で推定できる。推定は前節で行ったのと全く同じ方法(最小二乗法)で行う。 M2 &lt;- lm(OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM, data = hvs_b) 結果は以下の通り。Estimateはパラメータの推定値を、t valueは5%水準でパラメータが有意に0と異なっているかを判断する際に用いられる。P値(Pr(&gt;|t|))を見ると、有意な変数は一つもなかった。 print(summary(M2), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + ## CC:FM, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.79 -1.50 -0.23 1.40 4.63 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.19e+01 2.24e+01 0.97 0.335 ## LatAbs -2.51e-01 1.60e-01 -1.56 0.124 ## CC 9.37e-04 1.65e-02 0.06 0.955 ## FM 2.16e-03 3.50e-02 0.06 0.951 ## LatAbs:CC 2.37e-04 1.30e-04 1.83 0.074 ## LatAbs:FM -4.49e-05 1.57e-04 -0.29 0.776 ## CC:FM -1.56e-06 2.50e-05 -0.06 0.951 ## ## Residual standard error: 2.14 on 47 degrees of freedom ## Multiple R-squared: 0.427, Adjusted R-squared: 0.354 ## F-statistic: 5.84 on 6 and 47 DF, p-value: 0.000131 1.6 Finding the optimal model さて、先ほどのモデルでは1つも有意に0と異なるパラメータ(\\(\\alpha, \\beta_1 \\sim \\beta_6\\))はなかった(= 目的変数に有意な影響を持つ説明変数変数がなかった)。このようなとき、選択肢がいくつかある。 そのままのモデルを採用し、全ての交互作用が5%水準では有意ではなかったと報告する。 AICを利用して古典的なモデル選択を行う。 仮説検定の結果に基づいて変数選択を行う(効果のなさそうな変数を外す)。 交互作用についてのみモデル選択を行う。 情報理論的アプローチを用い、モデル平均化などを行う(c.f., Burnham et al. (2011) )。 ここでは、 Pearce and Dunbar (2012) に従い、AICを用いたモデル選択を行うことにする。 Rでは、step関数を用いることでステップワイズ法(AICが最も低くなるまで説明変数を1つずつ増減させる方法)を用いた変数選択を行うことができる。分析の結果、LatAbs、CC、これらの交互作用のみを含むモデルが最もAICが低い(= 予測精度が高い)と判断された。 step(M2) ## Start: AIC=88.54 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM ## ## Df Sum of Sq RSS AIC ## - CC:FM 1 0.0177 214.75 86.547 ## - LatAbs:FM 1 0.3756 215.11 86.637 ## &lt;none&gt; 214.74 88.543 ## - LatAbs:CC 1 15.2596 230.00 90.250 ## ## Step: AIC=86.55 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM ## ## Df Sum of Sq RSS AIC ## - LatAbs:FM 1 0.4172 215.17 84.652 ## &lt;none&gt; 214.75 86.547 ## - LatAbs:CC 1 15.2501 230.00 88.252 ## ## Step: AIC=84.65 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## - FM 1 0.5409 215.71 82.788 ## &lt;none&gt; 215.17 84.652 ## - LatAbs:CC 1 16.8268 232.00 86.718 ## ## Step: AIC=82.79 ## OrbitalV ~ LatAbs + CC + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 215.71 82.788 ## - LatAbs:CC 1 17.24 232.95 84.940 ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + LatAbs:CC, data = hvs_b) ## ## Coefficients: ## (Intercept) LatAbs CC LatAbs:CC ## 2.323e+01 -2.552e-01 -5.829e-05 2.201e-04 そこで、選ばれた変数のみを用いたモデルを作成し、分析を行う。 M3 &lt;- lm(OrbitalV ~ LatAbs*CC, data = hvs_b) 分析の結果は以下のとおりである。交互作用項の係数の推定値のP値が0.051であり、わずかに交互作用項の影響があることが示唆された? print(summary(M3), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs * CC, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.759 -1.504 -0.098 1.513 4.588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.32e+01 5.23e+00 4.44 4.9e-05 ## LatAbs -2.55e-01 1.53e-01 -1.67 0.101 ## CC -5.83e-05 3.94e-03 -0.01 0.988 ## LatAbs:CC 2.20e-04 1.10e-04 2.00 0.051 ## ## Residual standard error: 2.08 on 50 degrees of freedom ## Multiple R-squared: 0.425, Adjusted R-squared: 0.39 ## F-statistic: 12.3 on 3 and 50 DF, p-value: 3.81e-06 1.7 Degree of freedom 重回帰分析では、 モデルの自由度は回帰式のパラメータ数なので4である。しかし、このような自由度の求め方はGAMではできない。一般に、パラメータ数は\\(\\mathbf{H}\\)の対角成分の和(= trace)で求めることができる。 \\[ p = \\sum_{i =1} ^{55} \\mathbf{H_{ii}} \\] 確かに4になっている。 X &lt;- model.matrix(M3) H &lt;- X %*% solve(t(X) %*% X) %*% t(X) sum(diag(H)) ## [1] 4 1.8 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。残差には普通の残差のほかに、標準化残差、スチューデント化残差などがあるが、ここでは標準化残差を用いる。 等分散性が成り立つか (→ モデルに基づく予測値と残差をプロットする) モデルがデータに当てはまっているか、残差の独立性があるか (→ 残差とモデルに含まれる説明変数、モデルに含まれない説明変数の関係をプロットする) データの独立性があるか(→ 自己相関があるかを確認する) 残差が正規分布に従うかを確認する(→ QQプロットを書く) モデルへの影響が大きいデータがないか確認する(→ Cook’s distanceやLeverage) まず、モデルによる予測値と標準化残差の関係をプロットする(図1.9)。このときプロットにパターンがあってはいけない(e.g., 広がっていく、ばらつきが不均等など)。もし前提を満たしていれば、0を中心に均等にばらつくはずである。図からは、明確なパターンは見られない(横軸が26~27で負の残差がほとんどないなどを除けば)。 data.frame(fitted = fitted(M3), resstd = rstandard(M3)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;) 図1.9: Standardized residuals versus fitted values to assess homogeneity 続いて、Cook`s distanceを用いて影響の大きいデータがないか確認する。Cook’s distanceは通常1を超えると影響が大きいと判断される2。ほんもでるではそのような値をとる観測値はない(図1.10)。 data.frame(cook = cooks.distance(M3), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cook))+ geom_col(width = 0.2)+ geom_hline(yintercept = 1, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Observations&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.10: Cook’s disance for each observation 残差の正規性は、ヒストグラムとQQプロットを基に判断される。QQプロットとは、「得られたデータ(今回の場合は標準化残差)と理論分布(今回の場合は標準正規分布)を比較し、その類似度を調べるためのグラフ」である。詳細についてはこちら。もし類似度が高ければ、点が直線上に乗る。そこまで大きくは外れていなさそう。 qqnorm(rstandard(M3)) qqline(rstandard(M3)) 図1.11: QQplot for M3 続いて、(モデルに入れていない説明変数を含めた)各連続変数と標準化残差の関連を図示する(図1.12)。いずれも関連はないようで、これはモデルによって説明できない部分(= 残差)はこうした変数とも関連がないことを示している。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(CC, LatAbs, FM, Illuminance, Temperature, resstd) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_point()+ geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;)+ facet_rep_wrap(~var, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.12: Multiple scatterplots of the standardized residuals versus each continuous variables これは、離散的な変数についても同様のようである(図1.13)。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(fPopulation, fGender, resstd) %&gt;% pivot_longer(1:2, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_boxplot()+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.13: Boxplot of standardized residuals versus discrete variable 自己相関も大きくなさそうである。 acf(hvs_b$OrbitalV) 1.9 Model interpretation モデルの推定値に基づくと、眼窩容量の予測値は以下のように書ける。 \\[ OrbitalV_i = 23.23 -0.25 \\times LatAbs_i -0.000058 \\times CC_i + 0.00022 \\times LatAbs_i \\times CC_i \\] モデルに基づく回帰平面を描くと以下のようになる(図1.14)。 data_M3 &lt;- crossing(LatAbs = seq(0.02,65, length.out = 100), CC = seq(1100,1700, length.out = 100)) pred &lt;- predict(M3, newdata = data_M3) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(data_M3) %&gt;% pivot_wider(names_from = CC, values_from = pred) %&gt;% select(-1) plot_ly(hvs_b, x = ~LatAbs, y = ~CC, z = ~OrbitalV, type = &quot;scatter3d&quot;, size = 2) %&gt;% add_trace(z = as.matrix(pred), x = seq(0.02,65, length.out = 100), y = seq(1100,1700, length.out =100), type = &quot;surface&quot;) -&gt; p p 図1.14: 3d plot of the fitted surface 1.10 What to do if things go wrong もしモデルが前提を満たさなかったらどうすればよいだろうか?本節では特にどのようなときにGAMを適用すべきかを解説する。 等分散性の仮定が満たされないとき、以下の選択肢を検討する必要がある。 目的変数に変数変換を施す 一般化最小二乗法(GLS)を用いる さらに説明変数や交互作用を加える 目的変数の分布として他の分布を用いる(ガンマ分布など) 3つ目の選択肢において、非線形のパターンも許容するように拡張すると、GAMが使えるようになる。これは、残差と説明変数が何らかのパターンを示した時にも有効である(= 関係が線形でない可能性があるため)。 References "],["Chapter2.html", "2 Introduction to additive models using deep-sea fisheries data 2.1 Impact of deep-sea fisheries 2.2 First encounter with smoothers 2.3 Allpying GAM in R using the mgcv package 2.4 Cross validation 2.5 Model validation 2.6 Extending the GAM with more covariates 2.7 Transforming the density data 2.8 Allowing for heterogeneity 2.9 Transforming and allowing for heterogeinity 2.10 What to present in paper", " 2 Introduction to additive models using deep-sea fisheries data 本章では、正規分布に従う一般化加法モデル(GAM)の導入を行う。 2.1 Impact of deep-sea fisheries 本章では、商業的な漁業が深海(水深800–4865m)の魚の密度に及ぼす影響を調べた Bailey et al. (2009) のデータを用いる。データは2つの期間に分かれており、1979年から1989年は商業的な漁業がおこなわれる前(深い水深での漁業が発展している段階)で、1997年から2002年は商業的漁業がおこなわれている時期である。商業的漁業は技術的または商業的な理由により水深約1600mまでに限られている。 fish &lt;- read_delim(&quot;data/BaileyDensity.txt&quot;) datatable(fish, options = list(scrollX = 20), filter = &quot;top&quot;) 期間ごとにデータをサンプリングした場所を示したのが図2.1である。Periodは1が1979–1989年を、2が1997–2002年を表す。 fish %&gt;% mutate(Period = as.factor(Period)) %&gt;% ggplot(aes(x = Xkm, y = Ykm))+ geom_point(aes(fill = Period), shape = 21, alpha = 0.6)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;)) 図2.1: Position of the Sites Bailey et al. (2009) では、魚の密度を以下のように定義している。 \\[ 場所iにおける魚の密度 = \\frac{場所iの魚の総量}{場所iで探索を行った面積} \\] 密度のような割り算データを目的変数にして正規分布に当てはめると、等分散性の問題が生じることが多い。通常、このような分子が整数値の割り算データに対してはポワソン分布や負の二項分布でオフセット項を用いる(第4章を参照)。もし分母が試行数、分子が成功数などのカウントデータの場合は二項分布を当てはめた方がよい。密度が0より大きい値しかとらないのであれば、ガンマ分布を当てはめることもできる。 2.2 First encounter with smoothers 2.2.1 Applying linear regression 2.2.1.1 当てはめるモデル 全種を含めた魚の密度は以下のように表せる。なお\\(i\\)は場所を、\\(j\\)は魚の種類を表す。また、\\(SA_i\\)は場所\\(i\\)における探索面積を、\\(Y_{ij}\\)は場所\\(i\\)における種\\(j\\)の捕獲個体数を表す。 \\[ Dens_i = \\frac{\\sum_j Y_{ij}}{SA_i} \\] まずは、各探索場所の深さのみが魚の密度に影響するとする線形なモデルを考える。モデル式は以下のようになる。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta \\times Depth_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.2.1.2 data exploration いかなるモデルを作ろうとも、まずはデータ探索を行う。まずは、水深と魚の密度の関連をプロットする(図2.2)。図から明らかに水深と魚の密度の関係は線形ではない。しかし、ここではこうしたデータが線形モデルの前提を満たさないことを示すため、まずは通常の線形モデルを適用する。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% mutate(year01 = ifelse(Year &gt; 1990, &quot;commercial&quot;,&quot;non-commercial&quot;)) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(shape = year01))+ scale_shape_manual(values = c(19,1)) + theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.2: Relationship between fish density and mean sampling depth. Filled circles are observations from the second period and open circles from the first period. モデルは以下のように実行できる。モデルは、目的変数のばらつきの33.7%が水深で説明できると推定している(Adjusted R-squaredより)。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% na.omit() -&gt; fish M2_1 &lt;- lm(Dens ~ MeanDepth, data = fish) print(summary(M2_1), digits = 3) ## ## Call: ## lm(formula = Dens ~ MeanDepth, data = fish) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.007835 -0.002519 -0.000558 0.001420 0.023109 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.09e-02 8.06e-04 13.51 &lt;2e-16 *** ## MeanDepth -2.56e-06 2.96e-07 -8.63 1e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.00449 on 145 degrees of freedom ## Multiple R-squared: 0.339, Adjusted R-squared: 0.335 ## F-statistic: 74.4 on 1 and 145 DF, p-value: 1.02e-14 2.2.1.3 model diagnosis それでは、モデル診断を行おう。 まずは標準化残差とモデルの予測値の関係を見る(図2.3のA)。明らかにパターンが見て取れ、モデルが等分散性の仮定を満たしていないことが分かる。また、水深と標準化残差にもパターンがあるように見え(図2.3のB)、このモデルでは水深でうまく目的変数を説明できていないことが分かる。 data.frame(resstd = rstandard(M2_1), fitted = fitted(M2_1)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_1_a data.frame(resstd = rstandard(M2_1), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_1_b p_diag_M2_1_a + p_diag_M2_1_b 図2.3: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットでも標準化残差が標準正規分布に従っていないことが示唆される。 qqnorm(rstandard(M2_1)) qqline(rstandard(M2_1)) 図2.4: QQplot for M2_1 残差に見られたパターンは、明らかに非線形なデータに直線的なモデルを当てはめているために生じている。図2.5からわかるように、水深2000m以上ではモデルに基づく回帰直線がほとんどデータの上に来てしまっている。また、水深約4000m以上では予測値がマイナスになってしまっている。 dataM2_1 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_1 &lt;- predict(M2_1, newdata = dataM2_1) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_1) pred_M2_1 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.5: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.2 Applying cubic polynomials モデルを改善するため、説明変数に水深の二乗、三乗、四乗項を入れるモデルを考える(= 多項式回帰)。このようにすることで非線形な関係をとらえられるかもしれない。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth^2_i + \\beta_3 \\times Depth^3_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] そのようなモデルは以下で実行できる。 M2_2 &lt;- lm(Dens ~ poly(MeanDepth, 3), data = fish) モデルの診断を行ったのが図2.6である。明確なパターンがあるように見え(A. 予測値が大きいほどばらつきが大きくなる、B. 水深が浅くなるほどばらつきが大きくなる)、モデルが十分に改善できていないことが分かる。 data.frame(resstd = rstandard(M2_2), fitted = fitted(M2_2)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_2_a data.frame(resstd = rstandard(M2_2), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_2_b p_diag_M2_2_a + p_diag_M2_2_b 図2.6: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットからも標準化残差が標準正規分布に従っていないことが分かる(図2.7)。 qqnorm(rstandard(M2_2)) qqline(rstandard(M2_2)) 図2.7: QQplot for M2_2 実測値にモデルに基づく予測値を描いたのが図2.8である。水深4000mあたりで予測値がほとんどの実測値よりも低くなってしまっている。 dataM2_2 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_2 &lt;- predict(M2_2, newdata = dataM2_2) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_2) pred_M2_2 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.8: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.3 A simple GAM モデルを改善するほかの選択肢は、一般化加法モデル(GAM)を用いることである。シンプルなGAMは以下のように書ける。\\(f(Depth_i)\\)は平滑化関数であり、予測値がデータに合うような曲線を描くように推定される。以下では、GAMではどのようにしてこの関数を推定するのかを説明していく。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + f(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{2.1} \\] 2.2.4 Moving average and LOESS smoother データに合うように平滑化を行う方法は複数存在するが、比較的単純なものが移動平均とLOESS(局所回帰)である。より複雑な手法については第3方で解説する。 2.2.4.1 移動平均 移動平均は、推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータの平均値を推定値とするような方法である。例えば、水深2500mのときの推定値として、その前後500m(2000m ~ 3000m)にあるデータの平均値を用いると、0.00286になる(図2.9)。 fish %&gt;% filter(MeanDepth &gt;= 2000 &amp; MeanDepth &lt;= 3000) %&gt;% summarise(mean = mean(Dens)) -&gt; mean fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_vline(xintercept = 2000, linetype = &quot;dashed&quot;)+ geom_vline(xintercept = 3000, linetype = &quot;dashed&quot;)+ geom_point(aes(x = 2500, y = mean$mean), size = 5, shape = 18, color = &quot;black&quot;)+ annotate(geom = &quot;text&quot;, x = 3000, y = mean$mean + 0.002, label = sprintf(&quot;%.5f&quot;,mean$mean))+ geom_segment(aes(x = 2550, xend = 2900, y = mean$mean, yend = mean$mean + 0.0015))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.9: Visualization of the process of the moving average. A target value of depth = 2500 was chosen. これを一定間隔のデータで行ってつなげると、移動平均に基づいて平滑化曲線を描くことができる(図2.10)。 Depth_n &lt;- seq(810, 4800, length.out = 150) Mean_n &lt;- data.frame(MeanDepth = Depth_n, Est = NA) for(i in seq_along(Depth_n)){ fish %&gt;% filter(MeanDepth &gt;= Depth_n[i] - 500 &amp; MeanDepth &lt;= Depth_n[i] + 500) %&gt;% summarise(mean = mean(Dens)) -&gt; mean_i Mean_n[i,2] &lt;- mean_i$mean } fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_line(data = Mean_n, aes(y = Est), linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.10: Estimated moving average smoother 2.2.4.2 局所回帰(LOESS) 移動平均ではギザギラのラインが推定されるが、LOESSではよりスムーズなラインを引くことができる。局所回帰は推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータだけを用いて多項式回帰を行い(多くのソフトでデフォルトでは2次の項までを含む)、その予測値を推定値とする方法である。移動平均と同様に一定間隔のポイントに対してこれを行うことで、平滑化した曲線を描く。 Rでは、loess関数で推定を行うことができる。span =で各ポイントでの推定に用いるデータの割合を指定できる(デフォルトは0.75)。図2.11はspanを0.1, 0.5, 1にした場合に描けるモデルから推定された平滑化曲線である。1のときは、全データを使用した多項式回帰と同じ結果である。移動平均でもLOESSでも、推定を行う際に使用するデータの範囲を変えると結果も大きく変わるので注意が必要である。 M2_3_a &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.1) M2_3_b &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.5) M2_3_c &lt;- loess(Dens ~ MeanDepth, data = fish, span = 1) pred_M2_3_a &lt;- predict(M2_3_a, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.1) pred_M2_3_b &lt;- predict(M2_3_b, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.5) pred_M2_3_c &lt;- predict(M2_3_c, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 1) bind_rows(pred_M2_3_a, pred_M2_3_b, pred_M2_3_c) %&gt;% mutate(span = str_c(&quot;span = &quot;, span)) %&gt;% ggplot(aes(x = MeanDepth, y = fit))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3)+ geom_point(data = fish, aes(y = Dens), shape = 1)+ facet_rep_wrap(~ span)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.11: LOESS smoother using a span of 0.1, 0.5, and 1. 2.2.5 Packages for smoothing Rには、平滑化を行うことができるパッケージが複数存在する。例えば、gamパッケージ(Hastie and Hastie 2018)、mgcvパッケージ(Wood and EPSRC 2007)、gamlssパッケージ(Rigby et al. 2019)などがある。それぞれのパッケージに長所と短所があり、gamはLOESSを用いる際に使いやすく、mgvcはより発展的な手法に対して使いやすい。gamlssはより広い分布に対して用いることができる。本稿では主にmgcvパッケージを用いる。 mgvcパッケージでは様々な手法を用いた平滑化を行うことができるが、自身のデータに対してどの方法を用いるかを決めるためにはこうした手法について知っていなければならない。こうした手法については、第(3)章で詳しく学ぶ。 2.3 Allpying GAM in R using the mgcv package 本節では、mgvcパッケージを用いてGAMを適用する方法を学ぶ。まず、gam関数を用いて式(2.1)を以下のように適用する。なお、fx = TRUE、k = 5というのは有効自由度4の平滑化関数が用いられていることを示しているが、詳しくは次章で説明する。 M2_4 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 5), data = fish) gam関数はthin plate regression splineといわれる方法を用いている。有効自由度は曲線の形を決める値であり(calibration value)、1だと直線になり大きくなるほどより非線形な形になる。自由度4は古典的なパッケージでデフォルトとしてよく使われている値であり、推定された曲線は3次の項までを含む多項式回帰によるものと似ている。次節(2.4)ではcross validationを用いてどの自由度が最も適切か決める方法を学ぶ。 summary関数でモデルの結果の概要を得ることができる。 summary(M2_4) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, fx = TRUE, k = 5) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0047137 0.0003616 13.04 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 4 4 22.12 3.27e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.367 Deviance explained = 38.4% ## GCV = 1.9894e-05 Scale est. = 1.9218e-05 n = 147 切片の推定値は0.0047なので、モデル式は以下のように書ける。 \\[ Dens_i = 0.0047 + f(Depth_i) \\] また、結果からはモデルが分散の36.9%を説明すること、推定された残差が従う正規分布の分散が\\(1.908 \\times 10^{-5}\\)であることも分かる。 smoother(\\(f(Dens_i)\\))の有意性(Approximate significance of smooth term)は、以下のF値によって計算されている。なお、\\(RSS_1、RSS_2\\)はそれぞれsmootherがないモデルとあるモデルの残差平方和、\\(pとq\\)はそれぞれsmootherがあるモデルとないモデルの自由度、\\(N\\)はサンプル数である。もしモデルが前提を満たすならば、Fは自由度\\(N-p\\)と\\(p-q\\)のF分布に従う。 \\[ F = \\frac{(RSS_1 - RSS_2)/(p-q)}{RSS_2/(N-p)} \\] モデルによって推定された曲線は以下のようになる(図2.12)。mgvcパッケージで推定した結果は、gratiaパッケージを用いると簡単に描画することができる。 dataM2_4 &lt;- data.frame(MeanDepth = seq(800, 4865, length.out = 100)) ## 予測値を算出 pred_M2_4_4 &lt;- fitted_values(M2_4, data = dataM2_4) %&gt;% mutate(df = 4) ## 描画 pred_M2_4_4 %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.12: Fitted values obtained by the GAM. 2.4 Cross validation 前節では自由度4で分析を行ったが、自由度はほかの値に設定することも可能である(図2.13。どのようにして最適な自由度を選べばよいだろうか? ## df = 2 M2_4_2 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 3), data = fish) pred_M2_4_2 &lt;- fitted_values(M2_4_2, data = dataM2_4) %&gt;% mutate(df = 2) ## df = 3 M2_4_3 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 4), data = fish) pred_M2_4_3 &lt;- fitted_values(M2_4_3, data = dataM2_4) %&gt;% mutate(df = 3) ## df = 5 M2_4_5 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 6), data = fish) pred_M2_4_5 &lt;- fitted_values(M2_4_5, data = dataM2_4) %&gt;% mutate(df = 5) ## df = 7 M2_4_7 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 8), data = fish) pred_M2_4_7 &lt;- fitted_values(M2_4_7, data = dataM2_4) %&gt;% mutate(df = 7) ## df = 9 M2_4_9 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 10), data = fish) pred_M2_4_9 &lt;- fitted_values(M2_4_9, data = dataM2_4) %&gt;% mutate(df = 9) ## 描画 bind_rows(pred_M2_4_2, pred_M2_4_3, pred_M2_4_4, pred_M2_4_5, pred_M2_4_7,pred_M2_4_9) %&gt;% mutate(df = str_c(&quot;df = &quot;,df)) %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) + facet_rep_wrap(~df, repeat.tick.labels = TRUE) 図2.13: Fitted values obtained by the GAM using 2, 3, 4, 5, 7, 9 degrees of freedom. gam関数では、fx =とk =を書かなければ自動的に交差検証(cross validation)を実行し、最適な自由度を探してくれる。下記のように、最適な自由度は5.62ということになる。 M2_5 &lt;- gam(Dens ~ s(MeanDepth), data = fish) summary(M2_5) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0047137 0.0003561 13.24 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.621 6.723 14.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.386 Deviance explained = 40.9% ## GCV = 1.9514e-05 Scale est. = 1.8635e-05 n = 147 推定結果をもとに描いた平滑化曲線は以下のようになる(図2.14)。 pred_M2_5 &lt;- smooth_estimates(M2_5, data = dataM2_4) %&gt;% ## 95%信頼区間を算出 add_confint() %&gt;% mutate(est = est + coef(M2_5)[[1]], lower_ci = lower_ci + coef(M2_5)[[1]], upper_ci = upper_ci + coef(M2_5)[[1]]) %&gt;% mutate(df = 4) ## 描画 pred_M2_5 %&gt;% ggplot(aes(x = MeanDepth, y = est))+ geom_line()+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(-0.001,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.14: Fitted values obtained by the GAM. それでは、交差検証とは何だろうか?smoother\\(f(Depth_i)\\)の推定値を\\(\\hat{f}(Depth_i)\\)とするとき、推定値が真のsmootherとどれほど近いかは以下の式で表せる。 \\[ M = \\frac{1}{n}\\sum_{i = 1} ^n (f(Depth_i) - \\hat{f}(Depth_i))^2 \\] もし私たちが真の\\(f(Depth_i)\\)を知っているならば、Mが最小になるように\\(\\hat{f}(Depth_i)\\)を推定することができるが、真のsmootherを知ることはできない。そのため、私たちは\\(M\\)を何か計算可能なもので代用する必要がある。 方法としては、交差検証、一般化交差検証(generalized cross validation)、頑強なリスク推定(unbiased risk estimator)、Marrow’s Cpなどがある。gam関数では、通常の加法モデルを適用するか、一般化加法モデルを適用するかによってこれらのいずれかが用いられる。本節では、通常の交差検証(ordinary cross validation: OCV)について簡単な解説を行う。 交差検証のスコア\\(V_0\\)は以下の式で与えられる。\\(f^{-i}(Depth_i)\\)は\\(i\\)番目のデータ以外のデータから推定されたsmootherの推定値を表す。\\(V_0\\)を最小にするようにsmootherの推定値を求める。 \\[ V_0 = \\frac{1}{n}\\sum_{i = 1} ^n (Depth_i -f^{-i}(Depth_i))^2 \\] 理論的に、\\(V_0\\)の期待値は\\(M\\)の期待値に分散\\(\\sigma^2\\)を足した値に近似できる。 \\[ E[V_0] \\approx E[M] + \\sigma^2 \\] これを計算するのは負荷が大きいため、通常はgeneralized cross validation scoreというものを用いることでshortcutを行う。詳細については第3章で解説を行う。データ数が50未満の場合は多重共線性やデータの非独立性によって交差検証の結果に問題が生じることがある。そのため、交差検証の結果をきちんと確認することが必要である。 2.5 Model validation 2.5.1 Normality and homogeneity GAMでは重回帰分析のときと同様に残差を抽出し、その正規性や等分散性、独立性、影響のある観察の有無を確認しなければならない。 gratiaパッケージでは、appraise関数でQQプロット、残差 vs 予測値、残差のヒストグラム、実測値 vs 予測値のプロットを作成してくれる(図2.15)。なお、それぞれのグラフはqq_plot()、residuals_linpred_plot()、residuals_hist_plot()、observed_fitted_plotで個別に作成できる。 この結果から、等分散性や残差の正規性が成立していないことが分かる。 appraise(M2_5, type = &quot;response&quot;) 図2.15: Model diagnosis using gratia package. 手動で残差 vs 予測値、残差のヒストグラムは以下のように作成できる(図2.16)。 data.frame(res &lt;- resid(M2_5), fitted = fitted(M2_5)) -&gt; diag_M2_5 diag_M2_5 %&gt;% ggplot(aes(x = fitted,y = res))+ geom_point()+ geom_hline(yintercept = 0, color = &quot;red&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted value&quot;, y = &quot;Residuals&quot;) -&gt; p_diag_M2_5_a diag_M2_5 %&gt;% ggplot(aes(x = res))+ geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Residuals&quot;, y = &quot;Frequancy&quot;) -&gt; p_diag_M2_5_b p_diag_M2_5_a + p_diag_M2_5_b 図2.16: Model diagnosis of GAM. 2.5.2 Independence 残差の独立性を確認するため、残差と説明変数などの変数の関連をプロットする(図2.17)。水深との関連については(A)、等分散性の仮定が満たされていないことを除けば、特にパターンは見られない。もし水深との関連にもパターンがみられていたら、GAMの自由度を上げることでこの問題を解決できる。 一方で、期間との関連についてはパターンがみられ、期間2の残差がほとんど0を下回っている。このことは、Periodをモデルに加えた方がいいことを示唆している。 data.frame(res = resid(M2_5), MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;, title = &quot;A&quot;) -&gt; p_ind_M2_5_a data.frame(res = resid(M2_5), Period = as.factor(fish$Period)) %&gt;% ggplot(aes(x = Period, y = res))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Period&quot;, y = &quot;Residuals&quot;, title = &quot;B&quot;) -&gt; p_ind_M2_5_b p_ind_M2_5_a + p_ind_M2_5_b 図2.17: A: residuals versus depth. B: residuals versus period 残差に空間的な相関があるかを調べるため、各データポイントで調査が行われた場所と残差の大きさの関連を示したものが図2.18である。残差の大きさが点の色と大きさで表されている。このデータだけではいまいち解釈がしにくい。 data.frame(res = resid(M2_5), x = fish$Xkm, y = fish$Ykm) %&gt;% ggplot(aes(x = x, y = y))+ geom_point(aes(color = res, size = res), alpha = 0.5)+ scale_size(range = c(1,7))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X-coordinates&quot;, y = &quot;Y-coordinates&quot;) 図2.18: Bubble plot of the residuals. このようなときに使えるのがバリオグラム(variogram)である。バリオグラムは以下の手順で作成する。なお、通常dは離散的に選択する。 全てのサイト間の距離を計算する。 距離がある特定の値dであるサイトの全組み合わせについて残差の差の二乗を計算し、それの平均値を算出する。 これを全ての距離について行い、距離と平均値の関係をプロットする。 もし残差が空間的に独立なのであれば、算出された平均値は水平に分布する。 Rではgstatパッケージで以下のように算出できる。図で表したものが図2.19である。図からは150m以上離れるとsemi-variogram値(縦軸)が大きくなる傾向があることが分かる。このパターンは、他の変数や交互作用をモデルに含めることで解消できるかもしれない。 fish_cor &lt;- fish ## coordinateを作成 sp::coordinates(fish_cor) &lt;- ~ Xkm + Ykm ## 算出 vario_M2_5 &lt;- gstat::variogram(resid(M2_5) ~ 1, fish_cor) ## 作図 vario_M2_5 %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(size = 3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Distance (km)&quot;, y = &quot;semivariogram&quot;) 図2.19: Semi-variogram of the residuals of the GAM. この分析の問題点は深さが考慮されていない点である。2地点間のxy平面上の距離が近くても、深さが違えば実際の距離は最大で5km近く離れている可能性がある。 2.5.3 Influential observations GAMではcook’s distanceは算出できないが、各観測値の影響力の強さは全データを用いたモデルから推定されたsmoother(\\(\\hat{f}(Depth_i)\\))からその観測値以外のデータを用いたモデルから推定されたsmoother(\\(f^{-i}(Depth_i)\\))を引いた値の二乗の合計値を算出することで求めることができる。各観測値について影響力の大きさは以下のように定式化できる。 \\[ I_i = \\sum_{i = 1}^n (\\hat{f}(Depth_i) - f^{-i}(Depth_i))^2 \\] Rでは以下のように計算できる。 nd &lt;- data.frame(MeanDepth = seq(min(fish$MeanDepth), max(fish$MeanDepth), length.out = 150)) pred_M2_5 &lt;- predict(M2_5, newdata = nd, type = &quot;terms&quot;) I &lt;- vector() for(i in 1:nrow(fish)){ M2_5.i &lt;- gam(Dens ~ s(MeanDepth), data = fish %&gt;% filter(Site != fish[i,1][[1]])) pred_M2_5.i &lt;- predict(M2_5.i, newdata = nd, type = &quot;terms&quot;) I[i] &lt;- sum((pred_M2_5[1:150] - pred_M2_5.i[1:150])^2) } 各ポイントの影響力の大きさをサイズにしてプロットしたのが図2.20である。いくつか影響力の高そうな点があるが、それが有意に大きいのか否かを言うことはできない。 fish %&gt;% mutate(I = I) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(size = I))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.20: Scatterplot of fish density versus depth. The size of an observation point is proportional to its influence on the shape of the smoother. 2.6 Extending the GAM with more covariates 2.6.1 GAM with smoother and a normal covariate GAMでも通常の線形モデルと同様に2つ以上の説明変数や交互作用を含めることができる。ここでは、これまでのモデルでは考慮できなかった調査期間(Period)と調査期間と水深(MeanDepth)の交互作用を入れることで、調査期間ごとに水深と魚の密度の関係が変わっているのかを調べるモデルを作成する。本節では交互作用なしとありのモデルを作成し、どちらがより良いモデルかを検討する。 交互作用なしモデルのモデル式は以下のようになる。このモデルでは、水深と魚の密度の関連はいずれの期間でも同じだが、その平均が期間によって異なることを仮定している。 \\[ \\begin{aligned} Dnes_i &amp;= \\alpha + f(Depth_i) + \\beta \\times Period_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sin N(0,\\sigma^2) \\end{aligned} \\] モデルはRで以下のように実行できる。 fish &lt;- fish %&gt;% mutate(Period = as.factor(Period)) M2_6 &lt;- gam(Dens ~ s(MeanDepth) + Period, data = fish) 結果は以下の通り。 summary(M2_6) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054572 0.0004291 12.716 &lt; 2e-16 *** ## Period2 -0.0021859 0.0007433 -2.941 0.00383 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.566 6.664 14.85 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.417 Deviance explained = 44.4% ## GCV = 1.8637e-05 Scale est. = 1.7677e-05 n = 147 モデルの推定結果からそれぞれの期間について以下のような式が書ける。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0032 + f(Depth_i) \\end{aligned} \\] モデルの結果を図示したのが図2.21である。 nd &lt;- crossing(MeanDepth = seq(800, 4650, length.out = 100), Period = as.factor(c(1,2))) fitted_values(M2_6, data = nd, scale = &quot;response&quot;) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish, aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.21: Visualisation of the GAM that contains a smoother of depth and period as a factor. 2.6.2 GAM with interaction terms; first implement GAMで交互作用を含める場合、モデルは以下のようになる。\\(f_1(Depth_i)\\)と\\(f_2(Depth_i)\\)はそれぞれの期間ごとのsmootherを表す。 \\[ \\begin{aligned} Dnes_i &amp;= \\alpha + f_1(Depth_i) +f_2(Depth_i) + \\beta \\times Period_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sin N(0,\\sigma^2) \\end{aligned} \\] このモデルはRでは以下のように実行できる。 M2_7 &lt;- gam(Dens ~ s(MeanDepth, by = Period) + Period, data = fish) 推定結果は以下の通り。期間ごとにsmootherを推定しているので、それぞれのsmootherの自由度が異なる。期間2は自由度が1.078なのでほとんど直線に近いことになる。 summary(M2_7) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, by = Period) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054405 0.0004286 12.693 &lt; 2e-16 *** ## Period2 -0.0022054 0.0007324 -3.011 0.00309 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth):Period1 4.169 5.094 17.18 &lt; 2e-16 *** ## s(MeanDepth):Period2 1.078 1.151 10.33 0.000913 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.419 Deviance explained = 44.4% ## GCV = 1.8547e-05 Scale est. = 1.7632e-05 n = 147 推定結果から、各期間の魚の密度と水深の関係は以下のようになる。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f_1(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0032 + f_2(Depth_i) \\end{aligned} \\] 推定結果を図示したのが図2.22である。 fitted_values(M2_7, data = nd, scale = &quot;response&quot;) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)), aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2))))+ facet_wrap(~Period) 図2.22: Visualisation of the GAM that contains a smoother of depth and period as a factor. 2.6.3 GAM with interaction; third implementation 期間ごとに異なるsmootherを推定するもう一つの方法として、以下のモデルを使うこともできる。ここで、\\(f(Depth)\\)は両期間に共通するsmoother、、\\(f_2(Depth)\\)は期間2のみに適用されるsmootherである。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + f(Depth_i) +f_2(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルはRで以下のように実行できる。モデル式の中にモデルM2_7のように\\(Period\\)が単独で説明変数として入っていない点には注意が必要である。これは、gamでs(MeanDepth, by = as.numeric(Period == \"2\"))のように指定を行う場合はsmootherが0で中心化されていないからである(それ以外の場合は0で中心化されている)。 M2_8 &lt;- gam(Dens ~ s(MeanDepth) + s(MeanDepth, by = as.numeric(Period == &quot;2&quot;)), data = fish) モデルの結果は以下のとおりである。期間2だけのsmootherも有意であるので、期間1と2でsmootherが有意に異なることが分かる。モデルM2_7と異なるのは、このように水深と魚の密度の関連が期間ごとに有意に異なるのかを検定できる点である。 summary(M2_8) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) + s(MeanDepth, by = as.numeric(Period == ## &quot;2&quot;)) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054462 0.0004248 12.82 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 4.714 5.729 15.697 &lt; 2e-16 *** ## s(MeanDepth):as.numeric(Period == &quot;2&quot;) 2.000 2.000 6.737 0.00161 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.428 Deviance explained = 45.4% ## GCV = 1.8319e-05 Scale est. = 1.7358e-05 n = 147 推定結果から、各期間の魚の密度と水深の関係は以下のようになる。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0054 + f(Depth_i) + f_2(Depth_i) \\end{aligned} \\] 推定結果を図示したのが図2.23である。 fitted_values(M2_8, data = nd, scale = &quot;response&quot;) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)), aes(y = Dens, fill = Period), shape = 21)+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ scale_linetype_manual(values = c(&quot;solid&quot;,&quot;dashed&quot;))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2))))+ facet_wrap(~Period) 図2.23: Visualisation of the GAM that contains a smoother of depth and period as a factor. これまでに適用した交互作用を含むモデル(M2_7とM2_8)のモデル診断を行うと、いずれも等分散性や正規性の仮定を満たしていないことが分かる(図2.24と図(fig:fig-gam-diagnosis-M2-8))。 このようなとき、取りうる手段は(1) 変数を変換する、(2)等分散性を許容できる推定方法(GLSなど)を用いる、(3) (1)と(2)を組み合わせた方法を用いる、などがある。以下では、こうした方法について議論する。 appraise(M2_7) 図2.24: Model diagnosis of M2_7 appraise(M2_8) 図2.25: Model diagnosis of M2_8 2.7 Transforming the density data まず、魚の密度の平方根を目的変数とするように変数変換を行ったモデルを考える。 fish &lt;- fish %&gt;% mutate(Dens_sqrt = sqrt(Dens)) M2_9_a &lt;- gam(Dens_sqrt ~ s(MeanDepth, by = Period) + Period, data = fish) しかし、変数変換を施しても等分散性の仮定は両期間で満たされない。 data.frame(res = resid(M2_9_a), Period = fish$Period, MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(aes(yintercept = 0))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;) 図2.26: Residuals versus Mean Depth for M2_9_a 魚の密度を対数変換することもできる。 fish &lt;- mutate(fish, Dens_log = log(Dens)) M2_9_b &lt;- gam(Dens_log ~ s(MeanDepth, by = Period) + Period, data = fish) そうすると、等分散性の問題が解決されたように見える。 data.frame(res = resid(M2_9_b), Period = fish$Period, MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(aes(fill = Period), shape = 21)+ geom_hline(aes(yintercept = 0))+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;) 図2.27: Residuals versus Mean Depth for M2_9_b ただし、QQプロットを見ると正規性の仮定は満たされていなさそう? qq_plot(M2_9_b)+ theme_bw()+ theme(aspect.ratio = 1) 図2.28: QQplot for M2_9 2.8 Allowing for heterogeneity 変数変換の問題点は、大きい目的変数の方が小さいものよりもより圧縮されることで、期間ごとの違いが小さくなってしまう傾向があることである。 Pinheiro and Bates (2000) は、モデルの中に分散の不均等性を入れ込むことができることを示した。残差が従う正規分布の分散として\\(\\sigma^2\\)ではなく、以下の3つのうちのいずれかを考える。 1つ目は、例えば期間ごと(\\(s = 1, 2\\))に異なる分散を考えるというものである。より細かくエリアごとに分散を求めたり、水深をカテゴライズしてそれぞれのカテゴリに異なる分散を割り当てることもできる。 2つ目と3つ目は、深さによって分散の値を変化させるというもので、その変化の仕方は最尤推定法によって推定されるパラメータ\\(\\delta\\)によって決定される。 \\[ \\begin{aligned} \\epsilon_i &amp;\\sim N(0, \\sigma_s^2)\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2 \\times |Depth_i|^{2 \\times \\delta}) \\\\ \\epsilon_i &amp;\\sim N(0, e^{2 \\times \\delta \\times Depth_i}) \\end{aligned} \\tag{2.2} \\] Zuur (2009) は、正しい分散構造や共変量を選ぶための10ステップのプロトコルを書いている。1つの選択肢は、たくさんの分散構造のモデルを当てはめてみて、AICなどでモデル選択を行うというものである。もう一つは、通常の分散を持つモデルの残差からどのような分散構造を当てはめるべきかを検討するというものである。 2つ目のアプローチをとるとすると、図2.26は2通りに解釈できる。 水深が2000m以下のデータはそれ以外のデータより大きな分散をとる 水深が深くなるほど、分散は小さくなっていく 1つ目の解釈に従うとすると、残差の従う正規分布の分散は以下のように書ける。 \\[ \\begin{aligned} var(\\epsilon_i) = \\begin{cases} \\sigma_2^2 &amp; (Depth_i &lt; 2000m)\\\\ \\sigma_1^2 &amp; (Depth_i &gt; 2000m)\\\\ \\end{cases} \\end{aligned} \\tag{2.3} \\] 2つ目の解釈に従うとすると、式(2.2)の2つ目か3つ目のアプローチをとることになる。2つで推定される結果の違いはほとんどなく、問題になるのは\\(Depth\\)が0になるときだけであるが、今回は問題ない(\\(Depth &gt; 800\\))。 式(2.3)はRでは以下のように実行できる。 fish %&gt;% mutate(IMD = ifelse(MeanDepth &lt; 2000, &quot;1&quot;,&quot;2&quot;)) %&gt;% mutate(IMD = as.factor(IMD)) -&gt; fish M2_10 &lt;- mgcv::gamm(Dens ~ s(MeanDepth, by = Period) + Period, weights = varIdent(form =~ 1|IMD), data = fish) 結果は、M2_10$lmeとM2_10$gamの2つに格納されている(正直、lmeの方はよくわからない)。 summary(M2_10$lme)のVariance functionで推定されている1.000…と0.134…は、期間1と2の標準偏差(\\(\\sigma_1, \\sigma_2\\))がそれぞれ\\(1.00 \\times \\sigma\\)と\\(0.13 \\times \\sigma\\)であることを示している。\\(\\sigma\\)の推定値はM2_10$lme$sigmaで求められ、0.0059であることから、期間1と2の分散はそれぞれ\\((1.00 \\times 0.0059)^2\\)、\\((0.13 \\times 0.0059)^2\\)である。 summary(M2_10$lme) ## Linear mixed-effects model fit by maximum likelihood ## Data: strip.offset(mf) ## AIC BIC logLik ## -1354.792 -1330.869 685.3962 ## ## Random effects: ## Formula: ~Xr - 1 | g ## Structure: pdIdnot ## Xr1 Xr2 Xr3 Xr4 Xr5 Xr6 ## StdDev: 0.00278938 0.00278938 0.00278938 0.00278938 0.00278938 0.00278938 ## Xr7 Xr8 ## StdDev: 0.00278938 0.00278938 ## ## Formula: ~Xr.0 - 1 | g.0 %in% g ## Structure: pdIdnot ## Xr.01 Xr.02 Xr.03 Xr.04 Xr.05 ## StdDev: 9.208057e-08 9.208057e-08 9.208057e-08 9.208057e-08 9.208057e-08 ## Xr.06 Xr.07 Xr.08 Residual ## StdDev: 9.208057e-08 9.208057e-08 9.208057e-08 0.005961115 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | IMD ## Parameter estimates: ## 1 2 ## 1.0000000 0.1348403 ## Fixed effects: y ~ X - 1 ## Value Std.Error DF t-value p-value ## X(Intercept) 0.004957091 0.0003399765 143 14.580687 0.0000 ## XPeriod2 -0.002669103 0.0003924738 143 -6.800718 0.0000 ## Xs(MeanDepth):Period1Fx1 -0.003085801 0.0011260515 143 -2.740373 0.0069 ## Xs(MeanDepth):Period2Fx1 -0.001177319 0.0001825878 143 -6.447962 0.0000 ## Correlation: ## X(Int) XPerd2 X(MD):P1 ## XPeriod2 -0.866 ## Xs(MeanDepth):Period1Fx1 -0.444 0.385 ## Xs(MeanDepth):Period2Fx1 0.000 -0.313 0.000 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.35949767 -0.40177858 -0.04041883 0.43543146 4.61217288 ## ## Number of Observations: 147 ## Number of Groups: ## g g.0 %in% g ## 1 1 summary(M2_10$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, by = Period) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0049571 0.0003376 14.682 &lt; 2e-16 *** ## Period2 -0.0026691 0.0003898 -6.848 2.14e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth):Period1 3.388 3.388 68.42 &lt;2e-16 *** ## s(MeanDepth):Period2 1.000 1.000 42.16 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.62 ## Scale est. = 3.5535e-05 n = 147 図2.29は標準化残差とモデルからの予測値をプロットしたものである。標準化残差\\(e_i^s\\)は以下のように求められる。\\(\\sigma_j\\)は期間ごとの分散である。プロットから、パターンが消えていることが確認できる。 \\[ \\begin{aligned} e_i &amp;= Dens_i - \\hat{\\alpha} - \\hat{f_1}(Depth_i) -\\hat{f_2}(Depth_i) -\\hat{\\beta} \\times Period_i \\\\ \\epsilon_i^s &amp;= \\frac{e_i}{\\sqrt{\\hat{\\sigma_j}^2}} \\end{aligned} \\] plot(M2_10$lme, col = 1, pch = 16, cex.lab = 1.5) 図2.29: Standardised residuals plotted versus fitted values obtained by the GAMM containing the varIdent residual variance structure. ただし、QQプロットを見ると正規性の仮定は満たされていなさそう? qq_plot(M2_10$gam)+ theme_bw()+ theme(aspect.ratio = 1) 図2.30: QQplot for M2_10 2.9 Transforming and allowing for heterogeinity 変数変換を行ったうえでまた等分散性の仮定が満たされない場合は、加えて式(2.2)のいずれかの方法で分散を調整することもできる。 Bailey et al. (2009) では以下のモデルを適用している。 \\[ \\begin{aligned} \\sqrt{Dens_i} &amp;= \\alpha + f(Depth_i) +f_2(Depth_i) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma_j^2)\\\\ \\sigma^2_j &amp;= \\begin{cases} \\sigma_2^2 &amp; (Depth_i &lt; 2000m)\\\\ \\sigma_1^2 &amp; (Depth_i &gt; 2000m)\\\\ \\end{cases} \\\\ \\end{aligned} \\] Rでは以下のように実行できる。 M2_11 &lt;- gamm(Dens_sqrt ~ s(MeanDepth, by = Period) + Period, weights = varIdent(form =~ 1|IMD), data = fish) モデル診断を実行すると、等分散性の問題も正規性の問題も解決できているように見える(図2.31)。 appraise(M2_11$gam) 図2.31: Model diagnosis for M_11 モデルM2_7, M2_9_a、M2_9_b、M2_11から得られた平滑化曲線を図示したのが図2.32である。 fish %&gt;% pivot_longer(cols = c(Dens,Dens_sqrt,Dens_log), values_to = &quot;Dens&quot;, names_to = &quot;type&quot;) %&gt;% mutate(type = ifelse(str_detect(type,&quot;sqrt&quot;),&quot;B&quot;, ifelse(str_detect(type,&quot;log&quot;),&quot;C&quot;,&quot;A&quot;))) %&gt;% bind_rows(fish %&gt;% select(-Dens,-Dens_log) %&gt;% rename(Dens = Dens_sqrt) %&gt;% mutate(type = &quot;D&quot;)) %&gt;% mutate(Period = str_c(&quot;Period &quot;,Period))-&gt; fish_long fitted_values(M2_7, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;A&quot;) %&gt;% bind_rows(fitted_values(M2_9_a, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;B&quot;)) %&gt;% bind_rows(fitted_values(M2_9_b, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;C&quot;)) %&gt;% bind_rows(fitted_values(M2_11, data = nd, scale = &quot;response&quot;) %&gt;% mutate(type = &quot;D&quot;)) %&gt;% mutate(Period = str_c(&quot;Period &quot;, Period)) %&gt;% ggplot(aes(x = MeanDepth))+ geom_point(data = fish_long, aes(y = Dens, fill = Period), shape = 21, alpha = 0.7, size = 2.5)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ new_scale_fill()+ geom_line(aes(y = fitted, linetype = Period), linewidth = 1.2)+ geom_ribbon(aes(ymin = lower, ymax = upper, fill = Period), alpha = 0.3)+ scale_fill_manual(values = c(&quot;grey45&quot;,&quot;red3&quot;))+ theme_bw(base_size = 13)+ theme(aspect.ratio = 1, strip.text = element_text(hjust = 0), strip.background = element_blank())+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;)), fill = &quot;Period&quot;, linetype = &quot;Period&quot;)+ guides(fill = guide_legend(override.aes = list(size = 3)))+ facet_rep_wrap(~type, repeat.tick.labels = TRUE, scales = &quot;free_y&quot;) 図2.32: Estimated smoothing curves obtained by a GAM. A: Gaussian GAM, B: Gaussian GAM square root density, C: Gaussian GAM log density, D: Gaussian GAM square root density, varIdent 2.10 What to present in paper 本章で行ったような分析を論文で記すとき、以下のものが含まれていなければいけない。 データを測定したサイトの場所を示した図(図2.1)。 検討した問い データ探索を行ったことと、なぜGAMを適用したかの説明 モデルの数学的な表現、モデルの結果、モデルの診断結果 図2.32のうちのいずれか References "],["Chapter3.html", "3 Technical aspects of GAM using pelagic bioluminescent organisms 3.1 Pelagic bioluminescent organism data 3.2 Lineaar regression 3.3 Polynomial regression model 3.4 Linear spline regression 3.5 Quadratic spline regression 3.6 Cubic regression splines 3.7 The number of knots 3.8 Penalized quadratic spline regression 3.9 Other smoothers 3.10 Cubic smoothing spline", " 3 Technical aspects of GAM using pelagic bioluminescent organisms 本章では、GAMの技術的な側面について説明を行う。 3.1 Pelagic bioluminescent organism data GAMの技術的な側面を解説するため、本章では Heger et al. (2008) が2004年夏に海洋生物の発光について調べた研究を用いる。船で海洋を航行中に検出した蛍光の強度(Source)と、水深(Depth)、温度(Temp)、塩分(Salinity)、酸素(Oxgen)などを測定している。 データは14のステーションでサンプルされている。データは以下の通り。 BL &lt;- read_delim(&quot;data/HegerPierce.txt&quot;) datatable(BL, options = list(scrollX = 20), filter = &quot;top&quot;) 3.2 Lineaar regression まずは線形回帰を行う。ひとまず、ステーションの違いは無視して分析を行う。 図3.1は水深(Depth)と\\(1m^3\\)あたりに確認した生物発光の数をプロットしたものである。データを見る限り直線的な関係があるわけではないことが分かる。 BL %&gt;% ggplot(aes(x = Depth, y = Sources)) + geom_point()+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1) 図3.1: Scatterplot of depth versus bioluminescence sources per m^3 以下のモデリングでは、水深を0から1にスケーリングする(モデルがうまく回らなくなるため)。 BL %&gt;% mutate(Original_Depth = Depth, Depth = Depth/max(Depth)) -&gt; BL 明確に直線的な関係はないが、まずは線形回帰を行う。データには様々な変数があるが、いくつかの変数は強く相関しているため、水深のみを説明変数として用いる(図3.2)。 ggpairs(BL %&gt;% select(Sources, Depth, Salinity, Temp, Oxgen)) 図3.2: Pair plot of the data. モデル式は以下のようになる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta \\times Depth_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のように実行する。 M3_1 &lt;- lm(Sources ~ Depth, data = BL) モデルによって推定された回帰直線をデータに当てはめると、明らかに当てはまりが悪いことが分かる(図3.3)。 nd_M3 &lt;- data.frame(Depth = seq(0,1,length.out = 100)) fitted_M3_1 &lt;- predict(M3_1, newdata = nd_M3,) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_1, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.3: Fitted line estimated from M3_1 本章の目的は、以下のような式を書いたときに\\(Depth\\)と\\(Sources\\)の関係をうまく説明できる\\(f(Depth_i)\\)という関数を見つけることである。先ほどの線形回帰では\\(f(Depth_i) = \\beta \\times Depth_i\\)だった。次節以降では、\\(f(Depth_i)\\)として何が最適かを探っていき、最終的にGAMの解説を行う。 \\[ Sources_i = \\alpha + f(Depth_i) + \\epsilon_i \\tag{3.1} \\] 3.3 Polynomial regression model 続いて、多項式回帰を行ってみる。モデル式は以下のとおりである。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\beta_3 \\times Depth^3 + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0, \\sigma^2) \\end{aligned} \\] Rでは以下のコードで実行できる。 M3_2 &lt;- lm(Sources ~ poly(Depth,3), data = BL) モデルによって推定された曲線をデータの上に描いたのが図3.4である。先ほどよりは当てはまりがよくなったが、左上と右下の当てはまりが悪いことが分かる。 fitted_M3_2 &lt;- predict(M3_2, newdata = nd_M3,) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_2, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.4: Fitted line estimated from M3_2 次節からは、GAMの数理的な基礎を理解するためにも以下のモデルを解説する。 線形スプライン回帰(linear spline regression) 二次スプライン回帰(quadratic spline regression) ノット数(numer of knots) 罰則付きスプライン回帰(penalized spline regression) 3.4 Linear spline regression 線形スプライン回帰とは、x軸をいくつかのセグメントに分け、それぞれのセグメントごとに線形回帰を行う方法である。問題は、いくつのセグメントにどのように分けるべきかということである。 図3.3や図3.4からは、スケール化された水深がだいたい0.2くらいで傾きが変わっている印象を受ける。そこで、0.2を境に傾きが変わるモデルを考える。ただし、このとき回帰直線は0.2でつながっていなければいけない。 実際にモデルを適用する前に、\\((Depth_i - 0.2)_+\\)を以下のように定義する。 \\[ (Depth_i - 0.2)_+ = \\begin{cases} 0 &amp; (Depth_i &lt; 0.2)\\\\ Depth_i - 0.2 &amp; (Depth_i ≧ 0.2)\\\\ \\end{cases} \\] Rでは以下のような関数rhsを作成してこうした変数を作成する。これは、ある変数xについて閾値THを境にそれ以下なら0、それ以上なら\\(x - TH\\)となるような新しい変数を作成する関数である。 rhs &lt;- function(x, TH) { ifelse(x &gt;= TH, x - TH, 0) } モデルは以下のようになる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_{11} \\times (Depth_i - 0.2)_+ + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] Rでこれを実装すると以下のようになる。 M3_3 &lt;- lm(Sources ~ Depth + rhs(Depth, 0.2), data = BL) モデルから推定された回帰曲線は以下のようになる(図3.5)。 fitted_M3_3 &lt;- predict(M3_3, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_3, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.5: Fitted line estimated from M3_3 問題は、モデルM3_3が通常の直線回帰モデル(M3_1)や多項回帰モデル(M3_2)よりもよいモデルかどうかである。赤池情報量規準(AIC)を持ちると3、M3_3はより予測の良いモデルだということが分かる。 AIC(M3_1, M3_2, M3_3) しかし、モデルM3_3にも問題点がいくつかある。\\(Depth = 0.2\\)での傾きの変化が急激であるということと、0.2という数値の選択基準が恣意的である点である。 こうした問題点を解決する手段として、例えばデータを10等分してそれぞれについて回帰直線を当てはめるというようなものが考えられる。この場合、傾きは以下の9ポイント(第1から第9十分位数)で変わることになる。このようなポイントをノット(knot)という。 q_Depth &lt;- quantile(BL$Depth, probs = seq(0.1,0.9,0.1)) このとき、モデル式は以下のように書ける。なお、\\(k_j\\)は第j十分位数を表す。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\sum_{j = 1}^9 \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+ \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルはRで以下のように実装できる。 M3_4 &lt;- lm(Sources ~ Depth + rhs(Depth, q_Depth[1]) + rhs(Depth, q_Depth[2]) + rhs(Depth, q_Depth[3]) + rhs(Depth, q_Depth[4]) + rhs(Depth, q_Depth[5]) + rhs(Depth, q_Depth[6]) + rhs(Depth, q_Depth[7]) + rhs(Depth, q_Depth[8]) + rhs(Depth, q_Depth[9]), data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.6)。 fitted_M3_4 &lt;- predict(M3_4, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_4, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.6: Fitted line estimated from M3_4 先ほどよりもよりデータへの当てはまりはよくなっているが、まだカクカクした線になっている。より細かく\\(Depth\\)を区分することは可能である。 model.matrix(M3_4)によって得られるこのモデルのsmootherの要素となった以下のものは、smootherの基底(smoother)と呼ばれる。 \\[ 1, Depth_i, (Depth_i - k_1)_+, (Depth_i - k_2)_+, \\dots, (Depth_i - k_9)_+ \\] 3.5 Quadratic spline regression 適切な\\(f(Depth_i)\\)を探す試みとして線形スプライン回帰を行ったが、ノットで傾きがカクカクしてしまっていた。これに代わる方法として、二次スプライン回帰(quadratic spline regression)を考えることができる。モデルは以下のように書ける。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\sum_{j = 1}^k \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+^2 \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.2} \\] そのため、\\(Depth_i\\)を10等分するのであれば、このモデルにおける基底は以下の12個になる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^2, (Depth_i - k_2)_+^2, \\dots, (Depth_i - k_9)_+^2 \\] このモデルをRで実装するため、以下の関数を作成する。これは、ある変数xについて閾値THを境にそれ以下なら0、それ以上なら\\((x - TH)^2\\)となるような新しい変数を作成する関数である。 rhs2 &lt;- function(x, TH) { ifelse(x &gt;= TH, (x - TH)^2, 0) } モデルは以下のように実行できる。 M3_5 &lt;- lm(Sources ~ Depth + I(Depth^2) + rhs2(Depth, q_Depth[1]) + rhs2(Depth, q_Depth[2]) + rhs2(Depth, q_Depth[3]) + rhs2(Depth, q_Depth[4]) + rhs2(Depth, q_Depth[5]) + rhs2(Depth, q_Depth[6]) + rhs2(Depth, q_Depth[7]) + rhs2(Depth, q_Depth[8]) + rhs2(Depth, q_Depth[9]), data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.7)。線形スプライン回帰よりもなめらかな曲線になっていることが分かる。 fitted_M3_5 &lt;- predict(M3_5, newdata = nd_M3) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% bind_cols(nd_M3) BL %&gt;% ggplot(aes(x = Depth, y = Sources))+ geom_point(size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_5, aes(y = fitted), linewidth = 1)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.7: Fitted line estimated from M3_5 以下、モデルの結果を見てみよう。rhs2関数で作られた変数の多くが有意でないのは、これらが強く相関しており多重共線性の問題があることが原因だろう。 summary(M3_5) ## ## Call: ## lm(formula = Sources ~ Depth + I(Depth^2) + rhs2(Depth, q_Depth[1]) + ## rhs2(Depth, q_Depth[2]) + rhs2(Depth, q_Depth[3]) + rhs2(Depth, ## q_Depth[4]) + rhs2(Depth, q_Depth[5]) + rhs2(Depth, q_Depth[6]) + ## rhs2(Depth, q_Depth[7]) + rhs2(Depth, q_Depth[8]) + rhs2(Depth, ## q_Depth[9]), data = BL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -42.285 -4.850 -1.006 2.705 63.710 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 175.444 28.621 6.130 1.25e-09 *** ## Depth -1410.486 409.840 -3.442 0.000601 *** ## I(Depth^2) 3291.466 1430.389 2.301 0.021584 * ## rhs2(Depth, q_Depth[1]) -549.110 2067.208 -0.266 0.790578 ## rhs2(Depth, q_Depth[2]) -2891.946 1340.997 -2.157 0.031269 * ## rhs2(Depth, q_Depth[3]) 368.134 1190.504 0.309 0.757212 ## rhs2(Depth, q_Depth[4]) -935.978 1061.824 -0.881 0.378262 ## rhs2(Depth, q_Depth[5]) 1197.211 877.679 1.364 0.172843 ## rhs2(Depth, q_Depth[6]) -445.930 730.756 -0.610 0.541842 ## rhs2(Depth, q_Depth[7]) 30.872 592.644 0.052 0.958466 ## rhs2(Depth, q_Depth[8]) 5.152 400.189 0.013 0.989732 ## rhs2(Depth, q_Depth[9]) -152.712 295.507 -0.517 0.605421 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.148 on 1037 degrees of freedom ## Multiple R-squared: 0.6892, Adjusted R-squared: 0.6859 ## F-statistic: 209.1 on 11 and 1037 DF, p-value: &lt; 2.2e-16 式(3.2)のモデルは正規分布の一般化加法モデルといえる。mgvcパッケージではより発展的なsmootherを用いており、多重共線性の問題などが生じないようなっている。 このモデルは第1章のときのように以下のように書ける。なお、\\(\\bf{y}\\)は目的変数をすべて含むベクトル、\\(\\bf{X}\\)はmodel.matrix(M3_5)によって得られる基底の行列、\\(\\bf{\\beta}\\)は回帰係数をすべて含むベクトルである。この表現で書けるということは、第1章と全く同じ方法で標準誤差や自由度、信頼区間、予測区間を算出できるということである。 \\[ \\bf{y} = \\bf{X} \\times \\bf{\\beta} + \\bf{\\epsilon} \\] 3.6 Cubic regression splines より回帰曲線を滑らかにするのであれば、3次スプライン回帰を考えることもできる。モデル式は以下の通り。Rでも前節までと同様に実行することができる。 \\[ \\begin{aligned} Sources_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth_i^2 + \\beta_3 \\times Depth_i^3 + \\sum_{j = 1}^k \\Bigl( \\beta_{1j} \\times (Depth_i - k_j)_+^3 \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.3} \\] Wood (2017) や Zuur (2009) では、さらに発展的な方法として以下のモデルを考えた。 \\[ \\begin{aligned} Sources_i &amp;= \\sum_{j = 1}^K \\Bigl( \\beta_{j} \\times b_j(Depth_i) \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.4} \\] ここで、\\(b_1(Depth_i) = 1, b_2(Depth_i) = Depth\\)であり、\\(j ≧ 2\\)のときは\\(B_j(Depth_i) = R(Depth_i, k_{j-2})\\)である。また、\\(k_{j-2}\\)は\\(j-2\\)番目のノットの値を表す。よって、以下のようにも書ける。 \\[ \\begin{aligned} Sources_i &amp;= \\beta_1 + \\beta_1 \\times Depth_i + \\sum_{j = 2}^K \\Bigl( \\beta_{j} \\times R(Depth_i, k_{j-2}) \\Bigl) + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\tag{3.5} \\] なお、\\((Depth_i, k_{j-2})\\)は以下のように定義される。 \\[ R(X,z) = \\frac{1}{4} \\times \\Bigl( (z - \\frac{1}{2})^2 - \\frac{1}{12} \\Bigl) \\times \\Bigl( (X - \\frac{1}{2})^2 - \\frac{1}{12} \\Bigl) - \\frac{1}{24} \\times \\Bigl( (|X-z| - \\frac{1}{2})^4 - \\frac{1}{2}(|X-z| - \\frac{1}{2})^2 + \\frac{7}{240} \\Bigl) \\] Rでもこの関数を作成する。 rk &lt;-function(x, z){ ((z-0.5)^2-1/12)*((x-0.5)^2-1/12)/4 - ((abs(x-z)-0.5)^4-0.5*(abs(x-z)- 0.5)^2 +7/240)/24 } また、説明変数をすべて含む行列\\(\\bf{X}\\)を作成する必要がある。この行列は1列目は全て1、2列目は\\(Depth_i\\)で、3列目以降は\\(R(Depth_i, k_{j-2})\\)である。Rでは以下のように作成できる。 spl.X &lt;-function(x, xk){ q &lt;-length(xk) + 2 n &lt;-length(x) X &lt;-matrix(1, n, q) X[,2] &lt;-x X[,3:q] &lt;-outer(x, xk, FUN = rk) X } X &lt;- spl.X(BL$Depth, q_Depth) Rでモデルを以下のように実行できる。なお、\\(\\bf{X}\\)にはすでに切片に相当する1列目が含まれているため、Sources ~ X - 1とする。 M3_6 &lt;- lm(Sources ~ X - 1, data = BL) このモデルによって推定された回帰曲線は以下のとおりである(図3.8)。2次スプライン回帰の結果と大きくは違わない。 Xp &lt;- spl.X(nd_M3$Depth, q_Depth) fitted_M3_6 &lt;- data.frame(Depth = nd_M3$Depth, fitted = Xp %*% coef(M3_6)) BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_M3_6, aes(x = Depth, y = fitted), linewidth = 1)+ geom_vline(xintercept = q_Depth, linetype = &quot;dashed&quot;)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ coord_cartesian(ylim = c(0,120), xlim = c(0.1,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.8: Fitted line estimated from M3_6 3.7 The number of knots 第3.4から3.6節までは\\(Depth_i\\)を10の区間に分けており、両端を除くとノット数は9だった。しかし、この数はあくまでも恣意的に選択したものに過ぎない。それでは、私たちはノット数をいくつに設定するのが適切なのだろうか。 図3.9は両端を除くノット数を変化させたときの回帰曲線を図示したものである。結果を見てみると、ノット数による違いはそこまで大きくないように思える。 num &lt;- c(1,3,5,7,9,11,13,15,17, 19, 31) q_Depth_list &lt;- list() X_list &lt;- list() for(i in seq_along(num)){ q_Depth_list[[i]] &lt;- quantile(BL$Depth, probs = seq(0,1,by = 1/(num[i]+1)))[2:(num[i]+1)] X_list[[i]] &lt;- spl.X(BL$Depth, q_Depth_list[[i]]) } M3_6_list &lt;- list() Xp_list &lt;- list() fitted_list &lt;- list() for(i in seq_along(num)){ M3_6_list[[i]] &lt;- lm(Sources ~ X_list[[i]] - 1, data = BL) Xp_list[[i]] &lt;- spl.X(nd_M3$Depth, q_Depth_list[[i]]) fitted_list[[i]] &lt;- data.frame(Depth = nd_M3$Depth, fitted = Xp_list[[i]] %*% coef(M3_6_list[[i]]), knot = num[i]) } bind_rows(fitted_list[1], fitted_list[[2]], fitted_list[[3]], fitted_list[[4]], fitted_list[[5]], fitted_list[[6]], fitted_list[[7]], fitted_list[[8]], fitted_list[[9]], fitted_list[[10]], fitted_list[[11]]) %&gt;% mutate(knot_text = str_c(&quot;inner knot = &quot;, knot)) %&gt;% mutate(knot_text = fct_reorder(knot_text, knot))-&gt; fitted_all BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_all, aes(x = Depth, y = fitted), linewidth = 1)+ facet_rep_wrap(~knot_text, repeat.tick.labels = TRUE)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.9: Fitted smoothers for a quadratic spline regression model using different numbers of knots. AICなどによってこれらのモデルの比較を行うことはできる(図3.10)。AICとAICcに基づくとノット数が7のモデルが最もよく(値が最も小さく)、そこからノット数が離れるほど予測がよくなくなる(= 値が大きくなる)。BICに基づくとノット数が5のときが最も予測が良い。 compare_performance(M3_6_list[[1]],M3_6_list[[2]],M3_6_list[[3]], M3_6_list[[4]],M3_6_list[[5]],M3_6_list[[6]], M3_6_list[[7]],M3_6_list[[8]],M3_6_list[[9]], M3_6_list[[10]],M3_6_list[[11]]) %&gt;% data.frame() %&gt;% mutate(knot = num) %&gt;% select(knot, AIC, AICc, BIC, R2, R2_adjusted) %&gt;% pivot_longer(c(AIC, AICc, BIC), names_to = &quot;IC&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = knot, y = value))+ geom_point(aes(color = IC, shape = IC), size = 5, stroke = 2, alpha = 0.7)+ scale_shape_manual(values = c(1,5,0))+ scale_x_continuous(breaks = num)+ labs(y = &quot;Information criteria&quot;, color = &quot;&quot;, shape = &quot;&quot;)+ theme_bw()+ theme(aspect.ratio = 1) 図3.10: AIC, AICc, BIC of the models with different number of knots. しかし、毎回このように様々なノット数でモデリングを行い、情報量規準などに基づいた比較を行うのは時間がかかってしまう。そこで考えられたのが次節(3.8)で説明するpenalized sline modelと呼ばれるものである。 3.8 Penalized quadratic spline regression 各モデルにおいて、回帰係数などのパラメータは最小二乗法によって推定されている。すなわち、以下で表される残差平方和が最小になるように推定を行っている。 \\[ Minimize\\; over \\;\\bf{\\beta} : \\sum_i \\epsilon_i^2 \\] 行列形式で表すと以下のようになる。 \\[ Minimize\\; over \\;\\bf{\\beta} : ||\\bf{\\epsilon^2}|| = ||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}||^2 \\] このとき、\\(\\bf{\\beta}\\)の推定値は以下の通りである(第1章も参照)。 \\[ \\hat{\\bf{\\beta}} = (\\bf{X^t} \\times \\bf{X})^{-1} \\times \\bf{X^t} \\times y \\] さて、ここで式(3.2)に従う二次スプライン回帰モデルを考える。もし両端を除くノット数がKであるとき、\\((Depth-k_j)_+^2\\)の回帰係数${11}, {12}, , _{1K} $を推定することになる。これらのパラメータは平滑化曲線(回帰曲線)の形に柔軟性を与える(= 形を調整する)役割を担っている。 ノット数を変えることで曲線の形を調整することはできるが、図3.9で見たようにノット数によって曲線の形は大きくは変わらなかった。そこで、ノット数を変えるのではなく、ノット数は固定して推定されるパラメータに制限をかけることでsmootherの形を調整するアプローチを考える。例えば、パラメータ\\(\\beta_{11}, \\beta_{12}, \\dots, \\beta_{1K}\\)の二乗がある定数\\(C\\)以下になるように推定を行うことを考える。 \\[ \\beta_{11}^2 + \\beta_{12}^2 + \\cdots + \\beta_{1K}^2 &lt; C \\tag{3.6} \\] こうした方法は制限付き最適化(constrained optimization)と呼ばれる。 ある条件内で残差平方和を最小化するパラメータはラグランジュの未定乗数法と呼ばれる方法で推定できる。例として、条件下で以下の関数\\(f(x,y)\\)を最大にする\\(x,y\\)の組み合わせを探すことを考える。 \\[ \\begin{aligned} f(x,y) = 2x^2 + 2y^2 \\:\\: subject \\:\\: to \\:\\: x + y = 1 \\end{aligned} \\] まず、以下の関数\\(f(x,y,\\lambda)\\)を考える。 \\[ f(x,y,\\lambda) = 2x^2 + 2y^2 + \\lambda(x + y-1) \\] 次に、\\(f(x,y,\\lambda)\\)をそれぞれの変数について偏微分した値が全て0になるように連立方程式を解く。 \\[ \\begin{aligned} 4x + \\lambda &amp;= 0\\\\ 4y + \\lambda &amp;= 0\\\\ x + y -1 &amp;= 0 \\end{aligned} \\] すると、簡単に\\(x = 1/2, y= 1/2\\)と解けるが、これが条件の下で\\(f(x,y)\\)を最大化する\\(x\\)と\\(y\\)の値である。制限付き最適化についてもまったく同じことを行う。式(3.6)のような条件があるときに\\(||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}||\\)を最小化するパラメータを求めるには、以下を最小化すればよい。 \\[ ||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}|| + \\lambda \\times (\\beta_{11}^2 + \\beta_{12}^2 + \\cdots + \\beta_{1K}^2 + C) \\tag{3.7} \\] 以下のような\\(K+3\\)次元の行列(\\(K\\)はノット数)\\(\\bf{D}\\)とベクトル\\(\\bf{\\beta}\\)を定義する。 \\[ \\bf{D} = \\begin{bmatrix} 0 &amp; \\cdots &amp; \\quad &amp; \\quad &amp; \\cdots&amp; 0\\\\ \\vdots &amp; 0 &amp; \\quad &amp; \\quad &amp; \\quad &amp; \\vdots\\\\ \\quad &amp; \\quad &amp; 0 &amp; \\quad &amp; \\quad &amp; \\quad \\\\ \\quad &amp; \\quad &amp; \\quad &amp; 1 \\quad &amp; \\quad &amp; \\vdots\\\\ \\vdots &amp; \\quad &amp; \\quad &amp; \\quad &amp; \\ddots &amp; 0\\\\ 0 &amp; \\cdots &amp; \\quad &amp; \\cdots &amp; 0 &amp; 1 \\end{bmatrix}, \\quad \\bf{\\beta} = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2\\\\ \\beta_3\\\\ \\beta_{11}\\\\ \\vdots\\\\ \\beta_{19} \\end{bmatrix} \\] このとき、式(3.7)は以下のように変形できる。 \\[ ||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}|| + \\lambda \\times (\\bf{\\beta^t} \\times \\bf{D} \\times \\bf{\\beta} - \\bf{C}) \\tag{3.8} \\] これを\\(\\bf{\\beta}\\)について解くと、その推定値は以下のようになる。もし\\(\\lambda = 0\\)ならば(= 何も条件がなければ)、推定値は通常の最小二乗法によるものと同じになる。 \\[ \\hat{\\bf{\\beta}} = (\\bf{X^t} \\times \\bf{X} + \\lambda \\times \\bf{D})^{-1} \\times \\bf{X^t} \\times \\bf{y} (\\#eq:est_beta) \\] \\(\\lambda\\)が特定の値を割り当てれば、smoother(\\(f_{\\lambda}\\))を決定することができる。\\(\\hat{\\beta}\\)は\\(\\lambda\\)の値によって変わるので、\\(f_{\\lambda}\\)も\\(\\lambda\\)によって変わる。\\(\\lambda\\)はペナルティの大きさを表すので、大きいほどスプライン回帰を行わない通常の線形回帰や多項式回帰の結果に近づき、0ならば罰則のないスプライン回帰の結果と同じになる。 \\[ \\hat{f_{\\lambda}} = \\bf{X} \\times \\bf{\\hat{\\beta}} \\] \\(\\lambda\\)の値ごとの曲線を図示したのが図3.11である。\\(\\lambda\\)が大きくなると2次の項までを含む普通の多項式回帰の結果に近づく。 K &lt;- 9 D &lt;- diag(rep(1, 3 + K)) D[1,1]&lt;-D[2,2]&lt;-D[3,3] &lt;-0 X &lt;- model.matrix(M3_5) lambdas &lt;- c(0, 0.25,0.7, 0.75, 1,10) beta &lt;- list() Yhat &lt;- list() for (i in seq_along(lambdas)){ beta[[i]] &lt;- solve(t(X) %*% X + lambdas[i] * D) %*%t(X) %*% BL$Sources MyDepth &lt;- seq(0.1, 1, length =100) XPred &lt;- model.matrix(~ 1 + MyDepth + I(MyDepth^2)+ rhs2(MyDepth, q_Depth[1]) + rhs2(MyDepth, q_Depth[2]) + rhs2(MyDepth, q_Depth[3]) + rhs2(MyDepth, q_Depth[4]) + rhs2(MyDepth, q_Depth[5]) + rhs2(MyDepth, q_Depth[6]) + rhs2(MyDepth, q_Depth[7]) + rhs2(MyDepth, q_Depth[8]) + rhs2(MyDepth, q_Depth[9])) Yhat[[i]] &lt;- XPred %*% as.vector(beta[[i]]) %&gt;% data.frame() %&gt;% rename(fitted = 1) %&gt;% mutate(lambda = lambdas[i], Depth = MyDepth) } fitted_lambda &lt;- bind_rows(Yhat[[1]], Yhat[[2]], Yhat[[3]], Yhat[[4]], Yhat[[5]],Yhat[[6]]) %&gt;% mutate(lambda_text = str_c(&quot;lambda = &quot;, lambda)) BL %&gt;% ggplot()+ geom_point(aes(x = Depth, y = Sources), size = 2, alpha = 0.6, color = &quot;grey54&quot;)+ geom_line(data = fitted_lambda, aes(x = Depth, y = fitted), linewidth = 1)+ facet_rep_wrap(~lambda_text, repeat.tick.labels = TRUE)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1, strip.background = element_blank(), strip.text = element_text(hjust = 0))+ coord_cartesian(ylim = c(0,120), xlim = c(0.105,1))+ labs(x = &quot;Scaled depth&quot;, y = &quot;Sources&quot;) 図3.11: Three smoothers using different values for λ 3.9 Other smoothers mgcvパッケージやgamlssパッケージで用いられるsmootherには様々な種類がある。本節では、これらのいくつかについてまとめ、次節(3.10)では、3次平滑化スプラインについて詳しく解説する。 二次スプライン回帰(第3.5節)や罰則付きの二次スプライン回帰(第3.8節)では、以下の変数が説明変数(基底)となる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^2, (Depth_i - k_2)_+^2, \\dots, (Depth_i - k_9)_+^2 \\] これは\\(p\\)次までの項を含むモデルについて以下のように一般化できる。このようなモデルはp次スプライン回帰モデルまたは罰則付きp次スプライン回帰と呼ばれる。 \\[ 1, Depth_i^2, (Depth_i - k_1)_+^p, (Depth_i - k_2)_+^p, \\dots, (Depth_i - k_K)_+^p \\] これらのモデルの問題点は各変数が強く相関している可能性が高いことである(特にノット数が多いときは)。Bスプライン平滑化(B-spline smoothing)と呼ばれる手法は、変数変換を施すことでこの問題を解決する。 絶対値の\\(p\\)乗項を含むモデルを考えることもできる。そのようなsmootherは放射基底平滑化(radial basis smoother)と呼ばれ、以下の基底を含む。 \\[ 1, Depth_i^2, |Depth_i - k_1|^p, |Depth_i - k_2|^p, \\dots, |Depth_i - k_K|^p \\] 3.10 Cubic smoothing spline 第3.8節でやったように\\(\\beta_{11}, \\dots, \\beta_{1K}\\)に制限を設けるのではなく、smootherの二次導関数(二回微分値)の和に制限を設ける方法もある。その場合、以下を最小化するようなパラメータを推定する。 \\[ ||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}||^2 + \\lambda \\times 全ポイントでの二次導関数の和 \\tag{3.9} \\] 一般にsmoother(\\(f(x)\\))の二次導関数を\\(f&#39;&#39;(x)\\)とするとき、\\(f&#39;&#39;(x)\\)の値が低いほど\\(f(x)\\)はより直線的であることを示す。全ての\\(x\\)について\\(f&#39;&#39;(x)\\)の値を合計するためには、\\(f&#39;&#39;(x)\\)を積分してやればよい。 そのため、式(3.9)は以下のように書き直せる。 \\[ ||\\bf{Y} - \\bf{X} \\times \\bf{\\beta}||^2 + \\lambda \\times \\int f&#39;&#39;(x) dx \\tag{3.10} \\] Wood (2017) は、この基準で最小になる\\(f(x)\\)が3次スプラインであることを証明している。また、式(3.10)は式(3.8)のように書き直すことが分かっているので、\\(\\beta\\)の推定値を得るのに積分をする必要はなく、式@ref(eq:est_beta)で求めることができる。 \\(\\bf{\\beta}\\)を推定するためには、\\(\\bf{X}\\)とパラメータ\\(\\lambda\\)、罰則を表す行列\\(\\bf{D}\\)を知る必要がある。3次平滑化スプライン(cubic smoothing spline)の基本は3次回帰スプライン(cubic regression spline)と同じなので、\\(\\bf{X}\\)は同じものを用いることができる。 両端を除くノット数はこれまでと同様に9とする。 X &lt;- spl.X(BL$Depth, q_Depth) \\(\\bf{D}\\)は\\(11\\times 11\\)の正方行列で、成分は第3.6で出てきた\\(R(X,z)\\)によって決まる。\\(\\bf{D}(i + 2, j + 2)\\)は\\(R(x_i,x_j)\\)によって決まり、\\(x_iとx_j\\)は両端を除くノットの値である。 Rでは以下の関数で計算できる。 spl.S &lt;- function(xk){ q &lt;- length(xk) + 2 S &lt;- matrix(0, nrow = q, ncol = q) S[3:q, 3:q] &lt;- outer(xk, xk, FUN = rk) S } D &lt;- spl.S(q_Depth) 最後に、\\(\\lambda\\)については References "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] fontregisterer_0.3 systemfonts_1.0.4 extrafont_0.18 lemon_0.4.6 ## [5] ggsci_2.9 concaveman_1.1.0 ggforce_0.4.1 ggdag_0.2.7 ## [9] dagitty_0.3-1 kableExtra_1.3.4 knitr_1.43 DT_0.27 ## [13] patchwork_1.1.2 GGally_2.1.2 ggnewscale_0.4.9 htmlwidgets_1.6.2 ## [17] plotly_4.10.1 sp_1.5-1 data.table_1.14.6 see_0.7.5.5 ## [21] report_0.5.7.4 parameters_0.20.3 performance_0.10.3 modelbased_0.8.6.3 ## [25] insight_0.19.1.4 effectsize_0.8.3.6 datawizard_0.7.1.1 correlation_0.8.4 ## [29] bayestestR_0.13.1 easystats_0.6.0.8 forcats_1.0.0 stringr_1.5.0 ## [33] dplyr_1.1.2 purrr_1.0.0 readr_2.1.3 tidyr_1.2.1 ## [37] tibble_3.2.1 ggplot2_3.4.2 tidyverse_1.3.2 gstat_2.1-1 ## [41] gratia_0.8.1.34 mgcv_1.8-41 nlme_3.1-160 ## ## loaded via a namespace (and not attached): ## [1] googledrive_2.0.0 colorspace_2.0-3 estimability_1.4.1 ## [4] fs_1.5.2 rstudioapi_0.15.0 farver_2.1.1 ## [7] fansi_1.0.3 mvtnorm_1.1-3 lubridate_1.9.0 ## [10] xml2_1.3.3 codetools_0.2-18 splines_4.2.2 ## [13] cachem_1.0.6 polyclip_1.10-4 jsonlite_1.8.4 ## [16] Rttf2pt1_1.3.8 broom_1.0.2 dbplyr_2.2.1 ## [19] compiler_4.2.2 httr_1.4.4 emmeans_1.8.3 ## [22] backports_1.4.1 assertthat_0.2.1 Matrix_1.5-1 ## [25] fastmap_1.1.0 lazyeval_0.2.2 gargle_1.2.1 ## [28] cli_3.6.0 tweenr_2.0.2 htmltools_0.5.4 ## [31] tools_4.2.2 igraph_1.3.5 coda_0.19-4 ## [34] gtable_0.3.3 glue_1.6.2 V8_4.2.2 ## [37] Rcpp_1.0.11 cellranger_1.1.0 jquerylib_0.1.4 ## [40] vctrs_0.6.2 svglite_2.1.1 extrafontdb_1.0 ## [43] xfun_0.39 rvest_1.0.3 timechange_0.1.1 ## [46] lifecycle_1.0.3 googlesheets4_1.0.1 MASS_7.3-58.1 ## [49] zoo_1.8-11 scales_1.2.1 tidygraph_1.2.2 ## [52] hms_1.1.3 RColorBrewer_1.1-3 curl_4.3.3 ## [55] yaml_2.3.7 mvnfast_0.2.8 gridExtra_2.3 ## [58] sass_0.4.5 reshape_0.8.9 stringi_1.7.8 ## [61] ggokabeito_0.1.0 boot_1.3-28 intervals_0.15.4 ## [64] rlang_1.1.1 pkgconfig_2.0.3 evaluate_0.20 ## [67] lattice_0.20-45 tidyselect_1.2.0 plyr_1.8.8 ## [70] magrittr_2.0.3 bookdown_0.34 R6_2.5.1 ## [73] generics_0.1.3 DBI_1.1.3 pillar_1.9.0 ## [76] haven_2.5.1 withr_2.5.0 xts_0.12.2 ## [79] spacetime_1.3-0 modelr_0.1.10 crayon_1.5.2 ## [82] utf8_1.2.2 tzdb_0.3.0 rmarkdown_2.23 ## [85] grid_4.2.2 readxl_1.4.1 FNN_1.1.3.2 ## [88] reprex_2.0.2 digest_0.6.31 webshot_0.5.4 ## [91] xtable_1.8-4 munsell_0.5.0 viridisLite_0.4.2 ## [94] bslib_0.4.2 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
