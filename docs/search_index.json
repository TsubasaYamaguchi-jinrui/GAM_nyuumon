[["index.html", "Introduction to GAM using R 本稿の目的", " Introduction to GAM using R Tsubasa Yamaguchi 2023-07-20 本稿の目的 本稿で扱うのは、以下の内容である。 参考にしたのは主に以下の文献である。 なお、本稿の作成に使用したファイルとRのコードは筆者のGithubですべて閲覧できる。 "],["Chapter0.html", "0. パッケージの読み込み", " 0. パッケージの読み込み 本稿では、 ## GAM library(mgcv) library(gratia) library(gstat) ## データハンドリング library(tidyverse) library(easystats) library(data.table) ## グラフや表関連 library(sp) library(plotly) library(htmlwidgets) library(GGally) library(patchwork) library(DT) library(knitr) library(kableExtra) library(dagitty) library(ggdag) library(ggforce) library(concaveman) library(ggsci) library(lemon) ## フォント関連 library(extrafont) require(systemfonts) require(fontregisterer) なお、本稿はRの基本操作とtidyverseパッケージによるデータハンドリングができることを前提としている。tidyverseパッケージを用いたデータ処理については、以下の書籍などを参照。 R for Data Science (Wickham &amp; Grolemund, 2016) 電子書籍, 日本語 R Graphics Coocbook 2nd Edition (Chang, 2018) 電子書籍, 日本語 RユーザのためのRstudio[実践]入門~tidyverseによるモダンな分析フローの世界 改訂2版 (松村 et al., 2021) 出版社サイト References Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["Chapter1.html", "1 Review of multiple linear regressions 1.1 Light levels and size of the human visual system 1.2 The variables 1.3 Protocol for the analysis 1.4 Data exploration 1.5 Multiple linear regression 1.6 Finding the optimal model 1.7 Degree of freedom 1.8 Model validation 1.9 Model interpretation 1.10 What to do if things go wrong", " 1 Review of multiple linear regressions 本章では、一般化加法モデル(GAM)の説明に入る前に、多くの人に馴染みのある重回帰分析(multiple linear regression)について説明する、なぜなら、GAMは重回帰分析を拡張したものだからである。 1.1 Light levels and size of the human visual system Pearce &amp; Dunbar (2012) は、ヒトの集団が住んでいる標高と眼窩の容量に正の関連があることから、住んでいる環境の光量がヒトの視覚システムの進化の原動力になっていると結論付けた。本章ではこの論文のデータを用いて重回帰分析について説明を行う。重回帰分析でデータを探索し、モデルを構築し、モデルを当てはめ、モデル選択を行い、モデルの妥当性を確認する方法はGAMでもほとんど同じように適用できる。 1.2 The variables Pearce &amp; Dunbar (2012) は、オックスフォード大学博物館にある55人の成人の頭蓋骨から、頭蓋の容量(cranial capacity: CC)と眼窩容量(orbital volume)、大後頭孔(foramen magnum: FM)などの測定を行った。 データは以下のとおりである。平均眼窩容量(mean orbital volume)が目的変数であり、それ以外の変数は説明変数である1。AbsoluteLatitudeとMinimum_Tempreture_celsiusはそれぞれ 頭蓋が発見された場所の標高と最低気温、FMarea_intercondyleは体格の大きさを示す指標、Minimum_Illuminanceはlogスケールで表した光の強度、Genderは頭蓋の性別である。 hvs &lt;- read_delim(&quot;data/HVS.txt&quot;) datatable(hvs, filter = &quot;top&quot;, options = list(scrollX = 20)) 変数名が長いので、以下のように短く変更する。 hvs %&gt;% rename(OrbitalV = MeanOrbitalVolume, LatAbs = AbsoluteLatitude, CC = CranialCapacity, Illuminance = Minimum_Illuminance, Temperature = Minimum_Temperature_celsius, FM = FMarea_intercondyle) %&gt;% mutate(fPopulation = factor(Population), fGender = factor(Gender)) -&gt; hvs 新しい列名は以下の通り。 colnames(hvs) ## [1] &quot;Museum&quot; &quot;Findsite&quot; &quot;Gender&quot; &quot;Population&quot; &quot;Latitude&quot; ## [6] &quot;LatAbs&quot; &quot;CC&quot; &quot;FM&quot; &quot;OrbitalV&quot; &quot;Illuminance&quot; ## [11] &quot;Temperature&quot; &quot;fPopulation&quot; &quot;fGender&quot; 1.3 Protocol for the analysis いかなるデータ分析も、以下の手順に沿って行わなければならない。 Data exploration 外れ値がないか、多重共線性(説明変数同士の強い相関)がないか、目的変数と説明変数の関係がどうか、ゼロ過剰はないか、サンプリングの収集が時間や場所によってばらついていないか、などをチェックする必要がある。 Model application 1の作業で分かったことや研究仮説をもとに、適切なモデルを適用する。今回は重回帰分析を行うが、様々なモデルを適用可能である。 Check the result モデルを当てはめたら、どの変数が有意な影響を持つかを調べ、そうでなかった変数についてはどうするかを考える。 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。満たしていれば結果の解釈や結果の作図を行い、満たしていなければモデルを改善する必要がある(GAM、GLM、GLMを使うなど)。 1.4 Data exploration まずは手順1のデータ探索を行う。データ探索については Zuur et al. (2010) に詳しい。 1.4.1 欠損値の確認 まず、欠損値がないかを調べる。 colSums(is.na(hvs)) ## Museum Findsite Gender Population Latitude LatAbs ## 0 0 0 0 0 0 ## CC FM OrbitalV Illuminance Temperature fPopulation ## 0 1 0 0 0 0 ## fGender ## 0 FMの列に1つ欠損値があるので取り除く。 hvs_b &lt;- na.omit(hvs) 1.4.2 外れ値の確認 続いて、外れ値がないかを確認する。ここでは、連続値の説明変数(Latitude、CC、FM、Illuminance、Temperature)についてCleveland Dotplotを作成する。Dotplotは縦軸にサンプル番号、横軸に実際の値をとる。 図は以下のとおりである(図1.1)。図を見る限り、外れ値はなさそうだ。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature) %&gt;% mutate(sample_number = 1:n()) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = sample_number))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Values of the variable&quot;, y = &quot;Sample number&quot;)+ theme(aspect.ratio = 1) 図1.1: Cleveland dotplot for covariates. 1.4.3 多重共線性の確認 次に、多重共線性(説明変数同士の強い相関)がないかを調べる。もしあると、推定結果にバイアスが生じてしまう。 説明変数同士の関連を調べたところ(図1.2)、LatAbsとIlluminance、IlluminanceとTemperature、TemperatureとLatAbsに強い相関があることが分かる。また、CCは男性で高い傾向があることが分かったので、CCとfGenderを同じモデルに説明変数として入れない方がよさそうである(今回はfGenderを用いない)。 ggpairs(hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, fGender)) 図1.2: correlation between covariates 1.4.4 目的変数と説明変数の関係の確認 最後に、目的変数と説明変数の関連を調べる(図1.3)。図には局所回帰(LOESS)による回帰曲線を追加している。 図から、LatAbsとOrbitalVの間に線形の関係がありそうだということが分かる(’CC’も?)。IlluminanceやTemperatureにも同様のことがいえるが、これは変数間に強い相関があることを考えれば当然だろう。多重共線性を考慮し、Pearce &amp; Dunbar (2012) にもとづいて解析ではLatAbsを用いてIlluminanceとTemperatureは用いないこととする。 hvs_b %&gt;% select(LatAbs, CC, FM, Illuminance, Temperature, OrbitalV) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = OrbitalV))+ geom_point(alpha = 1)+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ labs(x = &quot;Explanatory Variables&quot;, y = &quot;OrbitalV&quot;)+ theme(aspect.ratio = 1)+ geom_smooth(method = &quot;loess&quot;, se= F, color = &quot;grey32&quot;, span = 0.9) 図1.3: Relationship between explanatory variables and orbital volume (OrbitalV). A LOESS smoother was added to the plot. 1.5 Multiple linear regression 1.5.1 Underlying statistical theory それでは、重回帰分析を行う。まずは説明のために説明変数が1つだけのモデル(= 単回帰)を考えよう。 標高のみを説明変数とする単回帰モデルは以下のように実行できる。 M1 &lt;- lm(OrbitalV ~ LatAbs, data = hvs_b) summary(M1) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9893 -1.4166 -0.1616 1.5037 3.8887 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 22.91064 0.51412 44.563 &lt; 2e-16 *** ## LatAbs 0.06598 0.01411 4.677 2.11e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.253 on 52 degrees of freedom ## Multiple R-squared: 0.2961, Adjusted R-squared: 0.2825 ## F-statistic: 21.87 on 1 and 52 DF, p-value: 2.111e-05 これは、実際には何をやっているのだろうか? lm関数で短回帰を実行するとき、私たちは下記のモデルを実行している。なお、\\(i\\)はサンプル番号(今回は55個の頭蓋がある)を、2行目は\\(\\epsilon_i\\)が平均0、分散\\(\\sigma^2\\)の正規分布に従うことを表す。 \\[ \\begin{aligned} OrvitalV_i &amp;= \\alpha + \\beta\\times LatAbs_i + \\epsilon_i \\;\\; (i = 1,2,\\dots, 55)\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] このモデルで推定するパラメータは\\(\\alpha\\)、\\(\\beta\\)、\\(\\sigma\\)である。\\(\\beta\\)は標高(LatAbs)が眼窩容量(OrbitalV)に与える影響の大きさを表し、式からわかるように標高が1増えると眼窩容量が\\(\\beta\\)増えることを表す。先ほどlm関数で実行した結果でEstimateの下に書かれていた数字(\\(22.91...と0.065...\\))は\\(\\alphaと\\beta\\)の推定値を示しているのである。 もし以下のように行列を定義すると、 \\[ \\begin{aligned} \\mathbf{y} = \\begin{pmatrix} OrbitalV_1\\\\ OrbitalV_2\\\\ \\vdots\\\\ OrvitalV_{55} \\end{pmatrix} , \\mathbf{X} = \\begin{pmatrix} 1 &amp; LatAbs_1\\\\ 1 &amp; LatAbs_2\\\\ \\vdots &amp; \\vdots\\\\ 1 &amp; LatAbs_{55} \\end{pmatrix}, \\mathbf{\\beta} = \\begin{pmatrix} \\alpha\\\\ \\beta \\end{pmatrix}, \\mathbf{\\epsilon} = \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_{55} \\end{pmatrix} \\end{aligned} \\] モデル式は以下のように書ける。 \\[ \\mathbf{y = X\\times\\beta + \\epsilon} \\] \\(\\mathbf{X}\\)はRで以下のように求められる。 head(model.matrix(M1)) ## (Intercept) LatAbs ## 1 1 1.33 ## 2 1 5.42 ## 3 1 5.42 ## 4 1 28.51 ## 5 1 28.51 ## 6 1 28.51 パラメータは最小二乗法(ordinary least square)で求められる。最小二乗法は、残差の二乗和(実際の測定値と推定されたモデルによる予測値の差、ここでは\\(\\sum_i^{55}( y_i - \\alpha + \\beta \\times OrbitalV_i)\\))が最小になるようにパラメータを推定する方法である。 \\(bfmath(\\beta)\\)の推定値は数学的に以下のように求められる。なお、\\(\\mathbf{X^t}\\)は\\(\\mathbf{X}\\)の転置行列を、\\(\\mathbf{X^{-1}}\\)はは\\(\\mathbf{X}\\)の逆行列を表す。 \\[ \\mathbf{\\hat{\\beta}} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t} \\times \\mathbf{y} \\tag{1.1} \\] なお、\\(\\mathbf{\\hat{\\beta}}\\)は\\(\\mathbf{\\beta}\\)の推定値であることを表し、便宜的にここでは\\(\\mathbf{\\hat{\\beta}} = \\begin{pmatrix}a\\\\b \\end{pmatrix}\\)とする。 Rでは\\(\\mathbf{\\hat{\\beta}}\\)を以下のように求められ、lm関数で推定した場合と同じ推定値が得られることが分かる。 X &lt;- model.matrix(M1) solve(t(X) %*% X) %*% t(X) %*% hvs_b$OrbitalV ## [,1] ## (Intercept) 22.9106427 ## LatAbs 0.0659754 よって、モデルによって推定された眼窩容量(\\(\\hat{y_i}\\))は以下のように表せる。 \\[ Fitted OrbitalV_i = 22.930 + 0.066 \\times LatAbs_i \\] すなわち、モデルの推定値から得られた残差\\(e_i\\)は以下のように表せる。 \\[ e_i = OrbitalV_i - a + b\\times LatAbs_i \\] \\(\\mathbf{\\hat{y}} = \\mathbf{X}\\times \\mathbf{\\beta}\\)と書けるので、残差の行列\\(\\mathbf{e}\\)は\\(\\mathbf{H} = (\\mathbf{X^t}\\times \\mathbf{X})^{-1} \\times \\mathbf{X^t}\\)とするとき以下のように書ける。 \\[ \\mathbf{e} = \\mathbf{y} - \\mathbf{\\hat{y}} = \\mathbf{y} - \\mathbf{H\\times y} = \\mathbf{(1-H)\\times y} \\tag{1.2} \\] モデル式より、\\(\\mathbf{y}\\)の分散共分散行列は\\(\\sigma^2 \\times \\mathbf{I}\\)と表せるので(\\(\\mathbf{I}\\)は単位行列)、\\(\\mathbf{e}\\)の分散共分散行列は以下のように表せる。 \\[ cov(\\mathbf{e}) = \\sigma^2 \\times (\\mathbf{1 - H}) \\] また、以下の値を標準化残差(standardized residuals)という。なお、\\(H_{ii}\\)は\\(\\mathbf{H}\\)の\\(i\\)番目の対角成分を表す。 \\[ e_i ^* = \\frac{e_i}{\\hat{\\sigma} \\sqrt{(1-H_{ii})}} \\] もしモデルが正しいとき、標準化残差は標準正規分布に従うので、その値のほとんどは-2から2の間に収まるはずである。 Rでは、残差と標準化残差を以下のように求められる。 e &lt;- resid(M1) estd &lt;- rstandard(M1) 実際、1つのデータを除いて-2から2の範囲に収まっている(図1.4)。 data.frame(estd = estd) %&gt;% ggplot(aes(x = estd))+ geom_histogram(binwidth = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ scale_y_continuous(breaks = seq(0,10,1)) 図1.4: 標準化残差の分布 1.5.1.1 外れ値のチェック モデルに極端な外れ値がないかを調べるときには、LeverageとCook’s distanceが用いられることが多い。 *everageは\\(\\mathbf{H}\\)の対角成分で0から1の値をとり、大きいほどそのデータポイントが結果に大きな影響を与える外れ値であることを示す。特に極端な値はないよう(図1.5)。 data.frame(h = diag(H), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = h))+ geom_col(width = 0.3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Leverage&quot;) 図1.5: Leveragevalue for each observation 式(1.2)より、以下のように書ける。すなわち、\\(i\\)番目の観察に対してモデルから予測される値(fitted value)は元データの観測値の加重平均であり、重みは行列\\(\\mathbf{H}\\)により与えられる。 \\[ \\hat{y_i} = H_{i1} \\times y_1 + H_{i2} \\times y_2 + \\dots + H_{i55} \\times y_55 \\tag{1.3} \\] 特に\\(H_{ii}\\)は観測値\\(y_i\\)がモデルからの予測値\\(\\hat{y_i}\\)に与える影響の大きさを表している。そのため、\\(H_{ii}\\)が高いことは、その観測値がモデルの推定に大きな影響を及ぼしていることを示しているのである。 ある観測値がモデルの推定に影響を与えている度合いを表すのがCook’s distanceで、以下の式で表せる。\\(\\hat{y_{(i)}}\\)は式(1.3)から\\(H_{ii}\\times y_i\\)を除いたものである。また、\\(p\\)はモデルの回帰式の中のパラメータ数である。 \\[ D_i = \\frac{||\\hat{y_i} - \\hat{y_{(i)}}||}{p \\times \\hat{\\sigma^2}} \\] Cook’s distanceはRで以下のように取得できる。 D &lt;- cooks.distance(M1) data.frame(cookD = D, n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cookD))+ geom_col(width = 0.2)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;sample number&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.6: Cook’s distance for each observation 1.5.1.2 95%信頼区間と予測区間の算出 \\(\\mathbf{\\beta}\\)の推定値の分散共分散行列は\\(\\mathbf{y}\\)の分散共分散行列が\\(\\mathbf{\\sigma^2 \\times I}\\)であることを考えると、式(1.1)より以下のようになる。 \\[ \\begin{aligned} cov(\\mathbf{\\hat{\\beta}}) &amp;= \\mathbf(X^t \\times X)^{-1} \\times \\mathbf{X^t} \\times cov(\\mathbf{y}) \\times \\mathbf{X} \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\\\ &amp;= \\sigma^2 \\times (\\mathbf{X^t} \\times \\mathbf{X})^{-1} \\end{aligned} \\] \\(\\hat{\\beta}\\)の標準偏差は上式から得られる行列の対角成分の1/2乗である。この値は、lm関数を利用した結果(Std. Errorの下の数値)と一致する。 SE &lt;-summary(M1)$sigma * sqrt(diag(solve(t(X) %*% X))) SE ## (Intercept) LatAbs ## 0.51411731 0.01410749 95%信頼区間は、モデル式より\\(\\beta\\)が正規分布に従うので以下のように求められる。 Z &lt;- rbind(coef(M1) + 1.96*SE, coef(M1) - 1.96*SE) %&gt;% data.frame() rownames(Z) &lt;- c(&quot;Upper bound&quot;, &quot;Lower bound&quot;) Z ## X.Intercept. LatAbs ## Upper bound 23.91831 0.09362607 ## Lower bound 21.90297 0.03832472 ただし、これはサンプルサイズが十分に大きいときのみ成り立つ。実際は、\\(\\hat{\\beta}\\)は自由度\\(55-2\\)(サンプル数 - パラメータ数)のt分布に従うので、より正確に95%信頼区間を求めるには、1.96ではなく2.005746…を用いる必要がある。 qt(1- 0.05/2, df = 55-2) ## [1] 2.005746 95％信頼区間は、もし100回同様の方法で実験/観察を行ってそれぞれについて95%信頼区間を算出するとき、そのうち95個には真の値が含まれていることを表す。95%信頼区間に0が含まれていないとき、\\(\\hat{\\beta}\\)が有意に0とは違うということができる。 同様に、モデルに基づいた予測値の分散共分散行列は以下のように求められ、その対角成分の1/2乗が予測値の標準誤差(SE)になる。 \\[ cov(\\mathbf{\\hat{y}}) = \\mathbf{X} \\times cov(\\mathbf{\\hat{\\beta}}) \\times \\mathbf{X^t} \\tag{1.4} \\] 予測値の95%信頼区間はある標高(LatAbs)に対して100回データをサンプリングすれば95個のデータが含まれる範囲を表し、予測値が自由度55-2のt分布に従うので、\\(予測値 ± 2.0057 \\times SE\\)で求められる。 一方で95%予測区間は新たにデータをサンプリングしたときにデータの95%が収まる範囲を指す。予測区間を求める際の標準誤差には式(1.4)に\\(\\hat{\\sigma^2}\\)を足したものを用いればよい。 Rでは予測値と95%信頼区間、95%予測区間は以下のように求められる。 ## 係数の分散共分散行列 covbeta &lt;- vcov(M1) data &lt;- data.frame(LatAbs = seq(0,65,length.out = 100)) X &lt;- model.matrix(~LatAbs, data = data) t &lt;- qt(1-0.05/2, df = 55-2) data %&gt;% ## 予測値 mutate(p = X %*% coef(M1)) %&gt;% ## se(信頼区間) mutate(se.ci = sqrt(diag(X %*% covbeta %*% t(X)))) %&gt;% ## se(予測区間) mutate(se.pi = sqrt(diag(X %*% covbeta %*% t(X)) + summary(M1)$sigma^2)) %&gt;% mutate(ci_upper = p + t*se.ci, ci_lower = p - t*se.ci, pi_upper = p + t*se.pi, pi_lower = p - t*se.pi) -&gt; pred 図示すると以下のようになる(図1.7)。 pred %&gt;% ggplot(aes(x = LatAbs, y = p))+ geom_line()+ geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(aes(ymin = pi_lower, ymax = pi_upper), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point(data = hvs_b, aes(y = OrbitalV))+ theme(aspect.ratio = 1)+ theme_bw()+ labs(y = &quot;OrbitalV&quot;) 図1.7: 95%信頼区間と予測区間 predict関数を用いて簡単に求めることができる。 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;confidence&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; conf_M1 predict(M1, newdata = data.frame(LatAbs = seq(0,65,0.2)), interval = &quot;prediction&quot;) %&gt;% data.frame() %&gt;% bind_cols(data.frame(LatAbs = seq(0,65,0.2))) -&gt; pred_M1 hvs_b %&gt;% ggplot(aes(x = LatAbs, y = OrbitalV))+ geom_line(data = conf_M1, aes(y = fit))+ geom_ribbon(data = conf_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey21&quot;, alpha = 0.5)+ geom_ribbon(data = pred_M1, aes(y = fit, ymin = lwr, ymax = upr), fill = &quot;grey72&quot;, alpha = 0.5)+ geom_point()+ theme(aspect.ratio = 1)+ theme_bw() 図1.8: 95%信頼区間と予測区間(predict関数を使用) 1.5.2 Multiple linear regression それでは、2つ以上の変数を含めたモデリングを行う。データ探索や先行研究の知見から、モデルにはLatAbs、CC、FMを説明変数として入れ、2変数の交互作用を全ての組み合わせについて含めた。 \\[ \\begin{aligned} OrbitalV_i &amp;= \\alpha + \\beta_1 \\times LatAbs_i + \\beta_2 \\times CC_i + \\beta_3 \\times FM_i \\\\ &amp; + \\beta_4 \\times LatAbs_i \\times CC_i\\\\ &amp; + \\beta_5 \\times LatAbs_i \\times FM_i \\\\ &amp; + \\beta_6 \\times CC_i \\times FM_i + \\epsilon_i\\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 1.5.3 Fitting the model in R and estimate parameters モデルのパラメータは、先ほどと同様にlm関数で推定できる。推定は前節で行ったのと全く同じ方法(最小二乗法)で行う。 M2 &lt;- lm(OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM, data = hvs_b) 結果は以下の通り。Estimateはパラメータの推定値を、t valueは5%水準でパラメータが有意に0と異なっているかを判断する際に用いられる。P値(Pr(&gt;|t|))を見ると、有意な変数は一つもなかった。 print(summary(M2), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + ## CC:FM, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.79 -1.50 -0.23 1.40 4.63 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.19e+01 2.24e+01 0.97 0.335 ## LatAbs -2.51e-01 1.60e-01 -1.56 0.124 ## CC 9.37e-04 1.65e-02 0.06 0.955 ## FM 2.16e-03 3.50e-02 0.06 0.951 ## LatAbs:CC 2.37e-04 1.30e-04 1.83 0.074 ## LatAbs:FM -4.49e-05 1.57e-04 -0.29 0.776 ## CC:FM -1.56e-06 2.50e-05 -0.06 0.951 ## ## Residual standard error: 2.14 on 47 degrees of freedom ## Multiple R-squared: 0.427, Adjusted R-squared: 0.354 ## F-statistic: 5.84 on 6 and 47 DF, p-value: 0.000131 1.6 Finding the optimal model さて、先ほどのモデルでは1つも有意に0と異なるパラメータ(\\(\\alpha, \\beta_1 \\sim \\beta_6\\))はなかった(= 目的変数に有意な影響を持つ説明変数変数がなかった)。このようなとき、選択肢がいくつかある。 そのままのモデルを採用し、全ての交互作用が5%水準では有意ではなかったと報告する。 AICを利用して古典的なモデル選択を行う。 仮説検定の結果に基づいて変数選択を行う(効果のなさそうな変数を外す)。 交互作用についてのみモデル選択を行う。 情報理論的アプローチを用い、モデル平均化などを行う(c.f., Burnham et al. (2011) )。 ここでは、 Pearce &amp; Dunbar (2012) に従い、AICを用いたモデル選択を行うことにする。 Rでは、step関数を用いることでステップワイズ法(AICが最も低くなるまで説明変数を1つずつ増減させる方法)を用いた変数選択を行うことができる。分析の結果、LatAbs、CC、これらの交互作用のみを含むモデルが最もAICが低い(= 予測精度が高い)と判断された。 step(M2) ## Start: AIC=88.54 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM + CC:FM ## ## Df Sum of Sq RSS AIC ## - CC:FM 1 0.0177 214.75 86.547 ## - LatAbs:FM 1 0.3756 215.11 86.637 ## &lt;none&gt; 214.74 88.543 ## - LatAbs:CC 1 15.2596 230.00 90.250 ## ## Step: AIC=86.55 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC + LatAbs:FM ## ## Df Sum of Sq RSS AIC ## - LatAbs:FM 1 0.4172 215.17 84.652 ## &lt;none&gt; 214.75 86.547 ## - LatAbs:CC 1 15.2501 230.00 88.252 ## ## Step: AIC=84.65 ## OrbitalV ~ LatAbs + CC + FM + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## - FM 1 0.5409 215.71 82.788 ## &lt;none&gt; 215.17 84.652 ## - LatAbs:CC 1 16.8268 232.00 86.718 ## ## Step: AIC=82.79 ## OrbitalV ~ LatAbs + CC + LatAbs:CC ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 215.71 82.788 ## - LatAbs:CC 1 17.24 232.95 84.940 ## ## Call: ## lm(formula = OrbitalV ~ LatAbs + CC + LatAbs:CC, data = hvs_b) ## ## Coefficients: ## (Intercept) LatAbs CC LatAbs:CC ## 2.323e+01 -2.552e-01 -5.829e-05 2.201e-04 そこで、選ばれた変数のみを用いたモデルを作成し、分析を行う。 M3 &lt;- lm(OrbitalV ~ LatAbs*CC, data = hvs_b) 分析の結果は以下のとおりである。交互作用項の係数の推定値のP値が0.051であり、わずかに交互作用項の影響があることが示唆された? print(summary(M3), digits = 3, signif.stars = FALSE) ## ## Call: ## lm(formula = OrbitalV ~ LatAbs * CC, data = hvs_b) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.759 -1.504 -0.098 1.513 4.588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.32e+01 5.23e+00 4.44 4.9e-05 ## LatAbs -2.55e-01 1.53e-01 -1.67 0.101 ## CC -5.83e-05 3.94e-03 -0.01 0.988 ## LatAbs:CC 2.20e-04 1.10e-04 2.00 0.051 ## ## Residual standard error: 2.08 on 50 degrees of freedom ## Multiple R-squared: 0.425, Adjusted R-squared: 0.39 ## F-statistic: 12.3 on 3 and 50 DF, p-value: 3.81e-06 1.7 Degree of freedom 重回帰分析では、 モデルの自由度は回帰式のパラメータ数なので4である。しかし、このような自由度の求め方はGAMではできない。一般に、パラメータ数は\\(\\mathbf{H}\\)の対角成分の和(= trace)で求めることができる。 \\[ p = \\sum_{i =1} ^{55} \\mathbf{H_{ii}} \\] 確かに4になっている。 X &lt;- model.matrix(M3) H &lt;- X %*% solve(t(X) %*% X) %*% t(X) sum(diag(H)) ## [1] 4 1.8 Model validation 最後に、作成したモデルが前提を満たしているかをチェックする。残差には普通の残差のほかに、標準化残差、スチューデント化残差などがあるが、ここでは標準化残差を用いる。 等分散性が成り立つか (→ モデルに基づく予測値と残差をプロットする) モデルがデータに当てはまっているか、残差の独立性があるか (→ 残差とモデルに含まれる説明変数、モデルに含まれない説明変数の関係をプロットする) データの独立性があるか(→ 自己相関があるかを確認する) 残差が正規分布に従うかを確認する(→ QQプロットを書く) モデルへの影響が大きいデータがないか確認する(→ Cook’s distanceやLeverage) まず、モデルによる予測値と標準化残差の関係をプロットする(図1.9)。このときプロットにパターンがあってはいけない(e.g., 広がっていく、ばらつきが不均等など)。もし前提を満たしていれば、0を中心に均等にばらつくはずである。図からは、明確なパターンは見られない(横軸が26~27で負の残差がほとんどないなどを除けば)。 data.frame(fitted = fitted(M3), resstd = rstandard(M3)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;) 図1.9: Standardized residuals versus fitted values to assess homogeneity 続いて、Cook`s distanceを用いて影響の大きいデータがないか確認する。Cook’s distanceは通常1を超えると影響が大きいと判断される2。ほんもでるではそのような値をとる観測値はない(図1.10)。 data.frame(cook = cooks.distance(M3), n = 1:nrow(hvs_b)) %&gt;% ggplot(aes(x = n, y = cook))+ geom_col(width = 0.2)+ geom_hline(yintercept = 1, linetype = &quot;dotted&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Observations&quot;, y = &quot;Cook&#39;s distance&quot;) 図1.10: Cook’s disance for each observation 残差の正規性は、ヒストグラムとQQプロットを基に判断される。QQプロットとは、「得られたデータ(今回の場合は標準化残差)と理論分布(今回の場合は標準正規分布)を比較し、その類似度を調べるためのグラフ」である。詳細についてはこちら。もし類似度が高ければ、点が直線上に乗る。そこまで大きくは外れていなさそう。 qqnorm(rstandard(M3)) qqline(rstandard(M3)) 図1.11: QQplot for M3 続いて、(モデルに入れていない説明変数を含めた)各連続変数と標準化残差の関連を図示する(図1.12)。いずれも関連はないようで、これはモデルによって説明できない部分(= 残差)はこうした変数とも関連がないことを示している。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(CC, LatAbs, FM, Illuminance, Temperature, resstd) %&gt;% pivot_longer(cols = 1:5, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_point()+ geom_smooth(method = &quot;lm&quot;, color = &quot;black&quot;)+ facet_rep_wrap(~var, repeat.tick.labels = TRUE, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.12: Multiple scatterplots of the standardized residuals versus each continuous variables これは、離散的な変数についても同様のようである(図1.13)。 hvs_b %&gt;% mutate(resstd = rstandard(M3)) %&gt;% select(fPopulation, fGender, resstd) %&gt;% pivot_longer(1:2, names_to = &quot;var&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = values, y = resstd))+ geom_boxplot()+ facet_rep_wrap(~var, scales = &quot;free_x&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Explanatory variables&quot;, y = &quot;Standardized residuals&quot;) 図1.13: Boxplot of standardized residuals versus discrete variable 自己相関も大きくなさそうである。 acf(hvs_b$OrbitalV) 1.9 Model interpretation モデルの推定値に基づくと、眼窩容量の予測値は以下のように書ける。 \\[ OrbitalV_i = 23.23 -0.25 \\times LatAbs_i -0.000058 \\times CC_i + 0.00022 \\times LatAbs_i \\times CC_i \\] モデルに基づく回帰平面を描くと以下のようになる(図1.14)。 data_M3 &lt;- crossing(LatAbs = seq(0.02,65, length.out = 100), CC = seq(1100,1700, length.out = 100)) pred &lt;- predict(M3, newdata = data_M3) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(data_M3) %&gt;% pivot_wider(names_from = CC, values_from = pred) %&gt;% select(-1) plot_ly(hvs_b, x = ~LatAbs, y = ~CC, z = ~OrbitalV, type = &quot;scatter3d&quot;, size = 2) %&gt;% add_trace(z = as.matrix(pred), x = seq(0.02,65, length.out = 100), y = seq(1100,1700, length.out =100), type = &quot;surface&quot;) -&gt; p p 図1.14: 3d plot of the fitted surface 1.10 What to do if things go wrong もしモデルが前提を満たさなかったらどうすればよいだろうか?本節では特にどのようなときにGAMを適用すべきかを解説する。 等分散性の仮定が満たされないとき、以下の選択肢を検討する必要がある。 目的変数に変数変換を施す 一般化最小二乗法(GLS)を用いる さらに説明変数や交互作用を加える 目的変数の分布として他の分布を用いる(ガンマ分布など) 3つ目の選択肢において、非線形のパターンも許容するように拡張すると、GAMが使えるようになる。これは、残差と説明変数が何らかのパターンを示した時にも有効である(= 関係が線形でない可能性があるため)。 References Burnham, K. P., Anderson, D. R., &amp; Huyvaert, K. P. (2011). AIC model selection and multimodel inference in behavioral ecology: Some background, observations, and comparisons. Behav. Ecol. Sociobiol., 65(1), 23–35. Dunn, P. K., &amp; Smyth, G. K. (2018). Generalized linear models with examples in R. Springer New York. Pearce, E., &amp; Dunbar, R. (2012). Latitudinal variation in light levels drives human visual system size. Biol. Lett., 8(1), 90–93. Zuur, A. F., Ieno, E. N., &amp; Elphick, C. S. (2010). A protocol for data exploration to avoid common statistical problems. Methods Ecol. Evol., 1(1), 3–14. 説明変数(独立変数)とは、物事の原因となっている変数のこと、目的変数(応答変数)とは説明変数の影響を受けて発生した結果となっている変数のことである。今回の場合は、様々な標高など(= 説明変数)が眼窩容量(= 目的変数)に与える影響をモデリングする。↩︎ より正確には、F分布の50パーセンタイルが基準になるが、多くの場合その値は1に近い(Dunn &amp; Smyth, 2018)。↩︎ "],["Chapter2.html", "2 Introduction to additive models using deep-sea fisheries data 2.1 Impact of deep-sea fisheries 2.2 First encounter with smoothers 2.3 Allpying GAM in R using the mgcv package 2.4 Cross validation 2.5 Model validation 2.6 Extending the GAM with more covariates", " 2 Introduction to additive models using deep-sea fisheries data 本章では、正規分布に従う一般化加法モデル(GAM)の導入を行う。 2.1 Impact of deep-sea fisheries 本章では、商業的な漁業が深海(水深800~4865m)の魚の密度に及ぼす影響を調べた Bailey et al. (2009) のデータを用いる。データは2つの期間に分かれており、19791989年は商業的な漁業がおこなわれる前(深い水深での漁業が発展している段階)で、19972002年は商業的漁業がおこなわれている時期である。商業的漁業は技術的または商業的な理由により水深約1600mまでに限られている。 fish &lt;- read_delim(&quot;data/BaileyDensity.txt&quot;) datatable(fish, options = list(scrollX = 20), filter = &quot;top&quot;) Bailey et al. (2009) では、魚の密度を以下のように定義している。 \\[ 場所iにおける魚の密度 = \\frac{場所iの魚の総量}{場所iで探索を行った面積} \\] 密度のような割り算データを目的変数にして正規分布に当てはめると、等分散性の問題が生じることが多い。通常、このような分子が整数値の割り算データに対してはポワソン分布や負の二項分布でオフセット項を用いる(第4章を参照)。もし分母が試行数、分子が成功数などのカウントデータの場合は二項分布を当てはめた方がよい。密度が0より大きい値しかとらないのであれば、ガンマ分布を当てはめることもできる。 2.2 First encounter with smoothers 2.2.1 Applying linear regression 2.2.1.1 当てはめるモデル 全種を含めた魚の密度は以下のように表せる。なお\\(i\\)は場所を、\\(j\\)は魚の種類を表す。また、\\(SA_i\\)は場所\\(i\\)における探索面積を、\\(Y_{ij}\\)は場所\\(i\\)における種\\(j\\)の捕獲個体数を表す。 \\[ Dens_i = \\frac{\\sum_j Y_{ij}}{SA_i} \\] まずは、各探索場所の深さのみが魚の密度に影響するとする線形なモデルを考える。モデル式は以下のようになる。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta \\times Depth_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.2.1.2 data exploration いかなるモデルを作ろうとも、まずはデータ探索を行う。まずは、水深と魚の密度の関連をプロットする(図2.1)。図から明らかに水深と魚の密度の関係は線形ではない。しかし、ここではこうしたデータが線形モデルの前提を満たさないことを示すため、まずは通常の線形モデルを適用する。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% mutate(year01 = ifelse(Year &gt; 1990, &quot;commercial&quot;,&quot;non-commercial&quot;)) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(shape = year01))+ scale_shape_manual(values = c(19,1)) + theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Mean sampling depth (m)&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.1: Relationship between fish density and mean sampling depth. Filled circles are observations from the second period and open circles from the first period. モデルは以下のように実行できる。モデルは、目的変数のばらつきの33.7%が水深で説明できると推定している(Adjusted R-squaredより)。 fish %&gt;% filter(MeanDepth &gt; 800) %&gt;% na.omit() -&gt; fish M2_1 &lt;- lm(Dens ~ MeanDepth, data = fish) print(summary(M2_1), digits = 3) ## ## Call: ## lm(formula = Dens ~ MeanDepth, data = fish) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.007835 -0.002519 -0.000558 0.001420 0.023109 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.09e-02 8.06e-04 13.51 &lt;2e-16 *** ## MeanDepth -2.56e-06 2.96e-07 -8.63 1e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.00449 on 145 degrees of freedom ## Multiple R-squared: 0.339, Adjusted R-squared: 0.335 ## F-statistic: 74.4 on 1 and 145 DF, p-value: 1.02e-14 2.2.1.3 model diagnosis それでは、モデル診断を行おう。 まずは標準化残差とモデルの予測値の関係を見る(図2.2のA)。明らかにパターンが見て取れ、モデルが等分散性の仮定を満たしていないことが分かる。また、水深と標準化残差にもパターンがあるように見え(図2.2のB)、このモデルでは水深でうまく目的変数を説明できていないことが分かる。 data.frame(resstd = rstandard(M2_1), fitted = fitted(M2_1)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_1_a data.frame(resstd = rstandard(M2_1), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_1_b p_diag_M2_1_a + p_diag_M2_1_b 図2.2: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットでも標準化残差が標準正規分布に従っていないことが示唆される。 qqnorm(rstandard(M2_1)) qqline(rstandard(M2_1)) 図2.3: QQplot for M2_1 残差に見られたパターンは、明らかに非線形なデータに直線的なモデルを当てはめているために生じている。図2.4からわかるように、水深2000m以上ではモデルに基づく回帰直線がほとんどデータの上に来てしまっている。また、水深約4000m以上では予測値がマイナスになってしまっている。 dataM2_1 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_1 &lt;- predict(M2_1, newdata = dataM2_1) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_1) pred_M2_1 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.4: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.2 Applying cubic polynomials モデルを改善するため、説明変数に水深の二乗、三乗、四乗項を入れるモデルを考える(= 多項式回帰)。このようにすることで非線形な関係をとらえられるかもしれない。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + \\beta_1 \\times Depth_i + \\beta_2 \\times Depth^2_i + \\beta_3 \\times Depth^3_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] そのようなモデルは以下で実行できる。 M2_2 &lt;- lm(Dens ~ poly(MeanDepth, 3), data = fish) モデルの診断を行ったのが図2.5である。明確なパターンがあるように見え(A. 予測値が大きいほどばらつきが大きくなる、B. 水深が浅くなるほどばらつきが大きくなる)、モデルが十分に改善できていないことが分かる。 data.frame(resstd = rstandard(M2_2), fitted = fitted(M2_2)) %&gt;% ggplot(aes(x = fitted, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted values&quot;, y = &quot;Standardized residuals&quot;, title = &quot;A&quot;) -&gt; p_diag_M2_2_a data.frame(resstd = rstandard(M2_2), depth = fish$MeanDepth) %&gt;% ggplot(aes(x = depth, y = resstd))+ geom_point()+ geom_hline(yintercept = 0)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = &quot;Standardized residuals&quot;, title = &quot;B&quot;) -&gt; p_diag_M2_2_b p_diag_M2_2_a + p_diag_M2_2_b 図2.5: A. Standardized residuals versus fitted values to assess homogeneity. B. Residuals versus mean depth. QQプロットからも標準化残差が標準正規分布に従っていないことが分かる(図2.6)。 qqnorm(rstandard(M2_2)) qqline(rstandard(M2_2)) 図2.6: QQplot for M2_2 実測値にモデルに基づく予測値を描いたのが図2.7である。水深4000mあたりで予測値がほとんどの実測値よりも低くなってしまっている。 dataM2_2 &lt;- data.frame(MeanDepth = seq(800,5000,length.out = 100)) pred_M2_2 &lt;- predict(M2_2, newdata = dataM2_2) %&gt;% data.frame() %&gt;% rename(pred = 1) %&gt;% bind_cols(dataM2_2) pred_M2_2 %&gt;% ggplot(aes(x = MeanDepth, y = pred))+ geom_line()+ geom_point(data = fish, aes(y = Dens))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.7: Fidh density plotted versus depth, with fitted values obtained by linear model. 2.2.3 A simple GAM モデルを改善するほかの選択肢は、一般化加法モデル(GAM)を用いることである。シンプルなGAMは以下のように書ける。\\(f(Depth_i)\\)は平滑化関数であり、予測値がデータに合うような曲線を描くように推定される。以下では、GAMではどのようにしてこの関数を推定するのかを説明していく。 \\[ \\begin{aligned} Dens_i &amp;= \\alpha + f(Depth_i) + \\epsilon_i \\tag{2.1} \\\\ \\epsilon_i &amp;\\sim N(0,\\sigma^2) \\end{aligned} \\] 2.2.4 Moving average and LOESS smoother データに合うように平滑化を行う方法は複数存在するが、比較的単純なものが移動平均とLOESS(局所回帰)である。より複雑な手法については第3方で解説する。 2.2.4.1 移動平均 移動平均は、推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータの平均値を推定値とするような方法である。例えば、水深2500mのときの推定値として、その前後500m(2000m ~ 3000m)にあるデータの平均値を用いると、0.00286になる(図2.8)。 fish %&gt;% filter(MeanDepth &gt;= 2000 &amp; MeanDepth &lt;= 3000) %&gt;% summarise(mean = mean(Dens)) -&gt; mean fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_vline(xintercept = 2000, linetype = &quot;dashed&quot;)+ geom_vline(xintercept = 3000, linetype = &quot;dashed&quot;)+ geom_point(aes(x = 2500, y = mean$mean), size = 5, shape = 18, color = &quot;black&quot;)+ annotate(geom = &quot;text&quot;, x = 3000, y = mean$mean + 0.002, label = sprintf(&quot;%.5f&quot;,mean$mean))+ geom_segment(aes(x = 2550, xend = 2900, y = mean$mean, yend = mean$mean + 0.0015))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.8: Visualization of the process of the moving average. A target value of depth = 2500 was chosen. これを一定間隔のデータで行ってつなげると、移動平均に基づいて平滑化曲線を描くことができる(図2.9)。 Depth_n &lt;- seq(810, 4800, length.out = 150) Mean_n &lt;- data.frame(MeanDepth = Depth_n, Est = NA) for(i in seq_along(Depth_n)){ fish %&gt;% filter(MeanDepth &gt;= Depth_n[i] - 500 &amp; MeanDepth &lt;= Depth_n[i] + 500) %&gt;% summarise(mean = mean(Dens)) -&gt; mean_i Mean_n[i,2] &lt;- mean_i$mean } fish %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(shape = 1)+ geom_line(data = Mean_n, aes(y = Est), linewidth = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.9: Estimated moving average smoother 2.2.4.2 局所回帰(LOESS) 移動平均ではギザギラのラインが推定されるが、LOESSではよりスムーズなラインを引くことができる。局所回帰は推定値を求めたいポイントの前後にある特定の範囲(あるいは個数?)のデータだけを用いて多項式回帰を行い(多くのソフトでデフォルトでは2次の項までを含む)、その予測値を推定値とする方法である。移動平均と同様に一定間隔のポイントに対してこれを行うことで、平滑化した曲線を描く。 Rでは、loess関数で推定を行うことができる。span =で各ポイントでの推定に用いるデータの割合を指定できる(デフォルトは0.75)。図2.10はspanを0.1, 0.5, 1にした場合に描けるモデルから推定された平滑化曲線である。1のときは、全データを使用した多項式回帰と同じ結果である。移動平均でもLOESSでも、推定を行う際に使用するデータの範囲を変えると結果も大きく変わるので注意が必要である。 M2_3_a &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.1) M2_3_b &lt;- loess(Dens ~ MeanDepth, data = fish, span = 0.5) M2_3_c &lt;- loess(Dens ~ MeanDepth, data = fish, span = 1) pred_M2_3_a &lt;- predict(M2_3_a, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.1) pred_M2_3_b &lt;- predict(M2_3_b, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 0.5) pred_M2_3_c &lt;- predict(M2_3_c, se = TRUE, newdata = data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% data.frame() %&gt;% bind_cols(data.frame(MeanDepth = seq(800, 4865, length.out = 100))) %&gt;% mutate(upper = fit + qt(0.975, df = df)*se.fit, lower = fit - qt(0.975, df = df)*se.fit, span = 1) bind_rows(pred_M2_3_a, pred_M2_3_b, pred_M2_3_c) %&gt;% mutate(span = str_c(&quot;span = &quot;, span)) %&gt;% ggplot(aes(x = MeanDepth, y = fit))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3)+ geom_point(data = fish, aes(y = Dens), shape = 1)+ facet_rep_wrap(~ span)+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.10: LOESS smoother using a span of 0.1, 0.5, and 1. 2.2.5 Packages for smoothing Rには、平滑化を行うことができるパッケージが複数存在する。例えば、gamパッケージ(Hastie &amp; Hastie, 2018)、mgcvパッケージ(Wood &amp; EPSRC, 2007)、gamlssパッケージ(Rigby et al., 2019)などがある。それぞれのパッケージに長所と短所があり、gamはLOESSを用いる際に使いやすく、mgvcはより発展的な手法に対して使いやすい。gamlssはより広い分布に対して用いることができる。本稿では主にmgcvパッケージを用いる。 mgvcパッケージでは様々な手法を用いた平滑化を行うことができるが、自身のデータに対してどの方法を用いるかを決めるためにはこうした手法について知っていなければならない。こうした手法については、第(??)章で詳しく学ぶ。 2.3 Allpying GAM in R using the mgcv package 本節では、mgvcパッケージを用いてGAMを適用する方法を学ぶ。まず、gam関数を用いて式(2.1)を以下のように適用する。なお、fx = TRUE、k = 5というのは有効自由度4の平滑化関数が用いられていることを示しているが、詳しくは次章で説明する。 M2_4 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 5), data = fish) gam関数はthin plate regression splineといわれる方法を用いている。有効自由度は曲線の形を決める値であり(calibration value)、1だと直線になり大きくなるほどより非線形な形になる。自由度4は古典的なパッケージでデフォルトとしてよく使われている値であり、推定された曲線は3次の項までを含む多項式回帰によるものと似ている。次節(??)ではcross validationを用いてどの自由度が最も適切か決める方法を学ぶ。 summary関数でモデルの結果の概要を得ることができる。 summary(M2_4) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth, fx = TRUE, k = 5) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0046888 0.0003591 13.06 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 4 4 22.45 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.369 Deviance explained = 38.6% ## GCV = 1.9752e-05 Scale est. = 1.9085e-05 n = 148 切片の推定値は0.0047なので、モデル式は以下のように書ける。 \\[ Dens_i = 0.0047 + f(Depth_i) \\] また、結果からはモデルが分散の36.9%を説明すること、推定された残差が従う正規分布の分散が\\(1.908 \\times 10^{-5}\\)であることも分かる。 smoother(\\(f(Dens_i)\\))の有意性(Approximate significance of smooth term)は、以下のF値によって計算されている。なお、\\(RSS_1、RSS_2\\)はそれぞれsmootherがないモデルとあるモデルの残差平方和、\\(pとq\\)はそれぞれsmootherがあるモデルとないモデルの自由度、\\(N\\)はサンプル数である。もしモデルが前提を満たすならば、Fは自由度\\(N-p\\)と\\(p-q\\)のF分布に従う。 \\[ F = \\frac{(RSS_1 - RSS_2)/(p-q)}{RSS_2/(N-p)} \\] モデルによって推定された曲線は以下のようになる(図2.11)。mgvcパッケージで推定した結果は、gratiaパッケージを用いると簡単に描画することができる。 dataM2_4 &lt;- data.frame(MeanDepth = seq(800, 4865, length.out = 100)) ## 予測値を算出 pred_M2_4_4 &lt;- fitted_values(M2_4, data = dataM2_4) %&gt;% mutate(df = 4) ## 描画 pred_M2_4_4 %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.11: Fitted values obtained by the GAM. 2.4 Cross validation 前節では自由度4で分析を行ったが、自由度はほかの値に設定することも可能である(図2.12。どのようにして最適な自由度を選べばよいだろうか? ## df = 2 M2_4_2 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 3), data = fish) pred_M2_4_2 &lt;- fitted_values(M2_4_2, data = dataM2_4) %&gt;% mutate(df = 2) ## df = 3 M2_4_3 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 4), data = fish) pred_M2_4_3 &lt;- fitted_values(M2_4_3, data = dataM2_4) %&gt;% mutate(df = 3) ## df = 5 M2_4_5 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 6), data = fish) pred_M2_4_5 &lt;- fitted_values(M2_4_5, data = dataM2_4) %&gt;% mutate(df = 5) ## df = 7 M2_4_7 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 8), data = fish) pred_M2_4_7 &lt;- fitted_values(M2_4_7, data = dataM2_4) %&gt;% mutate(df = 7) ## df = 9 M2_4_9 &lt;- gam(Dens ~ s(MeanDepth, fx = TRUE, k = 10), data = fish) pred_M2_4_9 &lt;- fitted_values(M2_4_9, data = dataM2_4) %&gt;% mutate(df = 9) ## 描画 bind_rows(pred_M2_4_2, pred_M2_4_3, pred_M2_4_4, pred_M2_4_5, pred_M2_4_7,pred_M2_4_9) %&gt;% mutate(df = str_c(&quot;df = &quot;,df)) %&gt;% ggplot(aes(x = MeanDepth, y = fitted))+ geom_line()+ geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(0,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) + facet_rep_wrap(~df, repeat.tick.labels = TRUE) 図2.12: Fitted values obtained by the GAM using 2, 3, 4, 5, 7, 9 degrees of freedom. gam関数では、fx =とk =を書かなければ自動的に交差検証(cross validation)を実行し、最適な自由度を探してくれる。下記のように、最適な自由度は5.62ということになる。 M2_5 &lt;- gam(Dens ~ s(MeanDepth), data = fish) summary(M2_5) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0047137 0.0003561 13.24 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.621 6.723 14.1 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.386 Deviance explained = 40.9% ## GCV = 1.9514e-05 Scale est. = 1.8635e-05 n = 147 推定結果をもとに描いた平滑化曲線は以下のようになる(図2.13)。 pred_M2_5 &lt;- smooth_estimates(M2_5, data = dataM2_4) %&gt;% ## 95%信頼区間を算出 add_confint() %&gt;% mutate(est = est + coef(M2_5)[[1]], lower_ci = lower_ci + coef(M2_5)[[1]], upper_ci = upper_ci + coef(M2_5)[[1]]) %&gt;% mutate(df = 4) ## 描画 pred_M2_5 %&gt;% ggplot(aes(x = MeanDepth, y = est))+ geom_line()+ geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.3) + geom_point(data = fish, aes(y = Dens), shape = 1)+ coord_cartesian(ylim = c(-0.001,0.032))+ theme_bw(base_size = 12)+ theme(aspect.ratio = 1)+ labs(x = &quot;Mean Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.13: Fitted values obtained by the GAM. それでは、交差検証とは何だろうか?smoother\\(f(Depth_i)\\)の推定値を\\(\\hat{f}(Depth_i)\\)とするとき、推定値が真のsmootherとどれほど近いかは以下の式で表せる。 \\[ M = \\frac{1}{n}\\sum_{i = 1} ^n (f(Depth_i) - \\hat{f}(Depth_i))^2 \\] もし私たちが真の\\(f(Depth_i)\\)を知っているならば、Mが最小になるように\\(\\hat{f}(Depth_i)\\)を推定することができるが、真のsmootherを知ることはできない。そのため、私たちは\\(M\\)を何か計算可能なもので代用する必要がある。 方法としては、交差検証、一般化交差検証(generalized cross validation)、頑強なリスク推定(unbiased risk estimator)、Marrow’s Cpなどがある。gam関数では、通常の加法モデルを適用するか、一般化加法モデルを適用するかによってこれらのいずれかが用いられる。本節では、通常の交差検証(ordinary cross validation: OCV)について簡単な解説を行う。 交差検証のスコア\\(V_0\\)は以下の式で与えられる。\\(f^{-i}(Depth_i)\\)は\\(i\\)番目のデータ以外のデータから推定されたsmootherの推定値を表す。\\(V_0\\)を最小にするようにsmootherの推定値を求める。 \\[ V_0 = \\frac{1}{n}\\sum_{i = 1} ^n (Depth_i -f^{-i}(Depth_i))^2 \\] 理論的に、\\(V_0\\)の期待値は\\(M\\)の期待値に分散\\(\\sigma^2\\)を足した値に近似できる。 \\[ E[V_0] \\approx E[M] + \\sigma^2 \\] これを計算するのは負荷が大きいため、通常はgeneralized cross validation scoreというものを用いることでshortcutを行う。詳細については第??で解説を行う。データ数が50未満の場合は多重共線性やデータの非独立性によって交差検証の結果に問題が生じることがある。そのため、交差検証の結果をきちんと確認することが必要である。 2.5 Model validation 2.5.1 Normality and homogeneity GAMでは重回帰分析のときと同様に残差を抽出し、その正規性や等分散性、独立性、影響のある観察の有無を確認しなければならない。 gratiaパッケージでは、appraise関数でQQプロット、残差 vs 予測値、残差のヒストグラム、実測値 vs 予測値のプロットを作成してくれる(図??)。なお、それぞれのグラフはqq_plot()、residuals_linpred_plot()、residuals_hist_plot()、observed_fitted_plotで個別に作成できる。 この結果から、等分散性や残差の正規性が成立していないことが分かる。 appraise(M2_5, type = &quot;response&quot;) 図2.14: Model diagnosis using gratia package. 手動で残差 vs 予測値、残差のヒストグラムは以下のように作成できる(図2.15)。 data.frame(res &lt;- resid(M2_5), fitted = fitted(M2_5)) -&gt; diag_M2_5 diag_M2_5 %&gt;% ggplot(aes(x = fitted,y = res))+ geom_point()+ geom_hline(yintercept = 0, color = &quot;red&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Fitted value&quot;, y = &quot;Residuals&quot;) -&gt; p_diag_M2_5_a diag_M2_5 %&gt;% ggplot(aes(x = res))+ geom_histogram(fill = &quot;white&quot;, color = &quot;black&quot;)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Residuals&quot;, y = &quot;Frequancy&quot;) -&gt; p_diag_M2_5_b p_diag_M2_5_a + p_diag_M2_5_b 図2.15: Model diagnosis of GAM. 2.5.2 Independence 残差の独立性を確認するため、残差と説明変数などの変数の関連をプロットする(図2.16)。水深との関連については(A)、等分散性の仮定が満たされていないことを除けば、特にパターンは見られない。もし水深との関連にもパターンがみられていたら、GAMの自由度を上げることでこの問題を解決できる。 一方で、期間との関連についてはパターンがみられ、期間2の残差がほとんど0を下回っている。このことは、Periodをモデルに加えた方がいいことを示唆している。 data.frame(res = resid(M2_5), MeanDepth = fish$MeanDepth) %&gt;% ggplot(aes(x = MeanDepth, y = res))+ geom_point(shape = 1)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = &quot;Residuals&quot;, title = &quot;A&quot;) -&gt; p_ind_M2_5_a data.frame(res = resid(M2_5), Period = as.factor(fish$Period)) %&gt;% ggplot(aes(x = Period, y = res))+ geom_boxplot()+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Period&quot;, y = &quot;Residuals&quot;, title = &quot;B&quot;) -&gt; p_ind_M2_5_b p_ind_M2_5_a + p_ind_M2_5_b 図2.16: A: residuals versus depth. B: residuals versus period 残差に空間的な相関があるかを調べるため、各データポイントで調査が行われた場所と残差の大きさの関連を示したものが図2.17である。残差の大きさが点の色と大きさで表されている。このデータだけではいまいち解釈がしにくい。 data.frame(res = resid(M2_5), x = fish$Xkm, y = fish$Ykm) %&gt;% ggplot(aes(x = x, y = y))+ geom_point(aes(color = res, size = res), alpha = 0.5)+ scale_size(range = c(1,7))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;X-coordinates&quot;, y = &quot;Y-coordinates&quot;) 図2.17: Bubble plot of the residuals. このようなときに使えるのがバリオグラム(variogram)である。バリオグラムは以下の手順で作成する。なお、通常dは離散的に選択する。 全てのサイト間の距離を計算する。 距離がある特定の値dであるサイトの全組み合わせについて残差の差の二乗を計算し、それの平均値を算出する。 これを全ての距離について行い、距離と平均値の関係をプロットする。 もし残差が空間的に独立なのであれば、算出された平均値は水平に分布する。 Rではgstatパッケージで以下のように算出できる。図で表したものが図2.18である。図からは150m以上離れるとsemi-variogram値(縦軸)が大きくなる傾向があることが分かる。このパターンは、他の変数や交互作用をモデルに含めることで解消できるかもしれない。 fish_cor &lt;- fish ## coordinateを作成 coordinates(fish_cor) &lt;- ~ Xkm + Ykm ## 算出 vario_M2_5 &lt;- variogram(resid(M2_5) ~ 1, fish_cor) ## 作図 vario_M2_5 %&gt;% ggplot(aes(x = dist, y = gamma))+ geom_point(size = 3)+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Distance (km)&quot;, y = &quot;semivariogram&quot;) 図2.18: Semi-variogram of the residuals of the GAM. この分析の問題点は深さが考慮されていない点である。2地点間のxy平面上の距離が近くても、深さが違えば実際の距離は最大で5km近く離れている可能性がある。 2.5.3 Influential observations GAMではcook’s distanceは算出できないが、各観測値の影響力の強さは全データを用いたモデルから推定されたsmoother(\\(\\hat{f}(Depth_i)\\))からその観測値以外のデータを用いたモデルから推定されたsmoother(\\(f^{-i}(Depth_i)\\))を引いた値の二乗の合計値を算出することで求めることができる。各観測値について影響力の大きさは以下のように定式化できる。 \\[ I_i = \\sum_{i = 1}^n (\\hat{f}(Depth_i) - f^{-i}(Depth_i))^2 \\] Rでは以下のように計算できる。 nd &lt;- data.frame(MeanDepth = seq(min(fish$MeanDepth), max(fish$MeanDepth), length.out = 150)) pred_M2_5 &lt;- predict(M2_5, newdata = nd, type = &quot;terms&quot;) I &lt;- vector() for(i in 1:nrow(fish)){ M2_5.i &lt;- gam(Dens ~ s(MeanDepth), data = fish %&gt;% filter(Site != fish[i,1][[1]])) pred_M2_5.i &lt;- predict(M2_5.i, newdata = nd, type = &quot;terms&quot;) I[i] &lt;- sum((pred_M2_5[1:150] - pred_M2_5.i[1:150])^2) } 各ポイントの影響力の大きさをサイズにしてプロットしたのが図2.19である。いくつか影響力の高そうな点があるが、それが有意に大きいのか否かを言うことはできない。 fish %&gt;% mutate(I = I) %&gt;% ggplot(aes(x = MeanDepth, y = Dens))+ geom_point(aes(size = I))+ theme_bw()+ theme(aspect.ratio = 1, legend.position = &quot;none&quot;)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.19: Scatterplot of fish density versus depth. The size of an observation point is proportional to its influence on the shape of the smoother. 2.6 Extending the GAM with more covariates 2.6.1 GAM with smoother and a normal covariate GAMでも通常の線形モデルと同様に2つ以上の説明変数や交互作用を含めることができる。ここでは、これまでのモデルでは考慮できなかった調査期間(Period)と調査期間と水深(MeanDepth)の交互作用を入れることで、調査期間ごとに水深と魚の密度の関係が変わっているのかを調べるモデルを作成する。本節では交互作用なしとありのモデルを作成し、どちらがより良いモデルかを検討する。 交互作用なしモデルのモデル式は以下のようになる。このモデルでは、水深と魚の密度の関連はいずれの期間でも同じだが、その平均が期間によって異なることを仮定している。 \\[ \\begin{aligned} Dnes_i &amp;= \\alpha + f(Depth_i) + \\beta \\times Period_i + \\epsilon_i \\\\ \\epsilon_i &amp;\\sin N(0,\\sigma^2) \\end{aligned} \\] モデルはRで以下のように実行できる。 fish &lt;- fish %&gt;% mutate(Period = as.factor(Period)) M2_6 &lt;- gam(Dens ~ s(MeanDepth) + Period, data = fish) 結果は以下の通り。 summary(M2_6) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## Dens ~ s(MeanDepth) + Period ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0054572 0.0004291 12.716 &lt; 2e-16 *** ## Period2 -0.0021859 0.0007433 -2.941 0.00383 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(MeanDepth) 5.566 6.664 14.85 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.417 Deviance explained = 44.4% ## GCV = 1.8637e-05 Scale est. = 1.7677e-05 n = 147 モデルの推定結果からそれぞれの期間について以下のような式が書ける。 \\[ \\begin{aligned} Period1: Dens_i &amp;= 0.0054 + f(Depth_i) \\\\ Period2: Dens_i &amp;= 0.0032 + f(Depth_i) \\end{aligned} \\] モデルの結果を図示したのが図2.20である。 nd &lt;- crossing(MeanDepth = seq(800, 4650, length.out = 100), Period = as.factor(c(1,2))) fitted_values(M2_6, data = nd, scale = &quot;response&quot;) %&gt;% ggplot(aes(x = MeanDepth))+ geom_line(aes(y = fitted, linetype = Period))+ geom_point(data = fish, aes(y = Dens, fill = Period), shape = 21)+ scale_fill_manual(values = c(&quot;white&quot;,&quot;black&quot;))+ theme_bw()+ theme(aspect.ratio = 1)+ labs(x = &quot;Depth&quot;, y = expression(paste(&quot;Fish density&quot;,&quot; &quot;, (m^2)))) 図2.20: Visualisation of the GAM that contains a smoother of depth and period as a factor. 2.6.2 GAM with interaction terms; first implement References Bailey, D. M., Collins, M. A., Gordon, J. D. M., Zuur, A. F., &amp; Priede, I. G. (2009). Long-term changes in deep-water fish populations in the northeast atlantic: A deeper reaching effect of fisheries? Proc. Biol. Sci., 276(1664), 1965–1969. Hastie, T., &amp; Hastie, M. T. (2018). Package “gam.” GAM Package CRAN, Cran. R-Project. Org/Web/Packages/Gam/Gam. Pdf. Rigby, R. A., Stasinopoulos, M. D., Heller, G. Z., &amp; De Bastiani, F. (2019). Distributions for modeling location, scale, and shape: Using GAMLSS in R. CRC Press. Wood, S., &amp; EPSRC, P. funded by. (2007). R mgcv-package. "],["sessioninfo.html", "実行環境", " 実行環境 sessionInfo() ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 22621) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.utf8 LC_CTYPE=Japanese_Japan.utf8 ## [3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.utf8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] sp_1.5-1 gstat_2.1-1 gratia_0.8.1.34 mgcv_1.8-41 ## [5] nlme_3.1-160 fontregisterer_0.3 systemfonts_1.0.4 extrafont_0.18 ## [9] lemon_0.4.6 ggsci_2.9 concaveman_1.1.0 ggforce_0.4.1 ## [13] ggdag_0.2.7 dagitty_0.3-1 kableExtra_1.3.4 knitr_1.43 ## [17] DT_0.27 patchwork_1.1.2 GGally_2.1.2 htmlwidgets_1.6.2 ## [21] plotly_4.10.1 data.table_1.14.6 see_0.7.5.5 report_0.5.7.4 ## [25] parameters_0.20.3 performance_0.10.3 modelbased_0.8.6.3 insight_0.19.1.4 ## [29] effectsize_0.8.3.6 datawizard_0.7.1.1 correlation_0.8.4 bayestestR_0.13.1 ## [33] easystats_0.6.0.8 forcats_1.0.0 stringr_1.5.0 dplyr_1.1.2 ## [37] purrr_1.0.0 readr_2.1.3 tidyr_1.2.1 tibble_3.2.1 ## [41] ggplot2_3.4.2 tidyverse_1.3.2 ## ## loaded via a namespace (and not attached): ## [1] googledrive_2.0.0 colorspace_2.0-3 ellipsis_0.3.2 ## [4] estimability_1.4.1 fs_1.5.2 rstudioapi_0.15.0 ## [7] farver_2.1.1 fansi_1.0.3 mvtnorm_1.1-3 ## [10] lubridate_1.9.0 xml2_1.3.3 codetools_0.2-18 ## [13] splines_4.2.2 cachem_1.0.6 polyclip_1.10-4 ## [16] jsonlite_1.8.4 Rttf2pt1_1.3.8 broom_1.0.2 ## [19] dbplyr_2.2.1 compiler_4.2.2 httr_1.4.4 ## [22] emmeans_1.8.3 backports_1.4.1 Matrix_1.5-1 ## [25] assertthat_0.2.1 fastmap_1.1.0 lazyeval_0.2.2 ## [28] gargle_1.2.1 cli_3.6.0 tweenr_2.0.2 ## [31] htmltools_0.5.4 tools_4.2.2 igraph_1.3.5 ## [34] coda_0.19-4 gtable_0.3.3 glue_1.6.2 ## [37] V8_4.2.2 Rcpp_1.0.11 cellranger_1.1.0 ## [40] jquerylib_0.1.4 vctrs_0.6.2 svglite_2.1.1 ## [43] extrafontdb_1.0 xfun_0.39 rvest_1.0.3 ## [46] timechange_0.1.1 lifecycle_1.0.3 googlesheets4_1.0.1 ## [49] zoo_1.8-11 MASS_7.3-58.1 scales_1.2.1 ## [52] tidygraph_1.2.2 hms_1.1.3 RColorBrewer_1.1-3 ## [55] mvnfast_0.2.8 yaml_2.3.7 curl_4.3.3 ## [58] gridExtra_2.3 sass_0.4.5 reshape_0.8.9 ## [61] stringi_1.7.8 highr_0.10 ggokabeito_0.1.0 ## [64] boot_1.3-28 intervals_0.15.4 rlang_1.1.1 ## [67] pkgconfig_2.0.3 evaluate_0.20 lattice_0.20-45 ## [70] labeling_0.4.2 tidyselect_1.2.0 plyr_1.8.8 ## [73] magrittr_2.0.3 bookdown_0.34 R6_2.5.1 ## [76] generics_0.1.3 DBI_1.1.3 pillar_1.9.0 ## [79] haven_2.5.1 withr_2.5.0 xts_0.12.2 ## [82] spacetime_1.3-0 modelr_0.1.10 crayon_1.5.2 ## [85] utf8_1.2.2 tzdb_0.3.0 rmarkdown_2.23 ## [88] grid_4.2.2 readxl_1.4.1 FNN_1.1.3.2 ## [91] reprex_2.0.2 digest_0.6.31 webshot_0.5.4 ## [94] xtable_1.8-4 munsell_0.5.0 viridisLite_0.4.2 ## [97] bslib_0.4.2 References Bailey, D. M., Collins, M. A., Gordon, J. D. M., Zuur, A. F., &amp; Priede, I. G. (2009). Long-term changes in deep-water fish populations in the northeast atlantic: A deeper reaching effect of fisheries? Proc. Biol. Sci., 276(1664), 1965–1969. Burnham, K. P., Anderson, D. R., &amp; Huyvaert, K. P. (2011). AIC model selection and multimodel inference in behavioral ecology: Some background, observations, and comparisons. Behav. Ecol. Sociobiol., 65(1), 23–35. Chang, W. (2018). R graphics cookbook: Practical recipes for visualizing data. “O’Reilly Media, Inc.” Dunn, P. K., &amp; Smyth, G. K. (2018). Generalized linear models with examples in R. Springer New York. Hastie, T., &amp; Hastie, M. T. (2018). Package “gam.” GAM Package CRAN, Cran. R-Project. Org/Web/Packages/Gam/Gam. Pdf. Pearce, E., &amp; Dunbar, R. (2012). Latitudinal variation in light levels drives human visual system size. Biol. Lett., 8(1), 90–93. Rigby, R. A., Stasinopoulos, M. D., Heller, G. Z., &amp; De Bastiani, F. (2019). Distributions for modeling location, scale, and shape: Using GAMLSS in R. CRC Press. Wickham, H., &amp; Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. “O’Reilly Media, Inc.” Wood, S., &amp; EPSRC, P. funded by. (2007). R mgcv-package. Zuur, A. F., Ieno, E. N., &amp; Elphick, C. S. (2010). A protocol for data exploration to avoid common statistical problems. Methods Ecol. Evol., 1(1), 3–14. 松村優哉., 湯谷啓明., 紀ノ定保礼., &amp; 前田和. (2021). RユーザのためのRstudio[実践]入門 tidyverseによるモダンな分析フローの世界 改訂2版. 技術評論社. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
